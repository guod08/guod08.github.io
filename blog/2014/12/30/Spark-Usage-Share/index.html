
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Spark使用经验分享 - Dong Guo's Blog</title>
  <meta name="author" content="Dong Guo">

  
  <meta name="description" content="Spark是一个基于内存的分布式计算engine，最近1-2年在开源社区(github)和工业界非常火，国内的一些公司也搭建自己的spark集群。典型的应用场景是大数据上的机器学习模型的训练以及各种数据分析。下面是我理解的spark的优势: Spark使得分布式编程更简单 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://dongguo.me/blog/2014/12/30/Spark-Usage-Share">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Dong Guo's Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Dong Guo's Blog</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:dongguo.me" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Spark使用经验分享</h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-12-30T23:01:39+08:00" pubdate data-updated="true">Dec 30<span>th</span>, 2014</time>
        
        
           | <a href="#comments">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p><a href="https://spark.apache.org/">Spark</a>是一个基于内存的分布式计算engine，最近1-2年在开源社区(<a href="https://github.com/apache/spark">github</a>)和工业界非常火，国内的一些公司也搭建自己的spark集群。典型的应用场景是大数据上的机器学习模型的训练以及各种数据分析。下面是我理解的spark的优势:</p>

<ol>
<li><p>Spark使得分布式编程更简单</p>

<p> Spark将实际分布在众多Nodes上的数据抽象成RDD(resilient distributed dataset)，使得我们可以像本地数据一样进行处理。同时，Spark提供了相比MapReduce更丰富的<a href="http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations">API</a>，相比MapReduce编程更加简单。</p></li>
<li><p>Spark通过充分利用内存提高计算效率</p>

<p> 随着数据量越来越大，内存越来越便宜，使用较多的内存让（某些类型的）计算效率提升10至100倍，对很多公司来说是比较划算的。Spark和Facebook的Presto都基于这样的思想。在Spark中，你可以指定将那些在后续需要被多次使用的RDD缓存在内存中，减少了IO的开销，可以显著提高如机器学习模型训练这种需要迭代计算的应用的效率。</p></li>
<li><p>Spark提供了一整套的数据分析和计算解决方案，降低了学习和维护成本
 <img src="/images/personal/engineering/spark/spark-components.png" alt="" /></p>

<ul>
<li>Spark本身支持做batch的计算，比如每天机器学习模型的训练，各种数据的处；</li>
<li>Spark Streaming可以用来做realtime计算和数据处理，Spark Streaming的<a href="https://spark.apache.org/docs/1.1.1/streaming-programming-guide.html">API</a>和Spark的比较类似，其实背后的实现也是把一段段的realtime数据用batch的方式去处理；</li>
<li>MLlib实现了常用的机器学习和推荐算法，可以直接用或者作为baseline；</li>
<li>Spark SQL使得可以通过SQL来对Hive表，Json文件等数据源进行查询，查询会被转变为一个Spark job；</li>
<li>还有GraphX, 我没有用过，其用于一些图相关的计算；<br></br></li>
</ul>
</li>
<li><p>Spark可以和MapReduce通过YARN共享机器资源
 <img src="/images/personal/engineering/spark/spark-mr-yarn.png" alt="" /></p>

<p> 所有的存储(HDFS)，计算，内存资源都可以共享</p></li>
</ol>


<h2>个人使用Spark的一些经验总结</h2>

<ol>
<li><p>理解spark application的运行原理， 可以避免犯很多错误
 <img src="/images/personal/engineering/spark/driver-executors.png" alt="" />
 Driver中涉及到RDD操作的代码（比如RDD.map{}中的代码）需要Serialize后由Driver所在的Node传输给Executors所在的Nodes，并做Deserialize后在executors上执行，RDD操作中涉及到的数据结构，比如map中用到了一个user_id &ndash;> user_profile的hashtable，也需要由Driver所在的Node传输给Executors所在的Nodes。理解了这点就可以更好理解下面2点分享</p></li>
<li><p>保证Rdd操作中的代码都是可序列化的，否则会有NonSerializableException</p>

<p> 一种常见的错误是，在rdd1.map{objectOfClassA.fun}中，对象objectOfClassA所属的类ClassA需要是可序列化的，这也以为ClassA中用到的所有成员属性都是可序列化的。如果classA使用的某个成员属性无法序列化（或者标识为Serializable），scala中可以通过@transient关键字标明序列化ClassA时不序列化该成员变量。推荐stakoverflow的2个讨论：<a href="http://stackoverflow.com/questions/24224392/why-does-spark-throw-notserializableexception-org-apache-hadoop-io-nullwritable">link1</a> <a href="http://stackoverflow.com/questions/22592811/task-not-serializable-java-io-notserializableexception-when-calling-function-ou/22594142#22594142">link2</a></p></li>
<li><p>正确地使用广播变量(broadcast variables)</p>

<p> 如果我们有一份const数据，需要在executors上用到，一个典型的例子是Driver从数据库中load了一份数据dbData，在很多RDD操作中都引用了dbData，这样的话，每次RDD操作，driver node都需要将dbData分发到各个executors node一遍（分享1中已经介绍了背景），这非常的低效，特别是dbData比较大且RDD操作次数较多时。Spark的广播变量使得Driver可以提前只给各个executors node传一遍（spark内部具体的实现可能是driver传给某几个executors，这几个executors再传给其余executors）。使用广播变量有一个我犯过的错误如下：
 <pre><code> val brDbData = sparkContext.broadcast(dbData) //broadcast dbDataA, and name it as brDbData
 val dbDataB = brDbData.value //no longer broadcast variable
 oneRDD.map(x=>{dbDataB.getOrElse(key, -1); …})</code></pre>
 第一行将dbData已经广播出去且命名为brDbData，一定要在RDD操作中直接使用该广播变量，如果提前提取出值，第三行的RDD操作还需要将dbData传送一遍。正确的代码如下
 <pre><code> val brDbData = sparkContext.broadcast(dbData) //broadcast dbDataA, and name it as brDbData
 oneRDD.map(x=>{brDbData.value.getOrElse(key, -1); …})</code></pre></p></li>
<li><p>使用yarn-client或者yarn-cluster模式运行spark应用之前，在IDE中配置spark local模式调试以及测试好代码</p>

<p> spark的yanr-client或者yarn-cluster模式做一次测试比较耗时，因为涉及到代码打包以及上传。在IDE（推荐IntelliJ）中配置local模型用于debug和测试，将显著提升开发和测试效率；</p>

<p> 在VM option中配置：&#8221;-Dspark.master=local -Dspark.app.name=Test -Xmx2G&#8221; (also increase maximal memory for Heap)
 <img src="/images/personal/engineering/spark/spark-mr-yarn.png" alt="" /></p></li>
<li><p>充分利用spark的并行性</p>

<p> 理想的情况是整个代码的逻辑是对一个或几个RDD做处理，这时候spark的并行性往往是充分利用的。有时候代码逻辑会更复杂，比如你需要统计一年中每一天的一些数值，由于代码逻辑比较复杂，一种简单的“偷懒”方式是用一个for循环，在for循环内部做RDD的操作，这种情况是要努力避免的，务必思考将不同date的统计并行化。我写过的两个应用中都遇到了这种情况：优化之后速度提升非常明显。</p></li>
<li><p>使用cache()操作</p>

<p> cache RDD需要考虑自己有多少内存，对于后续不需要多次使用的RDD不要cache，如果内存有限却又指定要cache，大量的时间将被花在memory和disk的in-out上</p></li>
<li><p>为spark-submit选择合适的参数</p>

<p> <a href="http://spark.apache.org/docs/latest/submitting-applications.html">spark-submit</a>用于提交spark job，其可配置为job申请多少资源，包括Driver的内存和cpu，executor的个数，每个executor的内存，cpu和线程数。如果使用yarn做资源管理，只有内存是硬性占有的，一个job过多地申请内存，将会有资源浪费，可能会使别的job因为申请不到足够的内存无法跑。可以用JMX(Java Management Extension)来监控你的spark job到底消耗多少内存，可以指导你申请合适的内存大小。</p></li>
<li><p>Spark可以访问众多的数据源：比如HDFS, HBase, Cassandra或者Hive表（Hive on Spark)， 直接得到一个RDD用作后续处理</p></li>
</ol>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Dong Guo</span></span>

      








  


<time datetime="2014-12-30T23:01:39+08:00" pubdate data-updated="true">Dec 30<span>th</span>, 2014</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/big-data/'>big_data</a>, <a class='category' href='/blog/categories/engineering/'>engineering</a>, <a class='category' href='/blog/categories/spark/'>spark</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2014/12/16/Machine-Learning-talks-from-me/" title="Previous Post: Slides of some Machine Learning talk I shared in Hulu">&laquo; Slides of some Machine Learning talk I shared in Hulu</a>
      
      
        <a class="basic-alignment right" href="/blog/2015/02/12/cookies-matching-introduction/" title="Next Post: 在线广告中的cookie matching">在线广告中的cookie matching &raquo;</a>
      
    </p>
  </footer>
</article>


  <section>
    <h1>Comments</h1>
    <div id="comments" aria-live="polite"><!-- Duoshuo Comment BEGIN -->
<div class="ds-thread"></div>
<script type="text/javascript">
    var duoshuoQuery = {short_name:"guod08"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = 'http://static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>
<!-- Duoshuo Comment END -->
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Dong Guo</h1>
  <p>滴滴打车-高级算法工程师 (策略设计|机器学习|优化方法). 
  <br></br>Previously at Hulu and Baidu. Graduated from Tsinghua University.
  <br></br>
  Email: guod08[at]gmail.com<br> 
  <a href="http://www.linkedin.com/in/dongguo1">Linkedin</a>, <a href="https://github.com/guod08/">Github</a>, <a href="http://www.slideshare.net/guo_dong">SlideShare</a> </p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/03/28/shi-yong-shadowsockske-xue-shang-wang/">使用Shadowsocks科学上网</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/24/what-i-learned-in-my-first-job/">我在第一份工作中学到了什么</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/02/druid-cluster-setup/">Druid Cluster Setup</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/12/cookies-matching-introduction/">在线广告中的cookie Matching</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/12/30/Spark-Usage-Share/">Spark使用经验分享</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/12/16/Machine-Learning-talks-from-me/">Slides of Some Machine Learning Talk I Shared in Hulu</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/11/28/programmatic-digital-advertising/">Programmatic Digital Advertising</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/09/20/ad-inventory-forecasting/">Challenges for a Word-class Ad Inventory Forecasting System</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/05/druid-introduction-and-practise/">Druid介绍与实践</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/01/01/expectation-propagation/">Expectation Propagation: Theory and Application</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Tag Cloud</h1>
  <span id="tag-cloud"><a href='/blog/categories/bayesian' style='font-size: 120.0%'>bayesian(2)</a> <a href='/blog/categories/big-data' style='font-size: 140.0%'>big_data(4)</a> <a href='/blog/categories/career' style='font-size: 120.0%'>career(2)</a> <a href='/blog/categories/computing-ads' style='font-size: 130.0%'>computing_ads(3)</a> <a href='/blog/categories/data-platform' style='font-size: 120.0%'>data_platform(2)</a> <a href='/blog/categories/engineering' style='font-size: 160.0%'>engineering(6)</a> <a href='/blog/categories/machine-learning' style='font-size: 150.0%'>machine_learning(5)</a> <a href='/blog/categories/math' style='font-size: 110.0%'>math(1)</a> <a href='/blog/categories/spark' style='font-size: 110.0%'>spark(1)</a> </span>
</section>


  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Dong Guo -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>









</body>
</html>
