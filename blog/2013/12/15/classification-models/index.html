
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Classification Models - Dong Guo's Blog</title>
  <meta name="author" content="Dong Guo">

  
  <meta name="description" content="During my past 3 years in career, following classifiers are often used for classification tasks. Typcial classifiers comparision Decision Tree &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://dongguo.me/blog/2013/12/15/classification-models">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Dong Guo's Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Dong Guo's Blog</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:dongguo.me" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Classification Models</h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-12-15T00:35:00+08:00" pubdate data-updated="true">Dec 15<span>th</span>, 2013</time>
        
        
           | <a href="#comments">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>During my past 3 years in career, following classifiers are often used for classification tasks.</p>

<h2>Typcial classifiers comparision</h2>

<p><img class="left" src="/images/personal/research/classifiers/classifiers_compare.png" width="800"></p>

<h2>Decision Tree</h2>

<p>Decision Tree is not a start-of-art model for classification or regression, and when there are huge features(say millions) it will take a long time for training.
But it may perform very well when the number of distinct features are limited, and the classification/regression task is obviously non-linear.</p>

<p>A typical scenario is multi-model fusion: you have trained multiple models for single task, and you want to generate the final prediction result using all these models.
Based on my past experiments, Decision Tree can out perform linear model(linear regression, logistic regression and so on) on many datasets.</p>

<h2>RDT, random forest, boosting tree</h2>

<p>All of these 3 models are ensemble learning method for classification/regression that operate by constructing multiple Decision Tree at training time.
For RDT(random decision tree), only part of total samples are used to training each tree. And all features are considered for splitting.</p>

<p>Similar with RDT, random forest also use part of total sampels to construct each tree, but it also only use subset of features/dimisions for splitting.
So random forest introduces more &lsquo;random&rsquo; factors for training, and it may perform better when there are more noises in training set.</p>

<p>boosting tree is actually forward stagwise additive modeling with decision tree as base learner. And if you choose exponential loss function, then boosting tree becauses Adaboost with decision tree as base learner.
Here is one <a href="http://www.slideshare.net/guo_dong/additive-model-and-boosting-tree">slide</a> about additive model and boosting tree.</p>

<h2>Generalized linear model</h2>

<p>One of the most popular generalized linear model is logistic regression, which is generalized linear model with inversed sigmoid function as the link function.
There are multiple different implementation for logistic regression, and here are some often used by me.</p>

<h4>Logistic regression optimized with SGD.</h4>

<p>It&rsquo;s very basic, so I ignore the details here</p>

<h4>OWLQN</h4>

<p>It was proposed by Microsoft in paper <a href="http://research.microsoft.com/en-us/downloads/b1eb1016-1738-4bd5-83a9-370c9d498a03/">Orthant-Wise Limited-memory Quasi-Newton Optimizer for L1-regularized Objectives</a> of ICML 2007. You can also find the source code and executable runner via this link.</p>

<p>This model is optimized by a method which is similar with L-BFGS, but can achieve sparse model with L1 regularizer. I recommend you try this model and compare with other models you are using in your dataset.
Here are four reasons:</p>

<ol type="a">
<li>It&rsquo;s fast, especially when the dataset is huge;</li>
<li>It can generate start-of-art prediction results on most dataset;</li>
<li>It&rsquo;s stable and there are few parameters need to be tried. Actaully, I find only regularization parameters can impact the performance obviously;</li>
<li>It&rsquo;s sparse, which is very important for big dataset and real product. (Of course, sparse is due to L1 regularizer, instead of the specific optimization method)</li>
</ol>


<p>One problem is it&rsquo;s more challenge to implement it by yourself, so you need spend some time to make it support incremental update or online learning.</p>

<h4>FTRL</h4>

<p>It was proposed by Google via paper <a href="http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/41159.pdf">
Ad Click Prediction: a View from the Trenches</a> in 2013. I tried on my dataset, and this implementation can generate similar prediction performance with OWLQN.
It&rsquo;s quicker than OWLQN for training, and it&rsquo;s also sparse. One advantage is it&rsquo;s very easy to implement, and it support increamental update naturally.
One pain point for me is this model has 3-4 parameters need to be chosen, and most of them impact the prediction performance obviously.</p>

<h4>Ad predictor</h4>

<p>This <a href="http://research.microsoft.com/pubs/122779/adpredictor%20icml%202010%20-%20final.pdf">paper</a> was also proposed by Microsoft in ICML 2009.</p>

<p>One biggest different with upper 3 implementation is it&rsquo;s based on bayesian, so it&rsquo;s generative model. Ad predictor is used to predict CTR of sponsor search ads of Bing, and on my dataset, it could also achieve comparable prediction performance with OWQLN and FTRL.
Ad predictor model the weight of each feature with a gaussian distribution, so it natually supports online learning. And the prediction result for each sample is also a gaussian distribution, and it could be used to handle the exploration and exploitation problem.
See more details of this model in another <a href="http://guod08.github.io/me/blog/2013/12/01/bayesian-ctr-prediction-for-bing/">post</a>.</p>

<h2>Neural Network</h2>

<p>ANN is so slow for training, so it&rsquo;s tried only when the dataset is small of medium. Another disadvantage of ANN is it&rsquo;s totally blackbox.</p>

<h2>SVM</h2>

<p>SVM with kernel is also slow for training. You can try it with <a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">libsvm</a>.</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Dong Guo</span></span>

      








  


<time datetime="2013-12-15T00:35:00+08:00" pubdate data-updated="true">Dec 15<span>th</span>, 2013</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/machine-learning/'>machine_learning</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2013/12/02/gaussian-and-truncated-gaussian/" title="Previous Post: Gaussian and Truncated Gaussian">&laquo; Gaussian and Truncated Gaussian</a>
      
      
        <a class="basic-alignment right" href="/blog/2014/01/01/expectation-propagation/" title="Next Post: Expectation Propagation: Theory and Application">Expectation Propagation: Theory and Application &raquo;</a>
      
    </p>
  </footer>
</article>


  <section>
    <h1>Comments</h1>
    <div id="comments" aria-live="polite"><!-- Duoshuo Comment BEGIN -->
<div class="ds-thread"></div>
<script type="text/javascript">
    var duoshuoQuery = {short_name:"guod08"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = 'http://static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>
<!-- Duoshuo Comment END -->
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Dong Guo</h1>
  <p>滴滴打车-高级算法工程师 (策略设计|机器学习|优化方法). 
  <br></br>Previously at Hulu and Baidu. Graduated from Tsinghua University.
  <br></br>
  Email: guod08[at]gmail.com<br> 
  <a href="http://www.linkedin.com/in/dongguo1">Linkedin</a>, <a href="https://github.com/guod08/">Github</a>, <a href="http://www.slideshare.net/guo_dong">SlideShare</a> </p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/07/25/di-di-tong-yong-mo-xing-zu-qing-ni-ru-huo/">滴滴打车-通用模型组请你入伙</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/07/18/wo-zai-di-di-yu-dao-de-ji-zhu-tiao-zhan/">我在滴滴遇到的技术挑战</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/28/shi-yong-shadowsockske-xue-shang-wang/">使用Shadowsocks科学上网</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/24/what-i-learned-in-my-first-job/">我在第一份工作中学到了什么</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/02/druid-cluster-setup/">Druid Cluster Setup</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/12/cookies-matching-introduction/">在线广告中的cookie Matching</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/12/30/Spark-Usage-Share/">Spark使用经验分享</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/12/16/Machine-Learning-talks-from-me/">Slides of Some Machine Learning Talk I Shared in Hulu</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/11/28/programmatic-digital-advertising/">Programmatic Digital Advertising</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/09/20/ad-inventory-forecasting/">Challenges for a Word-class Ad Inventory Forecasting System</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/05/druid-introduction-and-practise/">Druid介绍与实践</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/01/01/expectation-propagation/">Expectation Propagation: Theory and Application</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/15/classification-models/">Classification Models</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/02/gaussian-and-truncated-gaussian/">Gaussian and Truncated Gaussian</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/01/bayesian-ctr-prediction-for-bing/">Bayesian CTR Prediction of Bing</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/11/12/distributed-system-theory/">Notes for Distributed System Theory</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/10/20/shi-jian-guan-li/">更高效地工作学习</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Tag Cloud</h1>
  <span id="tag-cloud"><a href='/blog/categories/bayesian' style='font-size: 120.0%'>bayesian(2)</a> <a href='/blog/categories/big-data' style='font-size: 140.0%'>big_data(4)</a> <a href='/blog/categories/career' style='font-size: 120.0%'>career(2)</a> <a href='/blog/categories/computing-ads' style='font-size: 130.0%'>computing_ads(3)</a> <a href='/blog/categories/data-platform' style='font-size: 120.0%'>data_platform(2)</a> <a href='/blog/categories/engineering' style='font-size: 160.0%'>engineering(6)</a> <a href='/blog/categories/machine-learning' style='font-size: 150.0%'>machine_learning(5)</a> <a href='/blog/categories/math' style='font-size: 110.0%'>math(1)</a> <a href='/blog/categories/spark' style='font-size: 110.0%'>spark(1)</a> </span>
</section>


  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Dong Guo -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>









</body>
</html>
