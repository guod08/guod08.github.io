<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Dong Guo's Blog]]></title>
  <link href="http://dongguo.me/atom.xml" rel="self"/>
  <link href="http://dongguo.me/"/>
  <updated>2017-10-18T18:12:59+08:00</updated>
  <id>http://dongguo.me/</id>
  <author>
    <name><![CDATA[Dong Guo]]></name>
    <email><![CDATA[-----------------------]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[批判性思维-读书感想]]></title>
    <link href="http://dongguo.me/blog/2017/10/18/critical-thinking/"/>
    <updated>2017-10-18T16:52:23+08:00</updated>
    <id>http://dongguo.me/blog/2017/10/18/critical-thinking</id>
    <content type="html"><![CDATA[<p>最近看完了2本批判性思维的书，一本是<a href="https://book.douban.com/subject/26278795/">《批判性思维》</a>，另一本是<a href="https://book.douban.com/subject/20428922/">《学会提问》</a>（更推荐）。我感觉CRITICAL THINKING是职场以及生活中重要的素质，推荐大家都读读。</p>

<h3>故事的起源：人的学习与批判性思维的必要性</h3>

<p>（该部分纯YY）</p>

<p>我理解人类学习的主要方式是归纳演绎：从事件的重复中总结出规律，包括聚类、分类、回归、相关性建立、等等（没错，Machine Learning就是参考这一套）。</p>

<p>Bayesian Framework：Loss Function + Prior experience + Optimization =》Posterior experience</p>

<p>Opitmization goal：Maximize Long Term Happiness</p>

<p>学习的模型可以用Bayesian来解释（实际很可能不是Bayesian），你刚出生的时候，唯一有的就是基于人类和你父母基因拥有的prior（这里是假设不是白纸一张，因为你会恐惧，知道饥饿），出生后你观察并体验了一个个事件，比如被开水烫到，被狗叫声吓到，可能是一次可能是多次，你的基因和大脑做归纳学习，从此你小心避开沸腾的液体，发出剧烈叫声的动物。又或者你在地铁站被人骗了钱，连续2次，从此你不再轻易相信乞讨者。这些经验的总结和运用，是不是让你的生活更好了？我相信基因和进化论。</p>

<p>归纳出“经验/知识”后，你会有一个Cost Function，来评估如果一件事又发生（如再次被狗咬到），自己要付出的代价，来辅助你决定是不是要绕道3KM。</p>

<p>决策的优化目标是什么？可能是最大化个人的幸福感，包括了财富、健康、成长、情感等等。如何做的优化？</p>

<p>所以，人类从看到听到的论述中，吸收并影响自己的判断，是一套百万年下来科学合理，符合自身和种族生存繁衍的策略。但是问题来了，现代社会（特别是互联网爆发后）的媒体、网络、线下传播中存在比以往多得多的信息，尤其是不客观严谨的信息（原因之一是商业带来的逐利性），这是最近10年发生的巨大变化，样本不再同质（noise和fake样本也更多了），之前累积的人生经验不能指导人做出人生价值最大化判断，样本我们要做一轮批判性思考的过滤，再拿进来re-training自己的思维和认知。</p>

<p>这就是我理解的需要批判性思维很重要的原因：保证自己不受垃圾和欺骗性信息的误导，养成独立思考的习惯。</p>

<p>从功利的角度，具有好的批判性思维是职场发展的必修课。这是我觉得大佬与职员存在的主要差异之一。</p>

<h3>不靠谱论证出现的原因</h3>

<ul>
<li>人性：人往往喜欢和自己价值观取向类似的人或观点，有选择性</li>
<li>价值观影响判断，不同人价值观有差异</li>
<li>不熟悉问题或领域</li>
<li>讲述者存在利益相关（得到利益或者利益有损），导致立场不客观</li>
<li>欺骗性信息太多了（各个公司的公关团队、广告、政治媒体）</li>
<li>数字游戏(绝对值vs相对值、呈现方式、平均数vs中位数)</li>
</ul>


<h3>知识和经验</h3>

<ul>
<li>知识：论证分为演绎推论和非演绎推论，后者都是在支持论证，但不能证明论点</li>
<li>知识：第一关注论述这的结论是什么，第二关注他得到该结论的理由</li>
<li>知识：典型论证方式：直觉、个人或他人观察或经验、专家、实验、研究报告、类比；</li>
<li>知识：听到某个论证，人的思维更倾向于”我是否赞同“，而不是”是否符合逻辑&#8221;</li>
<li>辩证：利弊：大部分事情不是非黑即白，往往要从不同情景、不同约束，不同价值观的角度辩证地看，想想是否有负面效果和代价</li>
<li>辩证：解决方案：事情常常不只有2种解决方案</li>
<li>辩证：起因：事情往往是由多种原因联合引起的结果，这些原因共同起作用创造了事情发生所需要的整体环境。特别是和人类特征或活动相关的</li>
<li>原则：批判性交流的过程中注意保持谦逊的、客观的立场。不是为了抓住别人的漏洞，是探求客观和真理</li>
<li>原则：批判性有一致的标准，对人对己</li>
<li>技巧：所有的非演绎推论都是不完整的，不要阻止你形成任何观点；小心求证，有足够信息就大胆决策</li>
<li>技巧：不要被问题或者立场困住，想想作者想解决什么问题，针对该问题是不是有更好的解决方案？不要就问题答问题</li>
<li>技巧：谁想要说服你 就有义务说清楚</li>
<li>技巧：说服的三种方式：背景名声成就说服、情感共鸣、逻辑论证（第三种反而困难）</li>
<li>留意：注意论证中存在的假设，典型的有价值观假设、事件的背景、相关方背景</li>
<li>留意：价值观假设：安全vs效率，自由vs平等，诚实vs和谐人际关系，集体vs个人，竞争vs合作，媒体自由vs国家安全，秩序vs言论自由，理性vs活力，责任，安全，纪律</li>
<li>警惕：小心修辞（“高达”，名词换名称），贬抑</li>
<li>警惕：几乎任何一个你收到的信息都有一个目的</li>
<li>警惕：一切主观性和情感色彩、名词定义（“新”vs“旧系统”，）反复想想作者的用词你真的知道准确含义吗 可以量化吗  作者的理解一定和你一样吗？ 作者利益相关吗？价值观一致吗</li>
<li>警惕：提防用词含糊歧义抽象不精确：用词含糊不准确，往往有主观动机，特别是有情感色彩的用词。 例子： “措施”、“见效“、“居高不下”、“日渐严重”</li>
<li>警惕：数字和图表是很容易说谎的：数字游戏(绝对值vs相对值、呈现方式、平均数vs中位数)、仅知道均值不知道分布带来的误导（方差可能很大）、图表的呈现方式</li>
<li>警惕：严谨的AB测试很难 往往有漏洞（不同质 选择偏置、统计意义、显著性、其他干扰因素），所以小心提防</li>
<li>警惕：我们所“见”都是经过一系列的价值观、偏见、态度、期望值、经验误差过滤后剩下来的东西</li>
<li>警惕：研究报告：注意主观性、立场倾向性、利益相关性、论证严谨性、是否过期、调研措辞有引导性</li>
<li>警惕：专家：小心利益相关，价值观，是否足够专业</li>
<li>警惕：类比：很形象，有煽动力，不过要判断是否是合适的类比</li>
<li>警惕：判断是否有重要信息被忽略：如只讲优点没有将代价。记住很少有事情是有百利无一害</li>
</ul>


<h3>总结出一些应该问什么问题？</h3>

<ol>
<li> 全面性：这个行动潜在的长期的负面效果是什么？有什么成本和代价？</li>
<li> 证据严谨：数据从哪来的？实验如何做的？如何证明？结果有统计意义吗？是随机分组吗？</li>
<li> 利益相关：你和这个事情是什么关系</li>
<li> 追问结论：所以呢？so what？（通常是论述者没有讲到论点，或者隐藏了论点）</li>
<li> 追问理由：为什么你这么认为？（通常是没有提到理由）</li>
<li> 避免歧义：你说的XXX具体定义是什么？（避免歧义或者理解不一致）</li>
<li> 确认假设：你这个论点中是不是包含了什么假设？（价值观）</li>
<li> 价值观假设：为什么你觉得XX一定比YY更重要？</li>
<li> 证据严谨：你这个xxx是得到广泛认可的吗？得到专业认可了吗？什么专业来源？</li>
<li> 证据严谨你这个例子具有代表性吗？</li>
<li> 多种原因：有没有别的原因导致XXX</li>
<li> 逻辑：你这是相关性还是因果性？如何证明是因果性？</li>
<li> Miss info：有没有被忽略掉没讲的重要信息？</li>
</ol>


<h3>典型的谬论</h3>

<ol>
<li> 人身攻击谬论：不论证事情 给人扣帽子，对人不对事</li>
<li> 滑坡谬误：假设采取提议的行动会引发一系列不可控的不利事件，而事实上却并非不可控</li>
<li> 追求完美解决方案谬误：假设因为尝试某种解决方案后还有遗留问题未解决，那么这种解决方案根本就不应该采用</li>
<li> 偷换概念谬误：</li>
<li> 诉诸公众谬误：引述大部分人都持有这观点的说法来竭力证明某个论断有道理。错误地认为大部分人喜欢的一切就是有道理的</li>
<li> 诉诸可疑权威谬误：引用某一权威的话来证明论证。但该权威并不够权威，或者对这一论题本身并没有特别的专业知识</li>
<li> 诉诸情感谬误：使用强烈情感色彩的语言来分散读者或听众的注意力，而忽略了理由和证据。典型的有：害怕、希望、爱国主义、怜悯</li>
<li> 光环效应谬误：使用模糊的 引发人们强烈情感认同的美德词汇，使我们倾向于同意而不去仔细检查理由</li>
<li> 稻草人谬误：歪曲对方的观点，使它容易受到攻击。</li>
<li> 虚假的两难选择谬误：本来存在多种选择，却假设只有两种解决方案。典型的就是A和B可以兼而有之 不是只能取一</li>
<li> 乱扣帽子谬误：错误地假设因为你为特定事件或行为取了一个名称，你就合情合理地解释了这一事件</li>
<li> 转移话题谬误：插入一个不相干的话题，转移注意力，导致原主题被置之不理。</li>
<li> 循环论证谬误：推理过程中假设自己的结论成立的论证</li>
<li> 以偏概全谬误：样本少，非典型，选择偏置，不具有代表性</li>
<li> 强求确定性谬误：要求研究论证必须100%确定</li>
<li> 错误类比谬误：类比对象存在重要而又相关的不同点</li>
<li> 过度简化因果关系谬误：过分强调这些因素中的一个或多个因素的作用</li>
<li> 事后归因谬误：由于时间上先后发生，就判定有因果性。很多迷信的直接原因</li>
<li> 错置举证责任：不恰当地将举证责任分配给争议的某一方（判断哪一方有举证责任）</li>
<li> 错误类比谬误：提出一个类比，其中缺存在重要而又相关的不同点</li>
<li> 因果关系谬误：相关性 ！= 因果性</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2017国庆-北疆自驾]]></title>
    <link href="http://dongguo.me/blog/2017/10/07/xinjiang-travel/"/>
    <updated>2017-10-07T22:56:57+08:00</updated>
    <id>http://dongguo.me/blog/2017/10/07/xinjiang-travel</id>
    <content type="html"><![CDATA[<p>16年端午被老司机带着自驾甘肃，16年国庆节（家属基本不开车）自驾云南，17年五一自驾德国，刚刚过去的17年国庆自驾了北疆。下面是我北疆走的路线</p>

<p><img src="http://dongguo.me/images/personal/xinjiang/roadmap.png" alt="" /></p>

<h2>北疆自驾Tips：</h2>

<ol>
<li>证件：去北疆的部分区域需要边防证（比如喀纳斯），无需出发前办理（比较麻烦），景点办理比较方便，比如喀纳斯游客中心1分钟就办好了，就是一张纸</li>
<li>交通和车：北疆的路都很好开，无需SUV，更无需越野。乌鲁木齐比较堵，其余都一路畅通，绝大部分路段车都很少。另外除了选择从乌鲁木齐租车自驾，新疆有全国省份<a href="https://baike.baidu.com/item/%E6%96%B0%E7%96%86%E6%9C%BA%E5%9C%BA/20423931?fr=aladdin">最多的机场</a>（19个），可以飞到喀纳斯，适合时间紧张的行程</li>
<li>气候：国庆去北疆刚好赶上秋天的尾巴，白桦树金黄，风景很好，但是今年国庆中间几天北疆雨雪较多，特别是喀纳斯，2-4号都在下雨下雪，建议过去之前关注天气，协调好行程</li>
<li>餐饮：符合预期，城市或景点之间常常有300KM，最好自备食物在车里</li>
<li>加油：北疆行程中服务区确实比较少，很多都不能加油，不过也没有部分游记中写的那么紧张，在停靠的主要城市加油即可（乌鲁木齐、克拉玛依、布尔津、富蕴等）</li>
<li>安全性：全程感觉很安全，到处都是安检和警察亭，感觉很安全</li>
<li>喀纳斯tips：都是从布尔津县出发，自驾3小时左右达到换乘中心贾登峪，在这里停车买票。浏览点有3个：狭义上的喀纳斯（包括喀纳斯湖，贾登峪与喀纳斯游客中心之间30KM路程上的风景，包括3个著名的湾），禾木，白哈巴。白哈巴：从贾登峪坐区间车1.5小时到游客中心，再坐区间车1.5小时到白哈巴；也看到有人徒步去，目测大概需要半天时间，应该是不错的体验。禾木：应该是可以在贾登峪直接做区间车的，也看到有人徒步，应该是更棒的体验方式</li>
</ol>


<h2>概要行程</h2>

<ol>
<li>第1天：北京直飞乌鲁木齐，提前预定了神州租车，下了飞机提车（国庆价格比平时贵了2-3倍，比滴滴的动态加价猛多了，为啥没有群众和媒体攻击呢），入住乌市，到处都是安检（酒店、商城）</li>
<li>第2天：有雨，新疆的作息比北京晚2小时，上午出发走克榆公路直奔克拉玛依（比走G30近80KM），中途停靠一服务区加油，安检人员提醒后轮胎没气了，有点后怕，雨天后轮胎没气还开了100KM时速，幸好发现了，在加油站换了备胎继续上路。中午到达克拉玛依，天气转好，吃个饭，入住和颐酒店。对克拉玛依的印象很好，道路宽阔干净、城市现代；
<img src="http://dongguo.me/images/personal/xinjiang/ls.jpg" alt="" /></li>
<li><p>第3天：上午在附近的黑油山九龙潭转了一下，导向目的地布尔津，中午经过魔鬼城，在门口浏览一圈没有进去，阳光正好，傍晚直奔布尔津北面30KM的五彩滩，可以晚了一步，夕阳已被天边的乌云遮挡，不过五彩滩的风景还是很棒的，后面在可可托海弥补了阳光。
<img src="http://dongguo.me/images/personal/xinjiang/mgc.jpg" alt="魔鬼城门口的果树" />
<img src="http://dongguo.me/images/personal/xinjiang/wct.JPG" alt="五彩湾" /></p></li>
<li><p>第4天：从布尔津出发去喀纳斯，先到贾登峪，路上大概3个小时，有一半的路程是山路，不过路面不错不难走。达到贾登峪大概是下午2点，所有的车需要停在这里，买票，坐区间车进到喀纳斯游客中心，大概1.5小时，沿途可以看到喀纳斯几个主要的景色三湾。达到喀纳斯游客中心，我们直接做区间车去了白哈巴，行程也是1.5小时左右，到达白哈巴看到了经典的风景，很赞。
<img src="http://dongguo.me/images/personal/xinjiang/bhb.JPG" alt="" /></p></li>
<li><p>第5天：天公不作美今天有雨夹雪，非常冷，温度基本是零下，雨雪越来越大，回到喀纳斯游客中心，据说游览大巴途径经典的风景区域都不会停留，95%的人都直接坐车回贾登峪，我们也只能坐车回贾登峪，遗憾！下午打听到回布尔津的路封了，可能出不去，好在2点之后解封了，开车下山，前半程大堵车，太多车赶着下山了（如果雪继续下，有可能几天下不了山），晚上入住布尔津
<img src="http://dongguo.me/images/personal/xinjiang/kns-2.JPG" alt="" />
<img src="http://dongguo.me/images/personal/xinjiang/kns.jpg" alt="" /></p></li>
<li><p>第6天：一大早出发，开车直奔可可拓海，中途超速被拍，在可可托海镇住下（推荐，住在富蕴县城的话，一早需要开车2小时才能赶到景区）。吃到了全程感觉最好的一家维族馆子：吾苏曼江农家小院。</p></li>
<li><p>第7天：住在地方离景区只有5KM，天气很棒 阳光明媚，路上看到了最美的风景。一天在可可托海景区徒步，很爽！傍晚开车回富蕴县城，很棒的小城。
<img src="http://dongguo.me/images/personal/xinjiang/kkth-ls.jpg" alt="" />
<img src="http://dongguo.me/images/personal/xinjiang/kkth-1.jpg" alt="" />
<img src="http://dongguo.me/images/personal/xinjiang/kkth-tb.jpg" alt="" />
<img src="http://dongguo.me/images/personal/xinjiang/fuyun.JPG" alt="" /></p></li>
<li><p>第8天：开城去乌市，一路雨雪，下午3点到达，还车，酱油一下新疆博物馆。</p></li>
<li>第9天：回京，还是熟悉的味道！</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据驱动的核心：Controlled Experiments]]></title>
    <link href="http://dongguo.me/blog/2016/12/18/experiment/"/>
    <updated>2016-12-18T23:29:32+08:00</updated>
    <id>http://dongguo.me/blog/2016/12/18/experiment</id>
    <content type="html"><![CDATA[<p>越来越多人和公司认同data-drivern决策的必要性，不仅是滴滴、Google、Microsoft、Linkedin、Amazon这些科技公司，也包括传统意义上的非技术公司。Data-drivern的核心是Controlled experiment（即大家常说的A/B Testing)，按照字面理解就是将其它影响因素都control住，保持一致，实验结果只由预设的不同方案影响。</p>

<p>在滴滴算法团队，很多时间和精力都在做各种策略和算法实验，比如我们比较不同的订单分配策略哪个可以让接驾时间更短，比如评估新的动态定价策略对乘客的留存和活跃度有什么样的影响。基于近期在做实验方面遇到的一些挑战思考，以及上个周末看的几篇文章写一个小结在这里。先介绍几个controlled experiment相关的基础而重要的点，总结做controlled experiment中的一些遇到的难点和挑战，最后是一些实验方案和架构的构想。</p>

<!--more-->


<h3>1. 几个基础&amp;重要的知识点</h3>

<h4>1.1. A/A Testing</h4>

<p>A/A测试是一个比较有效的实践去检测你的实验设置中是不是有bias。AA测试一般有两种实现方法，一种就是仅在实验前做离线数据分析（AA测试并不都需要去线上做实验），另一种就是在线上setup A/B/A的实验。</p>

<h4>1.2. Hypothesis Testing</h4>

<p>A/B测试基本都需要通过假设检验计算猜想的置信度，你想证明的东西称为alternative hypothesis(&ldquo;备择假设&#8221;，比如“我的新算法比老算法能提高CTR”），反面称为null hypothesis（即“零假设”，即“我的新算法和老算法没啥差别”）。通过收集A/B实验的数据，计算B的均值X_b和A的均值X_a，计算二者的diff X_d = X_b &ndash; X_a，如果零假设成立，X_d应该较小。在假设策略A和B无明显差别的前提下，可以得到X_d服从的分布X_D，比较X_d和分布X_D，利用小概率事情一次是不会发生的思想（实际是设定置信度阈值，比如0.05），判断是接受还是拒绝零假设。（具体公式后续补充）</p>

<h4>1.3. Sociation or Causality</h4>

<p>相关性 ！= 因果性，非常重要的sense。一个经典的例子是“大量样本表明，口袋里有打火机的人得肺癌的概率显著高于口袋里没有打火机的人”</p>

<h3>2. 做Controlled experiment容易犯的错误和挑战</h3>

<p>通过AB测试产出正确的决策通常是一件非常不容易的事情，我可以很容易列举10条常见的导致产出错误结论的原因。错误的结论包括false postive（新方案无效或者有负向效果，但通过实验得出有效的结论）和false negtative（新方案有效果，但是通过实验判定无效），其中false postive相比false negative对公司伤害可能更大。常见的观点是在科技公司的算法和策略优化中，80%~90%的idea被验证是无效或者有负向效果的（见Microsoft这篇文章【3】的5.1小节）</p>

<h4>2.1. 几条典型的产出错误结论的原因</h4>

<ol>
<li>AB流量划分不随机：比如用用户ID最后一位数字做分流，事后才发现该ID并不随机。可通过对数据源深入了解分析和AA测试来减少这方面的错误</li>
<li>AB流量划分随机，但是control或treatement会影响对方的流量，导致对比结果的不可信</li>
<li>错误的指标选取：比如有时业务指标（KPI）很难量化，选择的“近似”可量化的指标实际相比业务指标差很远</li>
<li>实验结果未达到足够的置信度就宣布结论：看p-value，多break down指标看细节</li>
<li>线下线上分流没有对齐：实验设计、代码开发、指标选取都没有问题，但是由于离线用日志评估结果时未使用和线上一致的分流方案（典型的原因是没有将分流标志写入日志，离线只能按照口头约定的逻辑重新实现分流逻辑，常发生在开发和指标统计不是一个团队时），必然导致统计结果有偏差</li>
<li>实验期间外部因素干扰了实验结果，比如天气或特殊事件</li>
<li>任何一个环节的bug</li>
<li>实验本身很完美，但是你的（或者老板给你定的）KPI错了</li>
</ol>


<h4>2.2. 挑战1：设计合适的AB流量划分方案</h4>

<p>常见的流量划分方法有这么几种：按照某种ID进行随机划分（比如用户ID、session ID、cookie ID），按照时间片进行划分（比如每半个小时进行算法的轮换）、按照地理区域划分（比如将城市划分成网格，交错apply不同的算法）。</p>

<p>AB流量划分的第一点是保证划分的随机性，通过做AA测试分析基本可以保证。第二点是保证control/treatment不影响对方的流量，对于某些实验上面几种典型的流量划分方案就不可行了。假设滴滴要评估一个新的定价策略是否可以提高GMV，我们看下这几种流量划分方案：</p>

<ol>
<li>按照乘客或者订单ID随机划分：订单分配算法是全局的，所以运力/司机是2个定价策略共享的</li>
<li>按照时间片进行划分轮换：在当前时间片apply某个定价策略，可能会占用下个时间片的运力，特别是时间片较短时（比如不足一小时）影响显著，但是时间片越大时间本身引入的外界因素干扰就越大（比如不同时段的需求、运力、天气等因素的差异）</li>
<li>按照地理区域划分：同样有运力共享的问题</li>
</ol>


<p>对于这个case，如果你有好的流量划分idea非常欢迎和我交流</p>

<h4>2.3. 挑战2：确定正确的业务目标和实验指标</h4>

<p>想清楚业务优化的目标是一切的基础，比较容易犯的错误是优化了一个短期的目标，而该短期目标和长期目标常常是冲突的。错误的KPI往往有两个来源，一个是所谓的“目标分解，阶段性目标”，另一个是不了解各种指标之间存在千丝万缕联系的老大直接拍板了一个KPI（如果能在不伤害其他指标的情况下做到优化KPI当然是好的，但是老大只提了要优化KPI，没有说其他指标不能受到影响）。</p>

<p>Google在这篇文章【1】中提到了广告的投放不能仅看当下的收入，应该看长期的收益（年的粒度）。如果给用户展示了过多的广告，用户会自然地学习到对广告的blindness，之后的广告CTR会显著下降。为了度量不同的广告策略对用户长期的影响，作者设计AA &ndash;> AB &ndash;> AA实验：</p>

<ol>
<li>第一阶段（AA）：挑选两拨有相同广告体验的用户，且整体CTR差异不大</li>
<li>第二阶段（AB）：给其中一拨人B使用新的广告投放策略（即更多的广告展示），持续一段时间（文中提到是90天）</li>
<li>第三阶段（AA）：给用户群B恢复和A一致的广告体验，对比两拨人的广告CTR （这个阶段采用BB也可行）</li>
</ol>


<p>这里涉及到一个问题，用户对广告的blindness程度是受新策略作用时长影响的，这种影响可能需要数个月才能收敛，作者想去量化这种收敛后的长期影响，文中提出了2个方法，一个是用指数函数去fit CTR衰减曲线，另一个是用机器学习模型去预测（使用短期的CTR变化），作者提到google在过去几年累积了上百个广告blindness相关的样本，可以用作有监督学习。</p>

<p>我们在滴滴也犯过优化与长期目标矛盾的短期目标的错误，这里就不细讲了。</p>

<h3>3. 统一的一站式实验平台</h3>

<p>公司内部需要有一套统一的一站式实验平台，按照做实验的顺序包括：较完整指标库、实验管理、新建实验、流量管理与冲突检测、实验上线、实时监控报警、查看实验结果等。几个要点如下：</p>

<ol>
<li>正确/权威/完整/统一的指标库：每个实验都有自己的一级二级指标，全局统一且正确的指标非常关键，每次创建实验只需要从指标库中勾选需要观察的指标即可</li>
<li>全局流量管理：流量划分收敛到平台（避免由于未经协调不同的小组创建了同一份流量上创建了冲突的实验），且可以设计更高效的流量划分方案，比如Google的支持多层正交实验的平台【2】</li>
<li>实验管理/检查/分享：所有的实验及配置都可在平台上清晰地查看，有很多好处：比如每个人都有机会了解正在执行的实验，查看实验结果和结论，专业的同学可以帮忙检查实验的配置</li>
<li>创建实验无需开发，产品和运营同学也可以操作上线实验</li>
<li>实时监控及时发现问题：实验创建过程中可以配置任意metric的预期range，一旦在线上超过range自动发报警</li>
</ol>


<p>Google这篇文章【2】提出了支持不同实验在同一个domain的不同layer上overlapping的实验平台架构，值得一看。</p>

<h3>4. 实验的评审和分享</h3>

<p>创建一个公正的实验并产出可靠的结论是非常不容易的事情，在目标设定、指标选取、分流方案、外部因素考虑、置信度等任意一个方面出错都可能导致产出误导的结论。所以有一个实验review或者评审的环节就很有帮助了（文章【2】中也提到google有这样的实验委员会）。</p>

<p>除了把控实验的指标，分享&amp;讨论有趣的实验有助于stand on each others‘ shoulders，这个可以通过wiki、邮件、或者在实验平台的相关页面分享给大家。</p>

<h3>Reference</h3>

<ol>
<li><a href="http://research.google.com/pubs/archive/43887.pdf">Focusing on the Long-term: It’s Good for Users and Business</a> KDD2015</li>
<li><a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/pubs/archive/36500.pdf">Overlapping Experiment Infrastructure: More, Better, Faster Experimentation</a> KDD2010</li>
<li><a href="http://ai.stanford.edu/~ronnyk/ExPThinkWeek2009Public.pdf">Online Experimentation at Microsoft</a> 2009</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ArchSummit2016干货分享]]></title>
    <link href="http://dongguo.me/blog/2016/12/06/archsummit2016/"/>
    <updated>2016-12-06T08:58:46+08:00</updated>
    <id>http://dongguo.me/blog/2016/12/06/archsummit2016</id>
    <content type="html"><![CDATA[<p>上周去参加了<a href="http://bj2016.archsummit.com/">ArchSummit 2016</a>，是一个偏架构技术的会，也有一些talk结合了架构和算法一起介绍。我听了十几个和大数据架构和算法比较相关的talk，做了一点小结分享给大家。</p>

<h3>Highlights</h3>

<ol>
<li><p>订单分配：美团和菜鸟物流（阿里旗下）都简单介绍了自己的订单分配算法，和滴滴分单场景有近似之处。美团的外卖配送在某些方面比滴滴的分单问题更有挑战性，有一些思想可以借鉴，比如权衡体验和效率的“压单”；</p></li>
<li><p>热门的机器学习算法：</p>

<p>  GBDT + LR：腾讯微信的用户相似度预估、广告点击率预估，阿里推荐算法的点击率预估都在用。具体可以看Facebook在2014年的文章；</p>

<p>  FTRL：这个算法是google在2011年左右publish的，被国内各大公司作为online learning的重要选择，我之前实验中做过评估，其显著的几个优点：样本只需要过一遍，预测效果top，稀疏模型</p></li>
<li><p>大规模分布式机器学习框架：</p>

<p>  Parameter Server：若干公司提及，包括一些规模不太大的公司（第四范式、一点咨询），目前来看parameter server还是大规模特征下的分布式机器学习框架的首选</p>

<p>  Spark：spark简单易用，当特征规模在千万之内还是很不多，ThinkData给出自己开源的分布式机器学习算法库，据称在预测效果和训练速度上都显著优于MLlib</p></li>
<li><p>图算法：微信在做定向广告时，需要构造用户在朋友网络上的“社交相似度”特征，其使用了KDD2016最新的node2vec算法，类似Random walk + Word2vec，据称效果显著，有兴趣的可以去看paper；</p></li>
<li><p>知识图谱（Knowledge graph）：Facebook的knowledge graph将这块带的很火，在需要理解用户意图给出用户想要的结果的场景下大多会涉及。 本次有2个talk涉及：阿里的自动问答系统，一点咨询（类似今日头条）的新闻搜索；</p></li>
<li><p>深度学习：这次几个talk上提到，不过都还是在尝试，感觉没有DL在其应用中还没发挥核心作用。包括阿里的自动问答，第四范式</p></li>
<li><p>架构引擎相关，有2个talk影响较深刻，一个是阿里双十一的流量规划和压测实践（流量隔离压测 + 配比拉平可以减少直接在线上做压测的风险和人员投入成本），另一个是百度的大数据系统技术栈（百度文件系统BFS，分布式数据库Tera都已在github开源，值得学习一下）</p></li>
</ol>


<p>  <a href="http://ppt.geekbang.org/archsummit?nsukey=MGPCD1KdjIFyTTA2WehJpfsI%2BEoSPTzxdRHeqxnX8k1LsItgo6LdQLj4gOce0AUOmRLaavVtW0pSWnZ0Qt3VPo%2Fdyd1q%2BgmMjte64qRe9oCfhp23M8oMEFFKg7OsNO2aGXHKkPKEZWDb1DBSjaUXnZiRlfYhgr%2FMzH1TJc2AXwfxd%2FDzXYVIjrX485s1B0OE">slides 下载</a></p>

<!--more-->


<h2>美团：即时物流调度平台实践</h2>

<p>现状：美团外卖日订单800万，平均配送时长（从下单到送达）降到了单均28min，配送路程为2KM，28min还是比较厉害的。</p>

<h4>美团外卖配送算法在某些方面比滴滴的订单分配更复杂：</h4>

<ol>
<li>滴滴订单分配的对象是司机和乘客，而美团配送需要考虑三方（骑手、乘客、餐厅）。增加了不少复杂性，比如需要考虑商家备餐时间的不确定性和差异性</li>
<li>滴滴大部分订单都不是拼车，而美团骑车平均会一次性配送5个订单，订单匹配和组合的效率是核心问题</li>
<li>路径规划的复杂性更高（设想一个骑车同时被分配了5个订单，候选的路径数）</li>
<li>配送目的地的复杂性：外卖配送的目的地很多是小区（送达X号楼X单元X层的房间）和写字楼（楼层），应该要考虑更多的骑手个性化</li>
</ol>


<h4>美团的订单分配算法演进</h4>

<p><img src="http://dongguo.me/images/personal/archsummit/meituan.png" alt="" /></p>

<p>这里的“压单”是等待更多类似的订单，聚合起来一起分配给骑手。有点类似滴滴的拼车等待</p>

<p>在用的几个重要平台：场景回放平台、算法仿真环境（派单场景下）、分布式计算平台</p>

<h2>微信朋友圈基于社交相似度的定向广告技术</h2>

<p>简介：lookalike是一种经典的广告定向技术，指的是找出和指定目标人群类似的人群。微信使用了包含图特征的有监督学习找出的目标微信用户做广告定向，相比广告随机投放给active用户，可以提高2-3倍的点击率。</p>

<h4>算法概况：目标是预估指定用户和另一个微信用户的相似度</h4>

<ol>
<li>训练样本的label获取：找出公共展示广告较多的用户pair，计算其相似度：共同点击广告个数/共同展示的广告个数</li>
<li>使用了用户pair之间的社交相似性特征，通过node2vec network embedding算法生成</li>
<li>机器学习模型：SVR，GBDT+LR都做了尝试</li>
</ol>


<h4>使用node2vec生成社交相似度特征</h4>

<p>node2vec = Biased Random Walk + Word2Vec
node2vec in KDD 2016： <a href="http://www.kdd.org/kdd2016/papers/files/rfp0218-groverA.pdf">http://www.kdd.org/kdd2016/papers/files/rfp0218-groverA.pdf</a>
强调了调参（网络深度和广度参数p、q）的重要性</p>

<h4>GBDT+LR组合模型（通过GBDT学习出高区分性的组合特征，输入到LR中）</h4>

<p><img src="http://dongguo.me/images/personal/archsummit/weixin.png" alt="" />
Paper from Facebook：<a href="http://www.quinonero.net/Publications/predicting-clicks-facebook.pdf">http://www.quinonero.net/Publications/predicting-clicks-facebook.pdf</a> (ADKDD 2014)</p>

<p>腾讯和阿里都做了尝试：<a href="http://www.cbdio.com/BigData/2015-08/27/content_3750170.htm">http://www.cbdio.com/BigData/2015-08/27/content_3750170.htm</a></p>

<h2>一点资讯：兴趣引擎-深度融合搜索和推荐</h2>

<ol>
<li><p>检索系统使用了WAND operator：<a href="http://cis.poly.edu/westlab/papers/cntdstrb/p426-broder.pdf">http://cis.poly.edu/westlab/papers/cntdstrb/p426-broder.pdf</a>
WAND泛化了AND和OR操作，是更强大的匹配操作符</p></li>
<li><p>异构索引：由于需要在几个维度（近期和长期内容、编辑精品vs抓取内容、垂直频道vs全局内容、热门推荐和个性化推荐）上兼顾搜索和推荐的效果，搞了若干个内容索引，后面会做自适应索引召回（基于对query或者用户的理解决定从哪些索引返回结果）</p></li>
<li><p>自适应索引召回策略：对Query做意图理解，决定返回的文章
除了搜索词本身，还考虑了时下热点，用户浏览搜索上下文，用户兴趣图谱，用户demography等信息
决定从哪些下游索引、服务、内容中获取结果，以及排序
<img src="http://dongguo.me/images/personal/archsummit/yidianzixun.png" alt="" /></p></li>
<li><p>树状知识图谱
提到了其在用，未透露技术细节。树状知识图谱应该是内容推荐和搜索的关键模块</p></li>
<li><p>模型训练与更新
online learning 准实时模型更新（KAFKA &ndash;> Storm &ndash;> Online Learning），声称在用Parameter server
模型使用了流行的<a href="http://www.cnblogs.com/EE-NovRain/p/3810737.html">FTRL</a>
实验框架支持feature configuration</p></li>
</ol>


<h2>阿里-智能问答系统的实践</h2>

<ol>
<li>几种主流的问答匹配技术：rule-based模板式匹配，基于检索的模型，基于统计机器翻译SMT，基于深度学习模型
阿里目前以前三者为主，基于深度学习模型在探索</li>
<li>基于检索的问答模型还是基础方案
基本是搜索的一套方法，在复杂问答场景不胜任（意图识别，上下文对话）
<img src="http://dongguo.me/images/personal/archsummit/ali-qa.png" alt="" /></li>
<li>意图识别，被抽象成分类问题解决。该部分非常有挑战性，阿里也还停留在基础阶段，深度学习被应用在该分类任务中</li>
<li>Knowledge graph有被应用</li>
<li>语义挖掘：同义语义挖掘、近似词挖掘、潜在语义分析（LSA，PLSA，LDA）</li>
<li>探索中：Deep learning、Transfer learning、Reinforcement learning</li>
</ol>


<h2>ThinkData：Fregata- Spark上的轻量级大规模机器学习算法库</h2>

<p>已开源：<a href="https://github.com/TalkingData/Fregata">https://github.com/TalkingData/Fregata</a></p>

<p>基于Spark实现的分布式机器学习算法库，目前只有几个基础的模型(LR、softmax、RDT)，声称相比MLlib有更快的训练速度和更好的模型效果。</p>

<h4>几个点评：</h4>

<ol>
<li>提出了基于SGD改进的GSA（Greedy Step Averaging）优化算法（出发点是解决SGD等常见的优化算法需要选择learning rate的问题），该算法是Fregata实验效果优于MLlib的主要原因。文章见：<a href="https://arxiv.org/pdf/1611.03608v1.pdf">https://arxiv.org/pdf/1611.03608v1.pdf</a></li>
<li>Fregata强调样本一遍过完，无需多次迭代，提高了训练速度（我理解这取决于给定算法是否需要迭代，Fregata目前实现的少数几个模型不依赖于多遍迭代）</li>
<li>Fregata对标MLlib，同基于Spark，依然没有解决训练样本特征维度过高（百万/千万级）无法训练的问题，不如Parameter Server</li>
<li>目前只实现了LR、softmax、RDT少数几个模型，且尚不兼容Spark1.6以上的版本</li>
</ol>


<h2>第四范式：其构建机器学习产品的介绍</h2>

<p>整体停下来，干货很少。提到一个GDBT计算框架，就是实现的Parameter Server。部署在HADOOP那套生态上（YARN/HDFS等）。</p>

<p>另外，第四范式在尝试Deep Sparse Network，戴总的研究方向Transfer learning声称“在研究如何应用”状态</p>

<h2>阿里巴巴-天猫双11容量规划演进</h2>

<h4>容量规划经历的几个阶段</h4>

<p><img src="http://dongguo.me/images/personal/archsummit/ali-double11.png" alt="" />
压测和容量评估，不能以“点”的方式，要做场景化压测和评估</p>

<h4>容量评估主流程：容量评估&amp;压测平台</h4>

<p>自动化，最终自动生成压测报告，例行执行；可以控制流量要求
<img src="http://dongguo.me/images/personal/archsummit/ali-double11-2.png" alt="" /></p>

<h4>流量隔离压测 + 配比拉平</h4>

<p>阿里经历过直接在线上做全链路压测，为了线上分享和人员精力消耗（“几百人坐在一起盯着自己系统”），采取了在隔离的集群上做压测（可能占全部机器资源的90%），压测完找到合理的机器分配比之后，再在全部服务器上做配比拉平
<img src="http://dongguo.me/images/personal/archsummit/ali-double11-3.png" alt="" /></p>

<h2>百度：Spider3.0背后的数据处理系统（数据库Tera，文件系统BFS）</h2>

<h4>百度整体的大数据架构技术栈<a href="https://github.com/baidu">github page</a></h4>

<p><img src="http://dongguo.me/images/personal/archsummit/baidu1.png" alt="" /></p>

<h4>整个Spider3.0处理流程（增量处理、流式处理，基本都围绕Tera数据库读写）</h4>

<p>数据爬取延迟从spider2.0的2~3天，降低到spider3.0的5分钟
<img src="http://dongguo.me/images/personal/archsummit/baidu2.png" alt="" /></p>

<h4>Tera：百度高性能分布式NoSQL数据库Tera</h4>

<ol>
<li>对标google BigTable，加强版Hbase，已开源：<a href="https://github.com/baidu/tera">https://github.com/baidu/tera</a></li>
<li>keywords：分布式、列存储，支持分布式事务，万亿条记录，百PB容量，亿级QPS读写，全局有序表，快照支持回滚</li>
<li>分布式：按照row切割成大量的Tablet，做到并发读写，Tablets灵活地分裂与合并</li>
<li>容错和备份：先写log，再写内存，再固化到磁盘</li>
</ol>


<h4>BFS：百度文件系统</h4>

<p>见：<a href="https://github.com/baidu/bfs">https://github.com/baidu/bfs</a></p>

<h2>LinkedIn：Lessons in Internet scale stream processing（海量流数据处理经验总结）</h2>

<p><img src="http://dongguo.me/images/personal/archsummit/linkedin1.png" alt="" /></p>

<h4>Apache Samza</h4>

<p>LinkedIn开源的分布式流数据处理系统，对应于Storm和Spark Streaming，号称计算性能优于MR和Spark。 目前除LinkedIn，Uber、Netflix等公司也在用Samza。
<img src="http://dongguo.me/images/personal/archsummit/linkedin2.png" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[出行的未来]]></title>
    <link href="http://dongguo.me/blog/2016/07/03/future-transportation/"/>
    <updated>2016-07-03T22:03:48+08:00</updated>
    <id>http://dongguo.me/blog/2016/07/03/future-transportation</id>
    <content type="html"><![CDATA[<p>在滴滴待了16个月了，这一篇说说我理解的未来的智能出行：</p>

<ol>
<li><p>整个城市的车辆都由一个中枢系统控制，车辆的路径规划和控制可以最大化整体城市居民的出行效率，交通拥堵从此消失；</p></li>
<li><p>车辆是自动驾驶的，所以非常安全，车内变成真正的生活空间，交通标识和信号灯也不需要了；</p></li>
<li><p>人们不再购买车，车也不再属于个人，因为在城市的任何区域任何时间1分钟内就可以呼叫到车；</p></li>
<li><p>车辆都是电动的，会自己选择合适时机去电池站更换电池。由于车辆没有驾驶室，且车辆之间可以像积木一样拼接，车辆的外形也会发生变化；</p></li>
</ol>


<p>归纳起来就是几个关键字：共享出行、电气化、汽车网联、自动驾驶</p>

<p><img src="http://dongguo.me/images/personal/transport/CAV.gif" alt="" /></p>

<p>滴滴、Uber、Google以及一众高校正在推进这一科幻版的未来场景：</p>

<p>  共享出行：其是滴滴和Uber们的原始出发点，目前中国每天有10~20M乘客通过共享的方式出行。</p>

<p>  电气化：电动车的成本显著低于汽油车，滴滴正在推动更多电动车加入车主行列；</p>

<p>  自动驾驶：这一块已经非常火了，一方便有望大大降低交通事故发生率，对于滴滴和Uber来说可以省掉司机支出极大地降低成本；</p>

<p>Automated and Connected Vehicles技术目前是研究热点，有一篇<a href="http://autocaat.org/Technologies/Automated_and_Connected_Vehicles">科普文章</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[日记2016/02/13:周志华老师的新书]]></title>
    <link href="http://dongguo.me/blog/2016/02/13/ri-ji-2016-02-13-semi-supervised-learning-Reinforcement-learning/"/>
    <updated>2016-02-13T23:38:14+08:00</updated>
    <id>http://dongguo.me/blog/2016/02/13/ri-ji-2016-02-13-semi-supervised-learning-Reinforcement-learning</id>
    <content type="html"><![CDATA[<p>明天是2016春节后的第一个工作日，新年要有新气象，其中一件就是要多写博客，将每天的想法和收获总结下来。</p>

<p>今天在石家庄家里翻了翻<a href="http://cs.nju.edu.cn/zhouzh/">周志华</a>老师的新书《机器学习》，ML基础的内容基本都包括了，讲得比较通俗易懂，公式推导比比李航的《统计学习方法》更少一些。个人还是比较推荐的。</p>

<p>重点翻了翻半监督学习和强化学习这2章。做一些笔记如下</p>

<h3>半监督学习</h3>

<p>基于“相似的样本有相似的label”的合理假设，未标记样本为样本分布提供了信息，故可以提高有监督学习的效果。</p>

<p>一种典型的半监督学习模型是TSVM（Transductive SVM），其在目标函数中包含了未标注样本的松弛向量，求解方法类似于EM思想，E步对未标注样本进行预测，M步调整分类面；一个要点是未标注样本的预测结果通常是显然不如有标注样本的label靠谱的，所以在目标函数中这2类样本的松弛向量的权重有差别，且未标注样本的权重随着多轮迭代不断上升。</p>

<h3>强化学习</h3>

<p>强化学习的应用场景很广，比如曾经很火的Flappy Bird和最近很火的Google的AlphaGo（围棋AI）。</p>

<p>明天补充细节，碎觉</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[滴滴出行-大数据策略组请你加入]]></title>
    <link href="http://dongguo.me/blog/2015/07/25/didi-strategy-team-welcome-you/"/>
    <updated>2015-07-25T23:54:06+08:00</updated>
    <id>http://dongguo.me/blog/2015/07/25/didi-strategy-team-welcome-you</id>
    <content type="html"><![CDATA[<p>滴滴是一家飞速成长的公司，业务线从最初的出租车，扩展到专车，快车，顺风车，巴士，代价等越来越多样的出行方式，业务也从国内扩展到了国内外，正在改变越来越多人的出行方式。</p>

<p>大数据策略组在<a href="http://www.cad.zju.edu.cn/home/xiaofeihe/">何晓飞</a>、<a href="http://www.yelab.net/">叶杰平</a>两位知名机器学习人工智能方向教授的带领下，正在打造智能的出行平台闭环，包括各业务线的订单分配，订单价值调节，多业务线运力和需求整合，等等。这里诚意邀请在策略算法，机器学习，数据挖掘等方向有经验的朋友加入，和世界级的大牛一起解决世界性的难题。</p>

<h4>要做的事</h4>

<p>参与最核心的订单分配项目，从数据和用户反馈中获得灵感，设计更优的订单分配策略，更准更快地匹配乘客和车辆。</p>

<h4>希望你是这样的 (实习或全职都okay的)：</h4>

<pre><code>1.  扎实的计算机基本，熟悉几门常用的编程语言（C++, Scala, Python等），动手能力强，数据结构和算法基础好。
2.  在机器学习、数据挖掘或相关方向有不错的理论和实践积累
3.  能够承担压力，快速上手，适应较快的项目节奏
</code></pre>

<h4>待遇</h4>

<p>滴滴今年的待遇我了解是高于BAT的，对大牛更是不手软，欢迎来聊。</p>

<h4>有兴趣欢迎联系我：<a href="&#109;&#x61;&#105;&#x6c;&#116;&#111;&#58;&#x67;&#x75;&#111;&#100;&#111;&#110;&#x67;&#x40;&#x64;&#105;&#x64;&#105;&#x63;&#104;&#x75;&#120;&#105;&#110;&#103;&#46;&#x63;&#111;&#x6d;">&#103;&#117;&#111;&#100;&#x6f;&#110;&#103;&#x40;&#x64;&#x69;&#100;&#105;&#x63;&#104;&#x75;&#120;&#x69;&#110;&#x67;&#46;&#x63;&#x6f;&#x6d;</a></h4>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[我在滴滴遇到的技术挑战]]></title>
    <link href="http://dongguo.me/blog/2015/07/18/wo-zai-di-di-yu-dao-de-ji-zhu-tiao-zhan/"/>
    <updated>2015-07-18T11:44:53+08:00</updated>
    <id>http://dongguo.me/blog/2015/07/18/wo-zai-di-di-yu-dao-de-ji-zhu-tiao-zhan</id>
    <content type="html"><![CDATA[<p>加入滴滴打车3个半月，感觉遇到和解决的技术问题超过之前1年的。写在这里给大家分享。</p>

<p>滴滴这边负责所有策略算法设计的是“策略组”，大概有20几个员工。由于滴滴的业务线越来越多（出租车，专车，快车，顺风车拼车，大巴），项目上线时间紧，没有时间对策略算法做最好的设计和优化。于是，新成立了一个通用模型组，目标是抽取出不同业务线的共同点，在一个更高的角度设计更好的策略算法，特别是提供通用的大规模机器学习支持。我是这个team第一个员工。</p>

<h3>订单分配：</h3>

<p>滴滴一个技术重点是订单分配，全国每天有几百万的乘客通过滴滴叫车出行，有近百万司机接滴滴的订单，如何将订单分配给司机使得更多的人更快地打到车？至少有如下问题需要考虑：</p>

<ol>
<li>从大的层面，如何设计一套分配策略，能够保证目标最大？</li>
<li>从小的层面，分配订单时应该考虑到哪些因素？（距离？是否顺路？司机习惯偏好？天气？供求关系) 这些因素如何组合？</li>
<li>如何在更长的时间维度上做更优的分配？（比如，当前时刻将乘客A分给司机B是最优的，但几秒之后司机C出现了，司机C离乘客A要近得多）</li>
<li>拼车更环保也能帮乘客省钱，如何在订单分配中让尽可能多的人在保证体验的同时拼上车？<a href="http://www.trb.org/AboutTRB/AboutTRB.aspx">TRB</a>中有非常多的文献</li>
<li>乘客加价如何影响订单分配？</li>
<li>我们应该学习Uber的一些策略吗？（比如播单不告诉司机乘客的目的地）</li>
</ol>


<p>在创业初期，可以用规则快速简单地实现，现在滴滴已经初步有了一套理论上保证收益的分配策略，需要我们进一步去优化效果和效率。</p>

<p>透露一下，在整体策略中，有一个部分是涉及到大规模机器学习：样本是几十亿级别，特征是亿级别（这是我进来的第一个项目）</p>

<h3>动态调价：</h3>

<p>设想在周五的傍晚，下班高峰，又开始下大雨。在国贸商圈有1000个用户通过滴滴叫车，而附近只有100辆车。如何做订单分配？应该把有限的车给谁？</p>

<p>首先，我们需要定义一个目标：动态调价的目的是什么？最大化成交量？最大化流水？最大化（愿加价）乘客打车的成功率？还是这几个目标的组合最合理？</p>

<p>选定目标之后，每个乘客应该加多少钱？一个优质订单是不是应该少加点？</p>

<h3>滴米：</h3>

<p>为了促进订单成交，除了给司机补贴和要求乘客加价，是不是还有别的激励方案？</p>

<p>于是滴滴牛逼的PM们推出了滴米这个牛逼的产品。滴米是一种虚拟货币，对于优质订单，一堆司机挤破头来抢，我们就扣他们虚拟货币，对于没人要的订单，我们就奖励滴米。这样就调节了优质劣质订单冰火两重天的不和谐局面。关键是，乘客和滴滴不用花一分钱!</p>

<p>产品很牛逼，策略上如何支持？一个订单发出前，如何确定其是扣滴米还是奖励滴米？扣多少奖多少？每个司机一样吗？整个策略会导致通货膨胀或者紧缩吗？</p>

<h3>到达时间预估</h3>

<p>预估司机从A点到B点的时间消耗，对滴滴挺重要。如果准确地预估？基于哪些数据和因素？这是一个机器学习问题吗？有更巧妙的预估方法吗？</p>

<h2>工作感受</h2>

<p>说了来滴滴3各月参与和了解的几个项目，我觉得都非常有意思，也非常有意义。说下来之后的几点体验：</p>

<p>第一，最大的体会是中国互联网行业，特别是滴滴，生机勃勃，有太多有挑战的事情等着做。产品和策略迭代非常快，基本上每天线上的策略设计和架构都会有一次优化上线，你每次改动就会影响每天几百万人的出行体验。</p>

<p>第二，相比我之前的工作，在滴滴工作会和不同岗位的同学紧密合作，每天和靠谱的策略组小伙伴一起做策略设计和讨论；和90后PM mm们讨论进度和策略设计；和QA团队合作测试，保证上线风险可控；和OP同学配合上线；</p>

<p>第三，滴滴的招聘质量提升非常快，3个月前我刚入职，周边同学大概还是百度同学的平均水平，现在我参与的面试，发的offer的质量基本和hulu差不多了。</p>

<p>最后，昨天滴滴大巴上线了，现在可供出行的产品线有出租车，专车，快车，顺风车，大巴。欢迎加入滴滴，在滴滴最美好的阶段，和牛逼的人做牛逼的事情，一起改变中国人的出行体验。有兴趣的联系我: <a href="&#x6d;&#97;&#105;&#x6c;&#x74;&#111;&#58;&#103;&#x75;&#x6f;&#x64;&#x6f;&#x6e;&#x67;&#x40;&#100;&#105;&#100;&#x69;&#x74;&#x61;&#120;&#x69;&#46;&#x63;&#x6f;&#109;&#46;&#x63;&#x6e;">&#x67;&#117;&#x6f;&#x64;&#111;&#x6e;&#x67;&#64;&#x64;&#105;&#x64;&#105;&#x74;&#x61;&#x78;&#105;&#x2e;&#x63;&#111;&#109;&#46;&#x63;&#x6e;</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Shadowsocks科学上网]]></title>
    <link href="http://dongguo.me/blog/2015/03/28/shi-yong-shadowsockske-xue-shang-wang/"/>
    <updated>2015-03-28T18:54:43+08:00</updated>
    <id>http://dongguo.me/blog/2015/03/28/shi-yong-shadowsockske-xue-shang-wang</id>
    <content type="html"><![CDATA[<p>离开了墙外的Hulu，以后科学上网需要自力更生了。昨天尝试了Shadowsocks，确实稳定易用价格低，推荐给有需求的同学。</p>

<p>Shadowsocks的介绍和安装过程（windows/MacOs/ios/Android）在这篇经典的文章中有详细的介绍：<a href="http://www.jianshu.com/p/08ba65d1f91a">ShadowSocks—科学上网之瑞士军刀</a>。亲测可靠。</p>

<p>Shadowsocks客户端启动之后，是一个三角箭头，需要在“Open Server Preference”里设置账号（包括IP, 端口，加密方式和账号密码）。</p>

<p><img src="http://dongguo.me/images/personal/engineering/shadowsocks/shadow0.png" alt="Shadowsocks账号设置" /></p>

<p>Shadowsocks的账号网上有机会找到一些免费的，不过都是和很多人共享，且不稳定（比如密码改变），靠谱的方式是在VPS（虚拟专用服务器）上部署自己的Shadowsocks服务。我用了这家：<a href="http://it-player.com/">http://it-player.com/</a>（非广告）的服务，一年几十块，很划算了。（如果你难得需要科学上网一次，你甚至可以使用它的半小时有效的临时账号）</p>

<p>这家的VPS里已经配置好了Shadowsocks服务的安装程序，只需要在网页操作鼠标操作就可以安装好，复制端口号，密码，和VPS的ip配置到本地Shadowsocks客户端。截图如下：
<img src="http://dongguo.me/images/personal/engineering/shadowsocks/shadow3.png" alt="在VPS中安装配置Shadowsocks服务" /></p>

<p>配置好账号，就可以愉快地切换了，考虑到每个月有上百G的流量，默认一直科学上网好了。下载和youtube的速度都是刚刚的。</p>

<p><img src="http://dongguo.me/images/personal/engineering/shadowsocks/shadow4.png" alt="在VPS中安装配置Shadowsocks服务" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[我在第一份工作中学到了什么]]></title>
    <link href="http://dongguo.me/blog/2015/03/24/what-i-learned-in-my-first-job/"/>
    <updated>2015-03-24T11:26:00+08:00</updated>
    <id>http://dongguo.me/blog/2015/03/24/what-i-learned-in-my-first-job</id>
    <content type="html"><![CDATA[<p>Hulu是我的第一份工作。从2011年1月开始实习，7月毕业后正式加入，到15年春天，正好是本科4年的长度，在这里对这4年作个总结。</p>

<h4>1. 定位自己的技术领域</h4>

<p>互联网行业太大了，从技术角度来说至少包含了硬件研发，前端，后端service，基础架构，数据平台，策略算法等领域。大部分人都不能做到在每一个领域精耕细作，可行的方式就是一段时间内聚焦在自己有激情（最好也有基础）的1个领域发力，关注另外1－2个领域的技术发展，同时follow整个行业的大的趋势和变化。</p>

<p>第一份工作的一个收获就是我确定了自己未来几年的技术定位：聚焦在策略算法（包括机器学习，数据挖掘，优化问题，策略设计等）上，关注数据平台和后端service的技术发展，了解整个行业大的趋势和变化。</p>

<h4>2. 规划职业发展路线</h4>

<p>规划规划就是在问：十年后你想做什么，成为什么样的人？这是比给自己技术领域定位更大更长远的问题。想明白这个问题可以让自己更有目标，在做选择的时候看得更远。</p>

<p>我的技术发展路线目前在大数据这块，从下面的基础架构，数据平台，到上面的策略算法，业务逻辑。大数据现在比较热，但是和每一次技术浪潮一样，这波浪潮也会过去，我的判断是大概5到10年。不是说5-10年后大数据没有用武之地，而是说这块的技术会越来越成熟，越来越工具化。</p>

<p>开源社区和一些相关的技术公司正在以风卷残云的速度推进基础架构和数据平台的稳定性和工具化：Clourdea和Hortonworks提供的工具让Hadoop的安装变得一键傻瓜式；Spark以飞快的速度变成稳定，可以部署在上千台机器在P级别的内存里计算；YARN集群的管理和维护可以通过图形界面方便地操作；Hbase发布了1.0版本，可以搞定T到P级别的数据存储访问；越来越丰富的内存数据库和列存储数据库可供选择。</p>

<p>上层的策略和算法也越来越成熟，特别是有丰富的lib来使用，大部分公司使用工业界经典的算法和经验，加上尝试学术界新的研究成果就可以解决大部分问题了（比如spark的mllib，在最新的1.3版本里实现了大部分经典的机器学习，推荐系统和数据挖掘算法）。我相信几年之内开源社区就会提供好用（相比weka）的工具让你在图形界面里通过鼠标拖拽和简单输入解决大部分ML和DM问题。对于很多优化算法，也有现成的实现，不需要自己去推导实现。</p>

<p>最终大数据这块在未来有挑战性的是业务逻辑，每个公司都有自己相对独特的业务，理清业务，分清主次，平衡商业和技术，利用大数据技术给公司创造最大价值是个人价值最大化的方式。这背后需要的是对大数据领域全面的了解，架构能力，商业思维和团队管理。这也是我目前的职业发展目标。</p>

<h4>3. 个人技术发展 vs. 带团队</h4>

<p>我身边有不少技术流同事（大多工作2-3年左右）比较排斥带团队，想要100%的精力放在技术钻研上，我非常理解，有一段时间我也这么想。现在我开始思考一个更好的平衡，身边也有同事作出了很好的榜样。</p>

<p>带团队对个人成长的益处是明显的：让自己有更高的视野，培养商业思维，锻炼leadership，更大地发挥自己影响力和价值的机会，在承担更多责任的同时也会获得更多的回报。</p>

<p>带团队一定会占用一定的精力：为团队制订目标，项目规划，团队建设，与团队成员定期沟通，为team负责，做一些没人愿意干的活。解决的方法有2个，第一是delegate工作，比如设立一个PM的角色负责项目规划和对外沟通，将TB的安排分配给某个细心热心的同事；第二个是更努力勤奋，在承担更多的责任带领团队奔向目标的同时还要提高技术的深度和广度，只能更加努力，这是职业生涯必须要经历的阶段。</p>

<h4>4. 做一个积极的学习者</h4>

<p>视野局限在手头的工作是不够的，跟住技术圈和行业的发展很有必要。下面的一些点有些是我在关注的，有些是需要加强的：</p>

<ul>
<li>和同事，特别是别的组的同事多多交流，了解公司各个部门和team在做什么，他们关注什么，有什么值得学习和合作的；</li>
<li>积极参加公司内部的技术分享，特别是别的组的，用1个小时了解别人几个月做的事实在是很划算；</lib></li>
<li>订阅阅读，我在用feedly，比较好用，如果你关注大数据，可以订阅“Hadoop Weekly”, &ldquo;Databricks&#8221;以及一些技术公司的技术博客;</li>
<li>关注top conferences(ICML, KDD, AAAI, WSDM…), 90%的文章只需要看下标题，剩下的读读摘要和实验，需要精读或者实现的很少；</li>
<li>关注github trend;</li>
<li>微信的部分公众帐号</li>
<li>重视动手实践，动手去试过，我才会认为自己真的了解；</li>
</ul>


<p>每天保持阅读，follow技术进展和业界变化目前我做得还不够好，其实做了会发现也就是每天花半个小时，做与不做长期下来差别应该会很大。</p>

<h4>5. 时间和效率管理</h4>

<p>在Hulu的几年，时间管理上有一些心得，有些点执行得不够好，下一份工作要做到。</p>

<ul>
<li>每天早上的第一件事情就是做计划（前一天晚上应该更好），精确到半小时。按照优先级排序，每完成一项就标注，比较有成就感。注意尽力让自己不要被打断；</li>
<li>给邮件分类，取消邮件提醒，避免被邮件打断，集中午饭后和晚饭后2个时间段阅读回复邮件；</li>
<li>早上的时间最高效，我很享受很早到办公司，一个人把重要的事情先处理完，这样晚上甚至下午的时间可以用来读文章或者尝试新的东西；</li>
</ul>


<h4>6. 高质量带来高效率</h4>

<p>质量体现在工作的每个细节中，在Hulu的几年深有体会，比如说发邮件，你的邮件有语法错误吗？你的邮件组织清晰吗？你的邮件里的每句话对方都关心吗（不关心的就要删除）？有把核心结论放在头部吗？你的观点有充分的数据支持吗？数据支持的图表美观易懂吗？我很感谢对我作出指点的前辈同事。质量还体现在你做的技术分享的质量，开会前的准备，代码的质量和效率，code review时的认真度等等。</p>

<p>高质量和高效率有一些不可调和的地方，这就需要依据事情的优先级来，比如code review需要的细致程度取决于代码的重要性，有没有别的高质量reviewers帮忙。但是很多时候高质量保证了长期的高效率，比如：</p>

<ul>
<li><p>如果代码比较烂或者跑得太慢，请务必集中时间立刻彻底改进它，否则这些代码以后会成为你的时间黑洞。</p>

<p>  <code>实例：我曾经有半年的陷入在开发一个项目的某个模块（一个逻辑略复杂的spark应用），3个月开发完之后开始在集群上测试，跑得很慢，内存消耗也很大，但是勉强还能接受。虽然负责集群管理的team有所抱怨，自己一次完整的测试也要花4个小时，但是我还是没有足够重视。后来代码需要引入新的逻辑，由于之前代码质量不高，新逻辑的引入很痛苦，调试的时间也比较长。由于在spark集群中跑得时间太长内存消耗太大，经常会突然挂掉。挣扎了一段时间的小修小补后，终于下定决心梳理逻辑，重构代码，彻底修改了spark程序的并行逻辑，执行时间下降到了半个小时，内存使用大大减少，代码逻辑也简单很多了，这个改变要是在早期就做，肯定能节省很多时间。</code></p></li>
<li><p>在动手进行正式编码开发前，确保对数据做细致的分析，否则可能浪费掉一周的编码时间（不要假设任何来源的数据是没有问题的）；</p></li>
<li><p>你可以先用某个新语言或者工具，但是有时间了请务必搞透它，否则以后会付出代价；</p>

<p>  <code>实例：一直有一个坏习惯：每次遇到问题去google，而不是把东西研究透。在1年多前开始接触scala，草草地看了一本书，也写了一些比较小的应用，一直没有细致研究它。后来趟了无数坑。</code></p></li>
<li><p>将能自动化的一切自动化（一个典型的例子是机器学习的实验，从数据准备到测试到发实验报告整个过程在自动化后可以节约大量时间，提高了后续实验的效率）</p></li>
</ul>


<h4>7. 做技术总结和分享</h4>

<p>技术总结和分享可以梳理加深自己对知识的理解，纪录自己的成长，同时还是很好的提升自己影响力的机会。如果是通过演讲的方式分享，由于自己理解了和让别人理解不是一个难度，可以进一步加深自己的理解。锻炼自己成为一个好的演讲者（这非常重要）。</p>

<p>技术分享不仅仅是给大家讲调研了什么新的技术，读了什么nb的papers，还包括推动新技术，算法，代码库，工具在team和公司的使用。</p>

<h4>8. 成为让别人和公司信赖的人</h4>

<p>2013年一帮老朋友离开Hulu，都是和我合作比较多，对我帮助比较大的，第一份工作中遇到这种情况对我的影响还是比较大的。公司做了组织结构的调整，有一些别的组的同事调整到广告组来，在这个特殊阶段，我还算不错地扮演了team核心的角色，帮助公司让这个team稳定并一步步壮大起来。</p>

<p>在努力成为让公司信赖让别人可依赖的人的过程中，我成长了。这边总结下自己做得不够好的地方：1). 从心态上更好地调整好leader的心态； 2). 做判断需要更果断； 3). 更积极地协调大家的工作，特别是实习生的工作，让大家的效率更高； 4). 更好地和PM协调好工作分配</p>

<h4>9. 扮演好自己的角色</h4>

<p>在工作中，你需要相处的角色有4类，第1类是自己的下属，第2类是组内的PM(programe manager以及product manager)，第3类是其他组需要合作的同事，第4类是自己的老板。过去4年有很多心得，也有不少教训。</p>

<ul>
<li>和自己的下属：需要明确自信地宣称你是老大，你为这个team以及大家的成长和发展负责，定期的沟通，及时指出问题，保证每个人有正确的方向，做的事情符合优先级顺序，有产出，帮忙解决block issue。当然为team制定中长期计划，争取资源和项目也是非常重要的；</li>
<li>和组内的PM：需要一开始就划清职责边界，什么事情由谁负责决定，避免以后工作中出现职责不清或非良性得竞争。要敢于将工作delegate出去，当然要做到放得出去收得回来；</li>
<li>和其他组合作的同事：平时要注意建设好关系，不能需要支援的时候才联系对方。合作的过程中要多从对方的角度思考，对方为什么要合我合作这件事？对方关注什么？对方能得到什么？不能suppose对方有义务积极配合自己；</li>
<li>和自己老大：多沟通，争取主动权和控制权，学会向上manage；</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Druid Cluster Setup]]></title>
    <link href="http://dongguo.me/blog/2015/03/02/druid-cluster-setup/"/>
    <updated>2015-03-02T14:53:25+08:00</updated>
    <id>http://dongguo.me/blog/2015/03/02/druid-cluster-setup</id>
    <content type="html"><![CDATA[<p>本文介绍如何搭建Druid cluster，Druid的介绍与应用见<a href="http://dongguo.me/blog/2014/05/05/druid-introduction-and-practise/">另一篇文章</a></p>

<p>Druid的官网也有详细的<a href="http://druid.io/docs/latest/">文档</a>，建议浏览一遍。本文对关键部分做一些梳理，总结一些比较坑的点。</p>

<h2>机器准备</h2>

<p>Druid包含若干个services和nodes，我的配置如下（如果没有多个机器，当然可以将所有模块都起在一台机器上）</p>

<ul>
<li>services/nodes on machine1: Mysql server, Zookepper server, coordinator node, overlord node (indexing service)</li>
<li>services/nodes on machine2: Historical node, Realtime node</li>
<li>services/nodes on machine3: Broker node</li>
</ul>


<p>3台机器都安装配置好java (<a href="https://www.digitalocean.com/community/tutorials/how-to-install-java-on-ubuntu-with-apt-get">how</a>)</p>

<h2>安装配置依赖</h2>

<h4>mysql配置</h4>

<p>按照Druid的文档安装mysql并创建一个新的用户druid/diurd。理论上Druid在后续步骤会在database druid中创建3张表druid_config, druid_rules和druid_segments。如果最终你发现没有这3张表，可以手动创建。</p>

<h4>安装Zookeeper</h4>

<p>安装启动，无坑</p>

<h4>Deep storage</h4>

<p>如果是local模式（全部都在一台机器上），使用本地磁盘作为deep storage是最简单的，对于cluster，较简单的方式是大家（indexing services, historical node, realtime node）挂载一块公共的磁盘(比如nfs方式)，这样historical node就可以同步deep storage上的segments，realtime node也可以将segments同步到deep storage上来。</p>

<p>在实际应用中数据量通常比较大，常常会使用hdfs作为deep storage，为了能够将segments写入到hdfs中，</p>

<h3>配置启动Druid各个nodes</h3>

<p>对于如下每个node/service，Druid都有一个配置文件runtime.properties（较新的版本将一些公共的配置提取了出来），每个node/service都配置下druid.zk.service.host为zookeeper的地址。</p>

<ul>
<li>coordinator node: 无坑，在machine1上启动</li>
<li><p>historical node: Druid默认Deep storage数据路径为/tmp/druid/localStorage, 可通过配置druid.storage.storageDirectory=XXX来覆盖。</p>

<p>  <code>
druid.storage.type=local
druid.storage.storageDirectory=/mnt/data/druid/localStorage
druid.segmentCache.locations=[{"path": "/mnt/data/druid/indexCache", "maxSize"\: 10000000000}]
 </code>
  如果deep storage是hdfs，则修改druid.storage.type=hdfs，druid.storage.storageDirectory为hdfs上的路径</p></li>
<li><p>broker node: 无坑，在machine3上启动；</p></li>
<li><p>indexing service:</p>

<p>  <code>
druid.indexer.task.hadoopWorkingPath=hdfs://elsaudnn001.prod.hulu.com/user/guodong/druid
druid.storage.type=hdfs
druid.storage.storageDirectory=hdfs://elsaudnn001.prod.hulu.com/user/guodong/druid
 </code>
  对应deep storage是hdfs</p></li>
<li>realtime node: 需要使用kafka，参考官网文档即可；</li>
</ul>


<h3>数据导入</h3>

<p>使用indexing services是Druid推荐的数据导入方式，数据的input和output都可以是本地/挂载磁盘或者hdfs。
如果要读写hdfs，需要保证druid引用的hadoop版本和你使用的版本一致。</p>

<p>另外Druid引用了2.5.0版本的protobuf，而2.1.0之前版本的hadoop使用的是更老的protobuf版本（如2.4.0a），如果你遇到protobuf版本冲突的问题，需要修改druid的pom.xml<a href="http://druid.io/docs/latest/Build-from-source.html">重新打包</a></p>

<h2>参考</h2>

<ol>
<li><a href="http://druid.io/docs/latest/">官方文档</a></li>
<li><a href="https://groups.google.com/forum/#!forum/druid-development">google groups讨论区</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在线广告中的cookie Matching]]></title>
    <link href="http://dongguo.me/blog/2015/02/12/cookies-matching-introduction/"/>
    <updated>2015-02-12T13:45:00+08:00</updated>
    <id>http://dongguo.me/blog/2015/02/12/cookies-matching-introduction</id>
    <content type="html"><![CDATA[<p>用户定向是在线广告的核心优势之一，数据是用户定向的基础，而cookie matching技术可以将用户在各个站点上的数据关联在一起，使得re-targeting成为可能。</p>

<p>cookie matching有很多的应用场景，典型的有2种，一种是在DMP(Data Management Platform)生态中，另一种是在RTB(Real-time bidding)中。下面介绍下在这2种场景中cookie matching是如何实现的。</p>

<p><img src="http://dongguo.me/images/personal/ads/cookie_matching_DMP.png" alt="" /></p>

<ol>
<li>用户U访问jd.com, jd从用户browser中获取jd_cookie_id(jd.com的cookies id);</li>
<li>jd的页面中预先嵌入了BlueKai的js脚本，会有一个302重定向请求转发给BlueKai, 用户的browser中会生成BlueKai的cookies,同时用户的jd_cookie_id会被发送给BlueKai;</li>
<li>BlueKai在其后端service中纪录下BlueKai_cookie_id和jd_cookie_id的映射关系</li>
<li>用户U某一次去了yahoo.com浏览新闻，假设事先yahoo和jd签了一笔重定向的广告订单</li>
<li>yahoo的ad server在给用户U挑选广告前，访问BlueKai server，BlueKai会在其数据库中检索Bluekai_cookie_id对应了哪些站点的cookie_id</li>
<li>BlueKai给yahoo ad server返回用户U的tags（包含了哪些站点的cookie_id），如果其中包含了jd_cookie_id，则jd的广告可能会播放给该用户看</li>
</ol>


<p><img src="http://dongguo.me/images/personal/ads/cookie_matching_RTB.png" alt="" /></p>

<ol>
<li>用户U访问jd.com, jd用从户browser中获取jd_cookie_id(jd.com的cookies id);</li>
<li>jd的页面预先嵌入了PinYou的脚本，同样的会为BlueKai生成cookie，同时请求Pinyou分配cookie mapping任务;</li>
<li>Pinyou给jd返回一个beacon，其中包含ad exchange地址，和用户U的Pinyou_cookie_id;</li>
<li>jd会通过该beacon向DoubleClick发送cookie matching请求，包含了pinyou_cookie_id;</li>
<li>doubleclick通过302重定向向Pinyou发送doubleclick_cookie_id;</li>
<li>Pinyou在其数据库中存储doubleclick_cookie_id和pinyou_cookie_id的映射关系；</li>
<li>用户U某一次去yahoo.com浏览新闻，yahoo事先接入了double click广告平台售卖广告；</li>
<li>yahoo的ad server会向double click发送广告请求，double click会将用户U的doubleclick_cookie_id发送给Pinyou等DSP, Pinyou通过cookie matching数据库找到pinyou_cookie_id, 再检查其对应了哪些站点的cookie_id，如果包含了jd_cookie_id，Pinyou就可能会为jd的广告竞争该广告位</li>
<li>double click返回挑中的广告让yahoo播放</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark使用经验分享]]></title>
    <link href="http://dongguo.me/blog/2014/12/30/Spark-Usage-Share/"/>
    <updated>2014-12-30T23:01:39+08:00</updated>
    <id>http://dongguo.me/blog/2014/12/30/Spark-Usage-Share</id>
    <content type="html"><![CDATA[<p><a href="https://spark.apache.org/">Spark</a>是一个基于内存的分布式计算engine，最近1-2年在开源社区(<a href="https://github.com/apache/spark">github</a>)和工业界非常火，国内的一些公司也搭建自己的spark集群。典型的应用场景是大数据上的机器学习模型的训练以及各种数据分析。下面是我理解的spark的优势:</p>

<ol>
<li><p>Spark使得分布式编程更简单</p>

<p> Spark将实际分布在众多Nodes上的数据抽象成RDD(resilient distributed dataset)，使得我们可以像本地数据一样进行处理。同时，Spark提供了相比MapReduce更丰富的<a href="http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations">API</a>，相比MapReduce编程更加简单。</p></li>
<li><p>Spark通过充分利用内存提高计算效率</p>

<p> 随着数据量越来越大，内存越来越便宜，使用较多的内存让（某些类型的）计算效率提升10至100倍，对很多公司来说是比较划算的。Spark和Facebook的Presto都基于这样的思想。在Spark中，你可以指定将那些在后续需要被多次使用的RDD缓存在内存中，减少了IO的开销，可以显著提高如机器学习模型训练这种需要迭代计算的应用的效率。</p></li>
<li><p>Spark提供了一整套的数据分析和计算解决方案，降低了学习和维护成本
 <img src="http://dongguo.me/images/personal/engineering/spark/spark-components.png" alt="" /></p>

<ul>
<li>Spark本身支持做batch的计算，比如每天机器学习模型的训练，各种数据的处；</li>
<li>Spark Streaming可以用来做realtime计算和数据处理，Spark Streaming的<a href="https://spark.apache.org/docs/1.1.1/streaming-programming-guide.html">API</a>和Spark的比较类似，其实背后的实现也是把一段段的realtime数据用batch的方式去处理；</li>
<li>MLlib实现了常用的机器学习和推荐算法，可以直接用或者作为baseline；</li>
<li>Spark SQL使得可以通过SQL来对Hive表，Json文件等数据源进行查询，查询会被转变为一个Spark job；</li>
<li>还有GraphX, 我没有用过，其用于一些图相关的计算；<br></br></li>
</ul>
</li>
<li><p>Spark可以和MapReduce通过YARN共享机器资源
 <img src="http://dongguo.me/images/personal/engineering/spark/spark-mr-yarn.png" alt="" /></p>

<p> 所有的存储(HDFS)，计算，内存资源都可以共享</p></li>
</ol>


<h2>个人使用Spark的一些经验总结</h2>

<ol>
<li><p>理解spark application的运行原理， 可以避免犯很多错误
 <img src="http://dongguo.me/images/personal/engineering/spark/driver-executors.png" alt="" />
 Driver中涉及到RDD操作的代码（比如RDD.map{}中的代码）需要Serialize后由Driver所在的Node传输给Executors所在的Nodes，并做Deserialize后在executors上执行，RDD操作中涉及到的数据结构，比如map中用到了一个user_id &ndash;> user_profile的hashtable，也需要由Driver所在的Node传输给Executors所在的Nodes。理解了这点就可以更好理解下面2点分享</p></li>
<li><p>保证Rdd操作中的代码都是可序列化的，否则会有NonSerializableException</p>

<p> 一种常见的错误是，在rdd1.map{objectOfClassA.fun}中，对象objectOfClassA所属的类ClassA需要是可序列化的，这也以为ClassA中用到的所有成员属性都是可序列化的。如果classA使用的某个成员属性无法序列化（或者标识为Serializable），scala中可以通过@transient关键字标明序列化ClassA时不序列化该成员变量。推荐stakoverflow的2个讨论：<a href="http://stackoverflow.com/questions/24224392/why-does-spark-throw-notserializableexception-org-apache-hadoop-io-nullwritable">link1</a> <a href="http://stackoverflow.com/questions/22592811/task-not-serializable-java-io-notserializableexception-when-calling-function-ou/22594142#22594142">link2</a></p></li>
<li><p>正确地使用广播变量(broadcast variables)</p>

<p> 如果我们有一份const数据，需要在executors上用到，一个典型的例子是Driver从数据库中load了一份数据dbData，在很多RDD操作中都引用了dbData，这样的话，每次RDD操作，driver node都需要将dbData分发到各个executors node一遍（分享1中已经介绍了背景），这非常的低效，特别是dbData比较大且RDD操作次数较多时。Spark的广播变量使得Driver可以提前只给各个executors node传一遍（spark内部具体的实现可能是driver传给某几个executors，这几个executors再传给其余executors）。使用广播变量有一个我犯过的错误如下：
 <pre><code> val brDbData = sparkContext.broadcast(dbData) //broadcast dbDataA, and name it as brDbData
 val dbDataB = brDbData.value //no longer broadcast variable
 oneRDD.map(x=>{dbDataB.getOrElse(key, -1); …})</code></pre>
 第一行将dbData已经广播出去且命名为brDbData，一定要在RDD操作中直接使用该广播变量，如果提前提取出值，第三行的RDD操作还需要将dbData传送一遍。正确的代码如下
 <pre><code> val brDbData = sparkContext.broadcast(dbData) //broadcast dbDataA, and name it as brDbData
 oneRDD.map(x=>{brDbData.value.getOrElse(key, -1); …})</code></pre></p></li>
<li><p>使用yarn-client或者yarn-cluster模式运行spark应用之前，在IDE中配置spark local模式调试以及测试好代码</p>

<p> spark的yanr-client或者yarn-cluster模式做一次测试比较耗时，因为涉及到代码打包以及上传。在IDE（推荐IntelliJ）中配置local模型用于debug和测试，将显著提升开发和测试效率；</p>

<p> 在VM option中配置：&#8221;-Dspark.master=local -Dspark.app.name=Test -Xmx2G&#8221; (also increase maximal memory for Heap)
 <img src="http://dongguo.me/images/personal/engineering/spark/spark-mr-yarn.png" alt="" /></p></li>
<li><p>充分利用spark的并行性</p>

<p> 理想的情况是整个代码的逻辑是对一个或几个RDD做处理，这时候spark的并行性往往是充分利用的。有时候代码逻辑会更复杂，比如你需要统计一年中每一天的一些数值，由于代码逻辑比较复杂，一种简单的“偷懒”方式是用一个for循环，在for循环内部做RDD的操作，这种情况是要努力避免的，务必思考将不同date的统计并行化。我写过的两个应用中都遇到了这种情况：优化之后速度提升非常明显。</p></li>
<li><p>使用cache()操作</p>

<p> cache RDD需要考虑自己有多少内存，对于后续不需要多次使用的RDD不要cache，如果内存有限却又指定要cache，大量的时间将被花在memory和disk的in-out上</p></li>
<li><p>为spark-submit选择合适的参数</p>

<p> <a href="http://spark.apache.org/docs/latest/submitting-applications.html">spark-submit</a>用于提交spark job，其可配置为job申请多少资源，包括Driver的内存和cpu，executor的个数，每个executor的内存，cpu和线程数。如果使用yarn做资源管理，只有内存是硬性占有的，一个job过多地申请内存，将会有资源浪费，可能会使别的job因为申请不到足够的内存无法跑。可以用JMX(Java Management Extension)来监控你的spark job到底消耗多少内存，可以指导你申请合适的内存大小。</p></li>
<li><p>Spark可以访问众多的数据源：比如HDFS, HBase, Cassandra或者Hive表（Hive on Spark)， 直接得到一个RDD用作后续处理</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Slides of Some Machine Learning Talk I Shared in Hulu]]></title>
    <link href="http://dongguo.me/blog/2014/12/16/Machine-Learning-talks-from-me/"/>
    <updated>2014-12-16T00:00:00+08:00</updated>
    <id>http://dongguo.me/blog/2014/12/16/Machine-Learning-talks-from-me</id>
    <content type="html"><![CDATA[<p>Hulu has good traditional of engineering and research sharing, both internal and external.</p>

<p>Below are slides of 5 machine learning talks from me.</p>

<p><a href="http://www.slideshare.net/guo_dong/expectation-propagation-researchworkshop">Expectation propagation</a> (one popular bayesian inference technique proposed by Thomas Minka)</p>

<p><a href="http://www.slideshare.net/guo_dong/machine-learning-introduction">Machine Learning Introduction</a></p>

<p><a href="http://www.slideshare.net/guo_dong/feature-selection">Feature selection</a></p>

<p><a href="http://www.slideshare.net/guo_dong/logistic-regressionpptx">Logistic regression</a></p>

<p><a href="http://www.slideshare.net/guo_dong/additive-model-and-boosting-tree">Additive Model and boosting tree</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Programmatic Digital Advertising]]></title>
    <link href="http://dongguo.me/blog/2014/11/28/programmatic-digital-advertising/"/>
    <updated>2014-11-28T23:51:24+08:00</updated>
    <id>http://dongguo.me/blog/2014/11/28/programmatic-digital-advertising</id>
    <content type="html"><![CDATA[<p>从2010年开始开始工作，一直在做搜索广告，联盟上下文广告以及视频广告。这几年RTB，或者更广义的广告的程序化交易非常火。在这边总结一下我的理解。</p>

<p>“程序化交易“即通过程序自动化地完成商品的买和卖，这在很多领域都有应用，最经典的就是金融市场中的股票，债券，货币，期货等的交易。其至少有2个好处，第一：将人从交易的各个环节中解放出来，让一切变得自动化，有效率；第二：这种程序带来的自动化使得更大范围(甚至全球)资源的优化配置变得有可能。</p>

<p>广告也不例外。相比于传统线下媒体（比如电视）广告，互联网广告（这里我们默认是显示广告，不包括由几家巨头独营的搜索广告市场）有很多优势，最显著的也是2点，第一：用户在互联网的数据可以被用来做广告的精准投放，比如你在浏览很多网站的时候都有可能看到京东的广告，而广告的内容是你之前在京东浏览过的商品；第二：也是由于数据的获取更方便，互联网广告的质和量能更容易被度量，比如广告主可以仅为点击而不是展示付费，且点击次数很容易track。</p>

<p>当然这还不够完美，对于一个广告主，其终极目标是把自己的广告投放到全球最相关的用户上，可能出现在上万个不同的站点上，而自己只需要定义每次展示，点击，或者转化的付费（当然也可以为不同的站点指定不同的单价），广告主或者其代理不需要和各个内容提供商或内容提供商的代理分别扯皮。联盟广告（如百度联盟，阿里妈妈）实现了广告交易的程序化，但仅是其中特殊的一种。</p>

<h3>在线广告程序化交易</h3>

<p>在线广告程序化交易有如下一些stakeholders：
<img src="http://dongguo.me/images/personal/ads/programmatic_stakeholders.png">
DSP(Demand side platform)可以认为其是一个有技术背景的代理商，广告主可以选择为展示，点击或者转化进行付费，DSP则和其他众多DSP通过竞价竞争广告位。DSP的数据和技术积累直接关系到其是否NB.
SSP(Supply side platform)则将publishers进行整合。Ad Network在这个生态里扮演一个中枢的角色。</p>

<p>注意为了实现广告的程序化交易，除了advertisers和publishers, 其他角色都不是必须的，因为广告主和内容提供商之间完全可以直接交易。对于百度联盟，可以认为其同时扮演了Ad Network和DSP的角色，如果你既有内容资源又有广告主资源，你当然不希望和别人分享收益。</p>

<p>可以按照2个纬度（广告投放量是否被保证，以及是固定单价还是需要竞价）将在线广告的程序化交易分为4个类别：
<img src="http://dongguo.me/images/personal/ads/programmatic_types.png"/>
<a href="http://www.iab.net/media/file/IAB_Digital_Simplified_Programmatic_Sept_2013.pdf">reference</a></p>

<p>Inventory即广告流量，广告主往往比较关心广告投放量是否能够放完，特别是对于大的品牌广告主。保证广告投放量的deal就是传统的Guaranteed deal. 对于广告商来说，其为广告的付费一直是fixed，其可以选择是为每次展示付1毛钱还是为每次点击付10块钱。这个表格中提到的Pricing指的是publisher或者SSP端看到的报价，而这个价格通常指的都是展示的单价(CPM)，如果广告主选择以CPM付费（给DSP或者SSP或者直接给publisher）,publisher端看到的该由该advertiser声称的报价通常是稳定的，但是如果广告主选择以点击甚至转化付费，DSP对不同的广告位的出价的差别就很可能由很大的差别。</p>

<p>Automated Guaranteed相比传统的广告售卖方式差别不大，主要是让流程变得自动化。注意premium内容的售卖通常是这种方式（比如Hulu以及yahoo首页），这就意味着程序化交易的scope超脱了狭义的RTB, 也适用并有利于premium内容的售卖;</p>

<p>Unreserved Fixed Rate由比较大的实际意义，对于premium的内容，其大部分的Inventory还是会通过传统的方式一笔一笔和大广告主谈（大广告主的deal细节比较复杂），剩余有多少蛋糕可以卖给中小广告主？很难保证，所以通过不保量的方式程序化售卖出去是一个很理想的选择;</p>

<p>Invitation-Only Auction和Open Auction差别不大，只是前者限制只接入部分DSP或者advertisers，2者都是我们常说的RTB。</p>

<h3>实时竞价(Real-Time-Bidding)</h3>

<p>这边不展开介绍，有2个资源对RTB有很清晰的介绍</p>

<p><a href="https://www.youtube.com/watch?v=-Glgi9RRuJs&amp;index=2&amp;list=PL6aT9elthI51NOdkxxV3m7O3vIA_A9C5u">Youtube: how an Ad is Served with Real Time Bidding</a></p>

<p><a href="http://www.math.pku.edu.cn/teachers/yaoy/Spring2013/RTB101_iPinYou_XuehuaShen_English.pdf">iPinyou 沈学华的一篇科普</a></p>

<p>RTB这块对数据的要求还是比较高的。涉及到全互联网的数据共享，用户隐私又是一个棘手的问题。想想央视某年的315报道。</p>

<h3>新变化和问题</h3>

<p>相比RTB一直给人在垃圾流量做买卖的印象，越来越多高质量的publisher愿意接入到Ad Network中，小广告主也有机会了，程序化交易越来越普及；</p>

<p>质量的控制，包括广告的质量以及内容的质量；标准的统一，比如广告位的尺寸，视频广告的清晰度和风格等; 数据的获取以及隐私；</p>

<h3>一些推荐的资源</h3>

<p><a href="http://www.iab.net/">Interactive Advertising Bureau</a>: 一家致力于建立标准，推动在线广告行业发展的公司
<a href="http://www.iab.net/programmatic">IAB programmatic</a></p>

<p><a href="http://www.iab.net/iablog/2014/11/top-10-things-you-need-to-know-about-programmatic.html">TOP 10 thinks you need to know about programmatic</a></p>

<p><a href="https://www.youtube.com/watch?v=-Glgi9RRuJs&amp;index=2&amp;list=PL6aT9elthI51NOdkxxV3m7O3vIA_A9C5u">Youtube: how an Ad is Served with Real Time Bidding</a></p>

<p><a href="http://www.math.pku.edu.cn/teachers/yaoy/Spring2013/RTB101_iPinYou_XuehuaShen_English.pdf">iPinyou 沈学华的一篇科普</a></p>

<p><a href="http://www.tubemogul.com/">TubeMogul, 一家典型的DSP公司</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Challenges for a Word-class Ad Inventory Forecasting System]]></title>
    <link href="http://dongguo.me/blog/2014/09/20/ad-inventory-forecasting/"/>
    <updated>2014-09-20T22:01:24+08:00</updated>
    <id>http://dongguo.me/blog/2014/09/20/ad-inventory-forecasting</id>
    <content type="html"><![CDATA[<p>Key words: Ad Inventory Forecasting, Ad serving, Online advertising.</p>

<p>广告流量预估是各家采取保量模式售卖广告位的公司都必须要做的，无论是传统的电视媒体还是各家互联网公司。
一句话介绍就是给定未来任意一段时间区间（通过在一年内），在任意给定定向条件（比如demographic限定，geographic限定，上下文内容限定，平台限定，时间段限定等）下，预估对于各种形态的广告（比如视频，图片，文本广告）分别有多少可以卖。</p>

<h4>实现一个优秀的广告流量预估系统的挑战在什么地方呢？至少包括如下几点</h4>

<ol>
<li><p>在大数据量下保证快速的查询响应时间</p>

<ul>
<li>大数据体现在2点，首先是广告数据条目多，另外是定向条件多。当有100类定向条件，每类可以有2种取值时，不同定向条件的组合数目虽然不会到2<sup>100</sup>级别，但到billion级别还是可能的。如何做到近于实时的查询？<br></br></li>
</ul>
</li>
<li><p>复杂多样的干扰因素对预估准确性的影响</p>

<ul>
<li>业务本身的波动性对广告流量的影响</li>
<li>业务变动对广告流量的影响</li>
<li>突发时间对广告流量的影响<br></br></li>
</ul>
</li>
<li><p>具体业务逻辑的复杂性增加了系统逻辑的复杂性</p>

<ul>
<li>典型的业务流程是来了一个广告订单，在系统种查询是否有足够的流量可以售卖，但是查询得到的流量是满足定向条件的总流量，而单个订单的在投放过程种会有各种约束，比如不能给单个用户在一天中重复播放同一个广告商的广告。所以实际能够售卖给该订单的广告量一定少于查询到的总流量。这就需要在预估中考虑广告播放的频率限制；<br></br></li>
</ul>
</li>
<li><p>和Ad server(广告投放服务器)逻辑的协调</p>

<ul>
<li>通常同一个广告位会有多个广告qualify，Ad server决定了具体放哪个广告。在ad server逻辑不发生变化的情况下，可以利用历史数据（广告总量在各个定向条件上的分布）进行预估，但是一旦ad server逻辑发生变动，广告流量预告系统最好能实时作出调整，而不是收集了一个月数据之后才发应过来。<br></br></li>
</ul>
</li>
<li><p>流量预估只是第一步，流量的管理或者说全局的统筹优化是最大化收益的必要。</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Druid介绍与实践]]></title>
    <link href="http://dongguo.me/blog/2014/05/05/druid-introduction-and-practise/"/>
    <updated>2014-05-05T22:25:34+08:00</updated>
    <id>http://dongguo.me/blog/2014/05/05/druid-introduction-and-practise</id>
    <content type="html"><![CDATA[<h3>关键词</h3>

<p>Druid, column-stores, distributed system, bitmaps indexing</p>

<h3>应用场景</h3>

<p>最近在设计一个系统来预估未来一年的广告流量，不是总流量，是任意时间段任何定向(Targeting)条件约束情况下的流量。定向条件有近百种（内容类别，设备平台，用户地域，用户人口属性等），整个时间区间不同组合数（也就是数据行数）是亿级别。目标是秒级的查询响应时间。一个简单的数据例子如下：
<img src="http://dongguo.me/images/personal/engineering/druid/druid_data_example.png" width=800 align=bottom /></p>

<h3>存储系统选择</h3>

<h4>Mysql不是适合的选择</h4>

<p>最容易想到的是用Mysql作为数据存放和查询引擎，由于数据行数太多，Mysql必须通过创建索引或者组合索引来加速查询。典型的查询包含若干个定向类别，这些定向条件的组合是非常多的（top 80%的查询也会包含几十种组合），故需要创建非常多的组合索引，代价很高。另外，对于那些没有创建组合索引的查询，查询时间完全不能接受。实际测试结果是加了组合索引后整体查询速度提升有限。</p>

<h4>为什么没有用Hbase或者Hive</h4>

<p>Hbase本身是一个经典的基于hdfs的分布式存储系统，通常来说其是行存储的，当创建column families之后，每个column family是列存储的（代价就是当通过key查询某行的时候，需要从多个不连续的存储空间读数据，具体可<a href="http://stackoverflow.com/questions/11816609/column-based-or-row-based-for-hbase">参考</a>)。在这个应用中，可以为每个定向类别（包括日期）创建一个单独的column family，但是据我所知Hbase本身没有为column family创建bitmap indexing（<a href="https://issues.apache.org/jira/browse/HBASE-6014">参考</a>），查询速度应该会受到影响。另外不用Hbase的一个原因是我希望存储系统尽量轻量级，最好不要安装hadoop。</p>

<p>Hive将查询转化为M/R任务，没法保证查询的快速响应（比如M/R cluster资源竞争很激烈时），而且使用Hive需要以来hadoop cluster，对这个应用来说也略微重量级。</p>

<h4>我们需要一个高可用的分布式的列存储系统</h4>

<p>我们的核心需求包含2点，一是查询速度快，二是系统的拓展性好，最好是分布式的。</p>

<p>第一点要求意味着最好用column-store而不是row-store，在这个应用中，虽然定向类别有近百种，但是单次查询通常只会涉及几个。对于修改操作较少且查询往往只涉及少数几列的场景使用column-store可以获得快一个量级的查询速度。而且column-store可以通过bitmap indexing，encoding，以及compression来优化查询速度和存储开销。<a href="http://www.infoq.com/cn/articles/bigdata-store-choose">还存储还是列存储</a></p>

<p>第二点要求一方面是由于我们的数据量较大，并行存储和查询可以减少时间开销，另一方面是数据量每年还在快速上涨，以后可以简单地通过加机器来应对。</p>

<p>对系统的其他要求比较普遍：系统可用性要高，稳定，轻量级，易于上手。</p>

<h4>为什么Druid是适合的选择</h4>

<p>Druid满足我们上面2点要求，其是一个开源的、分布式的、列存储系统，特别适用于大数据上的（准）实时分析统计。且具有较好的稳定性（Highly Available）。
其相对比较轻量级，文档非常完善，也比较容易上手。</p>

<h3>Druid介绍</h3>

<p><strong>如何搭建一个Druid cluster请参考我<a href="http://dongguo.me/blog/2015/03/02/druid-cluster-setup/">另一篇文章</a></strong></p>

<h4>概念</h4>

<p><strong>Segment</strong>: Druid中有个重要的数据单位叫segment，其是Druid通过bitmap indexing从raw data生成的（batch or realtime）。segment保证了查询的速度。可以自己设置每个segment对应的数据粒度，这个应用中广告流量查询的最小粒度是天，所以每天的数据会被创建成一个segment。注意segment是不可修改的，如果需要修改，只能够修改raw data，重新创建segment了。</p>

<h4>架构</h4>

<p><img src="http://dongguo.me/images/personal/engineering/druid/druid_system.png" width=800 align=bottom /></p>

<p><strong>Druid本身包含5个组成部分</strong>：Broker nodes, Historical nodes, Realtime nodes, Coordinator Nodes和indexing services. 分别的作用如下：</p>

<ul>
<li>Broker nodes: 负责响应外部的查询请求，通过查询Zookeeper将请求划分成segments分别转发给Historical和Real-time nodes，最终合并并返回查询结果给外部；</li>
<li>Historial nodes: 负责&#8217;Historical&#8217; segments的存储和查询。其会从deep storage中load segments，并响应Broder nodes的请求。Historical nodes通常会在本机同步deep storage上的部分segments，所以即使deep storage不可访问了，Historical nodes还是能serve其同步的segments的查询；</li>
<li>Real-time nodes: 用于存储和查询热数据，会定期地将数据build成segments移到Historical nodes。一般会使用外部依赖kafka来提高realtime data ingestion的可用性。如果不需要实时ingest数据到cluter中，可以舍弃Real-time nodes，只定时地batch ingestion数据到deep storage；</li>
<li>Coordinator nodes: 可以认为是Druid中的master，其通过Zookeeper管理Historical和Real-time nodes，且通过Mysql中的metadata管理Segments</li>
<li>Druid中通常还会起一些indexing services用于数据导入，batch data和streaming data都可以通过给indexing services发请求来导入数据。</li>
</ul>


<p><strong>Druid还包含3个外部依赖</strong></p>

<ul>
<li>Mysql：存储Druid中的各种metadata（里面的数据都是Druid自身创建和插入的），包含3张表：&#8221;druid_config&#8221;（通常是空的）, &ldquo;druid_rules&#8221;（coordinator nodes使用的一些规则信息，比如哪个segment从哪个node去load）和“druid_segments”（存储每个segment的metadata信息）；</li>
<li>Deep storage: 存储segments，Druid目前已经支持本地磁盘，NFS挂载磁盘，HDFS，S3等。Deep Storage的数据有2个来源，一个是<a href="http://druid.io/docs/0.6.104/Batch-ingestion.html">batch Ingestion</a>, 另一个是real-time nodes；</li>
<li>ZooKeeper: 被Druid用于管理当前cluster的状态，比如记录哪些segments从Real-time nodes移到了Historical nodes；</li>
</ul>


<h4>查询</h4>

<p>Druid的查询是通过给Broker Nodes发送HTTP POST请求（也可以直接给Historical or Realtime Node），具体可见Druid<a href="http://druid.io/docs/latest/Tutorial:-All-About-Queries.html">官方文档</a>。查询条件的描述是json文件，查询的response也是json格式。Druid的查询包含如下4种：</p>

<ul>
<li><a href="http://druid.io/docs/latest/TimeBoundaryQuery.html">Time Boundary Queries</a>: 用于查询全部数据的时间跨度</li>
<li><a href="http://druid.io/docs/latest/GroupByQuery.html">groupBy Queries</a>: 是Druid的最典型查询方式，非常类似于Mysql的groupBy查询。query body中几个元素可以这么理解：

<ul>
<li>&ldquo;aggregation&rdquo;: 对应mysql&#8221;select XX from&#8221;部分，即你想查哪些列的聚合结果;</li>
<li>&ldquo;dimensions&rdquo;: 对应mysql&#8221;group by XX&#8221;，即你想基于哪些列做聚合;</li>
<li>&ldquo;filter&rdquo;: 对应mysql&#8221;where XX&#8221;条件，即过滤条件；</li>
<li>&ldquo;granularity&rdquo;: 数据聚合的粒度;</li>
</ul>
</li>
<li><a href="http://druid.io/docs/latest/TimeseriesQuery.html">Timeseries queries</a>: 其统计满足filter条件的&#8221;rows&#8221;上某几列的聚合结果，相比&#8221;groupBy Queries&#8221;不指定基于哪几列进行聚合，效率更高;</li>
<li><a href="http://druid.io/docs/latest/TopNQuery.html">TopN queries</a>: 用于查询某一列上按照某种metric排序的最常见的N个values;</li>
</ul>


<h3>本文小结</h3>

<ol>
<li>Druid是一个开源的，分布式的，列存储的，适用于实时数据分析的系统，文档详细，易于上手；

<ul>
<li>Druid在设计时充分考虑到了Highly Available，各种nodes挂掉都不会使得druid停止工作（但是状态会无法更新）；</li>
<li>Druid中的各个components之间耦合性低，如果不需要streaming data ingestion完全可以忽略realtime node；</li>
<li>Druid的数据单位Segment是不可修改的，我们的做法是生成新的segments替换现有的；</li>
<li>Druid使用Bitmap indexing加速column-store的查询速度，使用了一个叫做<a href="http://ricerca.mat.uniroma3.it/users/colanton/docs/concise.pdf">CONCISE</a>的算法来对bitmap indexing进行压缩，使得生成的segments比原始文本文件小很多；</li>
</ul>
</li>
<li>在我们的应用场景下（一共10几台机器，数据大概100列，行数是亿级别），平均查询时间&lt;2秒，是同样机器数目的Mysql cluter的1/100 ~ 1/10；</li>
<li>Druid的一些“局限”：

<ul>
<li>Segment的不可修改性简化了Druid的实现，但是如果你有修改数据的需求，必须重新创建segment，而bitmap indexing的过程是比较耗时的；</li>
<li>Druid能接受的数据的格式相对简单，比如不能处理嵌套结构的数据</li>
</ul>
</li>
</ol>


<h3>参考资料&amp;推荐阅读</h3>

<ol>
<li><a href="http://druid.io/docs/latest/">官方文档</a></li>
<li><a href="https://groups.google.com/forum/#!forum/druid-development">google groups讨论区</a></li>
<li><a href="http://static.druid.io/docs/druid.pdf">Druid: A Real-time Analytical Data Store</a></li>
<li><a href="http://en.wikipedia.org/wiki/Bitmap_index">Bitmap indexing wikepedia</a></li>
<li><a href="http://ricerca.mat.uniroma3.it/users/colanton/docs/concise.pdf">Bitmap indexing compression algorithm used by Druid</a></li>
<li><a href="http://www.infoq.com/cn/articles/bigdata-store-choose">行存储or列存储？</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Expectation Propagation: Theory and Application]]></title>
    <link href="http://dongguo.me/blog/2014/01/01/expectation-propagation/"/>
    <updated>2014-01-01T22:04:00+08:00</updated>
    <id>http://dongguo.me/blog/2014/01/01/expectation-propagation</id>
    <content type="html"><![CDATA[<h2>简介</h2>

<p>第一次接触EP是10年在百度实习时，当时组里面正有计划把线上的CTR预估模型改成支持增量更新的版本，读到了微软一篇基于baysian的CTR预估模型的文章（见推荐阅读5），文章中没有给出推导的细节，自己也没有继续研究。今年在PRML中读Approximal inference这章对EP有了一些了解，同时参考了其它相关的一些资料，在这里和大家探讨。</p>

<h4>什么是期望传播</h4>

<p>期望传播(Expectation Propagation): 基于<strong>bayesian</strong>的一种<strong>近似</strong>推断方法，常用于图模型中计算单个节点的边缘分布或者后验分布，属于message passing这一类推断方法。</p>

<h4>牛人</h4>

<p>首先当然是Thomas Minka, 其在MIT读博期间提出了EP，并将EP作为博士论文课题在2001年发表。Minka毕业之后去了CMU教书，现在和Bishop一起在剑桥微软研究院。</p>

<p>其次是Kevin p. Murphy, 他是我做EP相关文献调研时发现的paper比较多的，我读到的一篇全文基本都是在推导Minka博士论文中一些公式的细节。btw Murphy 2013年出版了一本书，见推荐阅读2。</p>

<h4>中英文对照</h4>

<p>下面是一些关键词的中英文对应 （由于相关的书籍文献基本都是英文的，有些词没有想到比较好的中文翻译，故保留英文）</p>

<p>截断高斯: Truncated Gaussian</p>

<p>置信传播: Belief Propagation （后面会简称BP）</p>

<p>期望传播: Expectation Propagation (后面会简称为EP)</p>

<p>消息传递: Message passing</p>

<h2>背景</h2>

<p>EP本身的思想和方法都还是比较简单的，不过会涉及到一些背景知识，这边一并介绍。</p>

<h3>高斯、截断高斯</h3>

<p>EP的核心思想之一是用指数族分布近似复杂分布，实际应用中通常选择高斯分布，所以多个高斯分布的乘积，相除，积分在EP应用过程中不可避免。</p>

<p>截断高斯是高斯分布在指定区间归一化后的结果，（所以其并不是一个高斯分布），EP本身并不和截断高斯直接相关，但是如果在分类问题中应用EP，对观察样本（0-1）建模方法通常是y=sign(f(x)>t), 和另一个高斯分布相乘之后即为截断高斯分布。（然后就需要计算其的均值方差，原因后面会提到）</p>

<p>我在另一篇文章<a href="http://dongguo.me/blog/2013/12/02/gaussian-and-truncated-gaussian/">Gaussian and Truncated Gaussian</a>中介绍了比较多的细节，可以参考。</p>

<h3>指数族分布</h3>

<p>指数族分布（exponential family distribution）有着非常好的特性，比如其有<strong>充分统计量</strong>，多个指数族分布的乘积依然是指数族分布，具体的介绍可以参见wikipedia, 介绍的非常全面，也可以参考PRML第2章。</p>

<p>由于指数族的良好特性，其常被拿去近似复杂的概率分布（EP和variance baysian都是）。由于EP中常常选择高斯分布，我们这边强调一下，高斯分布的充分统计量为: (x, x<sup>2</sup>), 其中x为高斯分布的自变量。</p>

<h3>图模型</h3>

<p>EP是贝叶斯流派的计算变量后验分布（或者说是边缘分布）的近似推断方法，通常都可以通过一个概率图模型来描述问题的生成过程（generation process），所以可以说图模型是EP的典型应用场景。</p>

<p>图模型在很多地方都有介绍，比如PRML第8章，在这里就不重复了。有1点提一下，一个图模型的联合分布（不管是有向图还是无向图）可以写成若干个因子的乘积，对于有向图每个因子是每个节点的条件分布（条件于其的所有直接相连的父节点），对于无限图每个因子是energy function。
这个特性在后面的置信传播算法会用到。</p>

<h3>factor graph</h3>

<p>图模型中节点之间的关系通过边来表达，factor graph将这种节点之间的关系通过显式的节点（factor node）来表达，比如对于有向图，每个factor node就代表一个条件概率分布，图中的所有的信息都存在于节点上（variable nodes和factor nodes）。</p>

<p>后面的BP和EP都基于factor graph，可以认为factor graph使得图上的inference方法变得比较直观，另一个好处是factor graph屏蔽了有向图和无向图的差异。（有向图无向图都可以转变为factor graph）</p>

<p>更多了解可以看PRML第8章。</p>

<h3>置信传播</h3>

<p>Belief Propagation (BP)又叫&#8217;sum-product&#8217;，是一种计算图模型上节点边缘分布的推断方法，属于消息传递方法的一种，非近似方法（基于其延伸的Loopy Belief propagation为近似推断方法）。
BP的核心为如下3点：</p>

<ul>
<li><strong>单个variable node边缘分布的计算</strong></li>
</ul>


<p><img src="http://dongguo.me/images/personal/research/ep-intro/marginal_dis_variable_node.png" width=400 align=top /></p>

<p>(注：上图来之PRML)</p>

<p>前面提到过图模型的联合分布可以分解为若干因子的乘积，每个因子对应一个factor node：</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/posterior_dis_variable_node_f1.png" width=500 align=top /></p>

<p>每个variable node的边缘分布为与其直接相连的factor nodes传递过来的message的乘积：</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/posterior_dis_variable_node_f2.png" width=700 align=top /></p>

<ul>
<li><strong>从factor node到variable node的消息传递</strong></li>
</ul>


<p><img src="http://dongguo.me/images/personal/research/ep-intro/message_factor_to_variable.png" width=400 align=bottom /></p>

<p>(注：上图来之PRML)</p>

<p>从factor node f传递到variable node x的message为：与f直接相连（除了x）的variable nodes传递到f的messages与f本身的乘积的积分（积分变量为与f直接相连的除x之外的所有variable nodes）：</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/message_factor_to_variable_f1.png" width=600 align=top /></p>

<ul>
<li><strong>从variable node到factor node的消息传递</strong></li>
</ul>


<p><img src="http://dongguo.me/images/personal/research/ep-intro/message_variable_to_factor.png" width=400 align=bottom /></p>

<p>(注：上图来之PRML)</p>

<p>从variable node x到factor node f的message为：与x直接相连的factor nodes（除f以外）传递到x的messages的乘积：</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/message_variable_to_factor_f1.png" width=400 align=top /></p>

<p>更多细节请参考PRML</p>

<h3>Moment matching</h3>

<p>在实际的问题中，要么后验分布本身比较复杂（推荐阅读3中的Clutter example），要么最大化后验的计算比较复杂，要么破坏了具体算法的假设（比如EP要求图中的所有message都是指数族），所以常常会用（有良好性质的）指数族分布近似实际的概率分布。</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/moment_matching_1.png" width=600 align=top />
<img src="http://dongguo.me/images/personal/research/ep-intro/moment_matching_2.png" width=300 align=top /></p>

<p>用一个分布去近似另一个分布的常见方法是最小化KL散度:</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/moment_matching_3.png" width=600 align=top />
<img src="http://dongguo.me/images/personal/research/ep-intro/moment_matching_4.png" width=600 align=top /></p>

<p>我们发现通过最小化KL散度得到的‘最接近’p(x)的q(x)可以简单地通过匹配充分统计量的期望得到。</p>

<p>当q(x)为高斯分布的时候，我们知道其充分统计量u(x)=(x, x<sup>2</sup>)，这时通过KL散度最小化近似分布近似的方法称为moment matching(匹配矩)</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/moment_matching_5.png" width=600 align=top /></p>

<p>为什么称为匹配矩呢，看看矩的定义就知道了：</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/moment_matching_6.png" width=350 align=top /></p>

<h2>期望传播方法-理论</h2>

<p>EP的思想：在图模型中，用高斯分布近似每一个factors，然后&#8217;approximate each factor in turn in the context of all remaining facotrs&#8217;.</p>

<p>下面为具体的算法：
<img src="http://dongguo.me/images/personal/research/ep-intro/ep_def.png" width=800 align=top />
(注：本算法参考了PRML)</p>

<p>下面通过Minka博士论文中的例子‘clutter problem’来解释：每个观察样本以(1-w)的概率由高斯分布N(x|sita, I)生成，以w的概率由noise生成（同样也是高斯分布N(x|0, aI)），于是：
<img src="http://dongguo.me/images/personal/research/ep-intro/clutter_problem_1.png" width=400 align=top />
<img src="http://dongguo.me/images/personal/research/ep-intro/clutter_problem_2.png" width=200 align=top /></p>

<p>按照EP的思想，我们用一个单高斯q(sita)去近似混合高斯p(x|sita)
<img src="http://dongguo.me/images/personal/research/ep-intro/clutter_problem_3.png" width=400 align=top /></p>

<p>单高斯去近似混合高斯听起来效果一定不好，但实际上，由于EP在近似的时候乘了其他所有factors的高斯近似之后的上下文，考虑到很多个高斯分布相乘之后的方差一般都很小，所有实际上单高斯只需要在很小的区间近似好混合高斯即可。如下图：</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/clutter_problem_4.png" width=350 align=top />
<img src="http://dongguo.me/images/personal/research/ep-intro/clutter_problem_5.png" width=350 align=top /></p>

<p>(注：上面2张图来之PRML)</p>

<p>其中蓝色曲线为混合高斯（没有画完整），红色曲线为近似的单高斯，绿色曲线为‘其它所有factor的乘积’。</p>

<h3>EP怎么应用在message passing中：</h3>

<p>在图模型中，所谓的&#8217;context of all remaining factors&#8217;就是当前节点之外所有节点和messages，所以EP在图模型中的使用方式为：和BP一样的方法计算message和marginal distribution，当某个factor或者marginal distribution不是高斯分布时，用高斯分布近似它。所以Minka认为EP也就是BP+moment matching。</p>

<p>由于每个factor以及variable node的边缘分布都是高斯分布（或被近似为高斯分布），所以EP的计算过程一般并不复杂。</p>

<h2>期望传播方法-应用</h2>

<p>EP被广泛地应用在图模型的inference上，这边提一下微软的2个应用：Bing的CTR预估，XBOX游戏中player skill的评估。</p>

<h3>Bing的CTR预估</h3>

<p>详细的推导及实验请参考：<a href="http://dongguo.me/blog/2013/12/01/bayesian-ctr-prediction-for-bing/">Bayesian CTR prediction for Bing</a>
paper中称这个model为ad predictor，其在我的数据集上预估效果很不错，训练预测速度快，天然支持增量更新，主要的缺点就是模型不是稀疏的。如果你知道怎么自然地达到稀疏效果，请指教。</p>

<p>和其它算法的比较请参考：<a href="http://dongguo.me/blog/2013/12/15/classification-models/">Classification Models</a></p>

<h3>XBOX中player skill的评估</h3>

<p>图模型和上一篇略有差异，推导过程差不多，paper中没有给出详细的推导过程，不过Murphy的新书中给出了，请参考推荐阅读2。</p>

<h2>一些小结</h2>

<ol>
<li>EP的通用性比较好，对于实际的问题，画出graph model和factor graph，就可以尝试用EP来进行inference；</li>
<li>虽然应用EP时的推导过程略长（计算很多个message和marginal distribution），但是最终的整体的更新公式一般都非常简单，所以模型训练时间开销往往较小；</li>
<li>为了使用EP，只能用高斯分布来建模，比如Bing的CTR预估那篇对每个feature的weight建模，只能假设服从高斯分布，相当于是2范数的正则化，不能达到稀疏模型的效果；</li>
<li>在我的实验中，通过EP进行inference得到的模型预估效果不错，值得一试；</li>
</ol>


<h2>推荐阅读</h2>

<ol>
<li><p>机器学习保留书籍:<a href="http://research.microsoft.com/en-us/um/people/cmbishop/prml/">Pattern recognition and machine learning</a> 第2,8,10章 (第2章看看高斯四则运算，指数族分布特性；第8章了解图模型基础，期望传播算法；第10章了解期望传播算法)</p></li>
<li><p>Murphy新书: <a href="http://www.cs.ubc.ca/~murphyk/MLbook/">Machine Learning: A Probabilistic Perspective</a> 第22章 (本书相比PRML更加具体，第22章干脆包含了TrueSkill的详细推导步骤)</p></li>
<li><p>Minka的博士论文：<a href="http://qh.eng.ua.edu/e_paper/e_thesis/EPThesis.pdf">A family of algorithms for approximate Bayesian inference</a> (想了解基本思想和理论看完前3节即可)</p></li>
<li><p>EP的应用之一：<a href="http://research.microsoft.com/pubs/74419/tr-2006-80.pdf">TrueSkill: A Bayesian Skill Rating System</a> (文中并没有给出EP每一步的细节)</p></li>
<li><p>EP的应用之二：<a href="http://research.microsoft.com/pubs/122779/adpredictor%20icml%202010%20-%20final.pdf">Web-Scale Bayesian Click-Through Rate Prediction for Sponsored Search Advertising in Microsoft’s Bing Search Engine</a> (CTR预估的应用比较吸引人，文章写得很棒，算法的效果也很好，只是干脆忽略的inference过程，有兴趣的同学可以参看我另一个文章，里面有一步一步推导的过程)</p></li>
<li><p>Minka整理的EP学习资料：<a href="http://research.microsoft.com/en-us/um/people/minka/papers/ep/roadmap.html">link</a> (其中的包含了一个videolecture上他做的variance inference的talk值得一看)</p></li>
<li><p>本文的PPT： <a href="http://www.slideshare.net/guo_dong/expectation-propagation-researchworkshop">墙外</a>, <a href="http://pan.baidu.com/s/1kT3DtvL">墙内</a></p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Classification Models]]></title>
    <link href="http://dongguo.me/blog/2013/12/15/classification-models/"/>
    <updated>2013-12-15T00:35:00+08:00</updated>
    <id>http://dongguo.me/blog/2013/12/15/classification-models</id>
    <content type="html"><![CDATA[<p>During my past 3 years in career, following classifiers are often used for classification tasks.</p>

<h2>Typcial classifiers comparision</h2>

<p><img class="left" src="http://dongguo.me/images/personal/research/classifiers/classifiers_compare.png" width="800"></p>

<h2>Decision Tree</h2>

<p>Decision Tree is not a start-of-art model for classification or regression, and when there are huge features(say millions) it will take a long time for training.
But it may perform very well when the number of distinct features are limited, and the classification/regression task is obviously non-linear.</p>

<p>A typical scenario is multi-model fusion: you have trained multiple models for single task, and you want to generate the final prediction result using all these models.
Based on my past experiments, Decision Tree can out perform linear model(linear regression, logistic regression and so on) on many datasets.</p>

<h2>RDT, random forest, boosting tree</h2>

<p>All of these 3 models are ensemble learning method for classification/regression that operate by constructing multiple Decision Tree at training time.
For RDT(random decision tree), only part of total samples are used to training each tree. And all features are considered for splitting.</p>

<p>Similar with RDT, random forest also use part of total sampels to construct each tree, but it also only use subset of features/dimisions for splitting.
So random forest introduces more &lsquo;random&rsquo; factors for training, and it may perform better when there are more noises in training set.</p>

<p>boosting tree is actually forward stagwise additive modeling with decision tree as base learner. And if you choose exponential loss function, then boosting tree becauses Adaboost with decision tree as base learner.
Here is one <a href="http://www.slideshare.net/guo_dong/additive-model-and-boosting-tree">slide</a> about additive model and boosting tree.</p>

<h2>Generalized linear model</h2>

<p>One of the most popular generalized linear model is logistic regression, which is generalized linear model with inversed sigmoid function as the link function.
There are multiple different implementation for logistic regression, and here are some often used by me.</p>

<h4>Logistic regression optimized with SGD.</h4>

<p>It&rsquo;s very basic, so I ignore the details here</p>

<h4>OWLQN</h4>

<p>It was proposed by Microsoft in paper <a href="http://research.microsoft.com/en-us/downloads/b1eb1016-1738-4bd5-83a9-370c9d498a03/">Orthant-Wise Limited-memory Quasi-Newton Optimizer for L1-regularized Objectives</a> of ICML 2007. You can also find the source code and executable runner via this link.</p>

<p>This model is optimized by a method which is similar with L-BFGS, but can achieve sparse model with L1 regularizer. I recommend you try this model and compare with other models you are using in your dataset.
Here are four reasons:</p>

<ol type="a">
<li>It&rsquo;s fast, especially when the dataset is huge;</li>
<li>It can generate start-of-art prediction results on most dataset;</li>
<li>It&rsquo;s stable and there are few parameters need to be tried. Actaully, I find only regularization parameters can impact the performance obviously;</li>
<li>It&rsquo;s sparse, which is very important for big dataset and real product. (Of course, sparse is due to L1 regularizer, instead of the specific optimization method)</li>
</ol>


<p>One problem is it&rsquo;s more challenge to implement it by yourself, so you need spend some time to make it support incremental update or online learning.</p>

<h4>FTRL</h4>

<p>It was proposed by Google via paper <a href="http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/41159.pdf">
Ad Click Prediction: a View from the Trenches</a> in 2013. I tried on my dataset, and this implementation can generate similar prediction performance with OWLQN.
It&rsquo;s quicker than OWLQN for training, and it&rsquo;s also sparse. One advantage is it&rsquo;s very easy to implement, and it support increamental update naturally.
One pain point for me is this model has 3-4 parameters need to be chosen, and most of them impact the prediction performance obviously.</p>

<h4>Ad predictor</h4>

<p>This <a href="http://research.microsoft.com/pubs/122779/adpredictor%20icml%202010%20-%20final.pdf">paper</a> was also proposed by Microsoft in ICML 2009.</p>

<p>One biggest different with upper 3 implementation is it&rsquo;s based on bayesian, so it&rsquo;s generative model. Ad predictor is used to predict CTR of sponsor search ads of Bing, and on my dataset, it could also achieve comparable prediction performance with OWQLN and FTRL.
Ad predictor model the weight of each feature with a gaussian distribution, so it natually supports online learning. And the prediction result for each sample is also a gaussian distribution, and it could be used to handle the exploration and exploitation problem.
See more details of this model in another <a href="http://guod08.github.io/me/blog/2013/12/01/bayesian-ctr-prediction-for-bing/">post</a>.</p>

<h2>Neural Network</h2>

<p>ANN is so slow for training, so it&rsquo;s tried only when the dataset is small of medium. Another disadvantage of ANN is it&rsquo;s totally blackbox.</p>

<h2>SVM</h2>

<p>SVM with kernel is also slow for training. You can try it with <a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">libsvm</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gaussian and Truncated Gaussian]]></title>
    <link href="http://dongguo.me/blog/2013/12/02/gaussian-and-truncated-gaussian/"/>
    <updated>2013-12-02T18:30:00+08:00</updated>
    <id>http://dongguo.me/blog/2013/12/02/gaussian-and-truncated-gaussian</id>
    <content type="html"><![CDATA[<p>Everybody knows about Gaussian distribution, and Gaussian is very popular in Bayesian world and even in our life. This article summaries typical operation of Gaussian, and something about Truncated Guassian distribution.</p>

<h2>Gaussian</h2>

<h3>pdf and cdf</h3>

<p><img class="left" src="http://dongguo.me/images/personal/research/gaussian/gaussian_pdf.png" width="350" title="'Gaussian pdf'" >
<img class="right" src="http://dongguo.me/images/personal/research/gaussian/gaussian_cdf.png" width="350" title="'Gaussian cdf'" >
<img src="http://dongguo.me/images/personal/research/gaussian/gaussian_1.png" width="1200"></p>

<h3>Sum/substraction of two independent Gaussian random variables</h3>

<p><img src="http://dongguo.me/images/personal/research/gaussian/gaussian_plus2.png" width="1200">
Please take care upper formula only works when x1 and x2 are independent. And it&rsquo;s easy to get the distribution for variable x=x1-x2
See <a href="http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter7.pdf">here</a> for the detils of inference</p>

<h3>Product of two Gaussian pdf</h3>

<p><img src="http://dongguo.me/images/personal/research/gaussian/gaussian_multiple2.png" width="1200">
Please take care x is no longer a gaussian distribution. And you can find it&rsquo;s very elegant to use &lsquo;precision&rsquo; and &lsquo;precision adjusted mean&rsquo; for Gaussian operation like multiply and division.
See <a href="http://www.tina-vision.net/docs/memos/2003-003.pdf">here</a> for the detils of inference</p>

<h3>Division of two Gaussian pdf</h3>

<p><img src="http://dongguo.me/images/personal/research/gaussian/gaussian_divide2.png" width="1200"></p>

<h3>Intergral of the product of two gaussian distribution</h3>

<p><img src="http://dongguo.me/images/personal/research/gaussian/gaussian_integral.png" width="1200"></p>

<h2>Truncated Gaussian</h2>

<p><img class="left" src="http://dongguo.me/images/personal/research/gaussian/tg_pdf.png" width="350" title="'Gaussian pdf'" >
<img class="right" src="http://dongguo.me/images/personal/research/gaussian/tg_cdf.png" width="350" title="'Gaussian cdf'" ></p>

<p>Truncated Gaussian distribution is very simple: it&rsquo;s just one conditional (Gaussian) distribution.
Suppose variable x belongs to Gaussian distribution, then x conditional on x belongs to (a, b) has a truncated Gaussian distribution.
<img src="http://dongguo.me/images/personal/research/gaussian/tg_def.png" width="1200"></p>

<h3>Calculate expectation of Truncated Gaussian</h3>

<p><img src="http://dongguo.me/images/personal/research/gaussian/tg_e1.png" width="1200">
<img src="http://dongguo.me/images/personal/research/gaussian/tg_e2.png" width="1200"></p>

<h3>Calculate variance of Truncated Gaussian</h3>

<p><img src="http://dongguo.me/images/personal/research/gaussian/tg_v1.png" width="1200">
<img src="http://dongguo.me/images/personal/research/gaussian/tg_v2.png" width="1200">
<img src="http://dongguo.me/images/personal/research/gaussian/tg_v3.png" width="1200"></p>
]]></content>
  </entry>
  
</feed>
