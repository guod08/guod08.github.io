<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Dong Guo's Blog]]></title>
  <link href="http://dongguo.me/atom.xml" rel="self"/>
  <link href="http://dongguo.me/"/>
  <updated>2015-07-18T11:42:13+08:00</updated>
  <id>http://dongguo.me/</id>
  <author>
    <name><![CDATA[Dong Guo]]></name>
    <email><![CDATA[-----------------------]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[使用Shadowsocks科学上网]]></title>
    <link href="http://dongguo.me/blog/2015/03/28/shi-yong-shadowsockske-xue-shang-wang/"/>
    <updated>2015-03-28T18:54:43+08:00</updated>
    <id>http://dongguo.me/blog/2015/03/28/shi-yong-shadowsockske-xue-shang-wang</id>
    <content type="html"><![CDATA[<p>离开了墙外的Hulu，以后科学上网需要自力更生了。昨天尝试了Shadowsocks，确实稳定易用价格低，推荐给有需求的同学。</p>

<p>Shadowsocks的介绍和安装过程（windows/MacOs/ios/Android）在这篇经典的文章中有详细的介绍：<a href="http://www.jianshu.com/p/08ba65d1f91a">ShadowSocks—科学上网之瑞士军刀</a>。亲测可靠。</p>

<p>Shadowsocks客户端启动之后，是一个三角箭头，需要在“Open Server Preference”里设置账号（包括IP, 端口，加密方式和账号密码）。</p>

<p><img src="http://dongguo.me/images/personal/engineering/shadowsocks/shadow0.png" alt="Shadowsocks账号设置" /></p>

<p>Shadowsocks的账号网上有机会找到一些免费的，不过都是和很多人共享，且不稳定（比如密码改变），靠谱的方式是在VPS（虚拟专用服务器）上部署自己的Shadowsocks服务。我用了这家：<a href="http://it-player.com/">http://it-player.com/</a>（非广告）的服务，一年几十块，很划算了。（如果你难得需要科学上网一次，你甚至可以使用它的半小时有效的临时账号）</p>

<p>这家的VPS里已经配置好了Shadowsocks服务的安装程序，只需要在网页操作鼠标操作就可以安装好，复制端口号，密码，和VPS的ip配置到本地Shadowsocks客户端。截图如下：
<img src="http://dongguo.me/images/personal/engineering/shadowsocks/shadow3.png" alt="在VPS中安装配置Shadowsocks服务" /></p>

<p>配置好账号，就可以愉快地切换了，考虑到每个月有上百G的流量，默认一直科学上网好了。下载和youtube的速度都是刚刚的。</p>

<p><img src="http://dongguo.me/images/personal/engineering/shadowsocks/shadow4.png" alt="在VPS中安装配置Shadowsocks服务" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[我在第一份工作中学到了什么]]></title>
    <link href="http://dongguo.me/blog/2015/03/24/what-i-learned-in-my-first-job/"/>
    <updated>2015-03-24T11:26:00+08:00</updated>
    <id>http://dongguo.me/blog/2015/03/24/what-i-learned-in-my-first-job</id>
    <content type="html"><![CDATA[<p>Hulu是我的第一份工作。从2011年1月开始实习，7月毕业后正式加入，到15年春天，正好是本科4年的长度，在这里对这4年作个总结。</p>

<h4>1. 定位自己的技术领域</h4>

<p>互联网行业太大了，从技术角度来说至少包含了硬件研发，前端，后端service，基础架构，数据平台，策略算法等领域。大部分人都不能做到在每一个领域精耕细作，可行的方式就是一段时间内聚焦在自己有激情（最好也有基础）的1个领域发力，关注另外1－2个领域的技术发展，同时follow整个行业的大的趋势和变化。</p>

<p>第一份工作的一个收获就是我确定了自己未来几年的技术定位：聚焦在策略算法（包括机器学习，数据挖掘，优化问题，策略设计等）上，关注数据平台和后端service的技术发展，了解整个行业大的趋势和变化。</p>

<h4>2. 规划职业发展路线</h4>

<p>规划规划就是在问：十年后你想做什么，成为什么样的人？这是比给自己技术领域定位更大更长远的问题。想明白这个问题可以让自己更有目标，在做选择的时候看得更远。</p>

<p>我的技术发展路线目前在大数据这块，从下面的基础架构，数据平台，到上面的策略算法，业务逻辑。大数据现在比较热，但是和每一次技术浪潮一样，这波浪潮也会过去，我的判断是大概5到10年。不是说5-10年后大数据没有用武之地，而是说这块的技术会越来越成熟，越来越工具化。</p>

<p>开源社区和一些相关的技术公司正在以风卷残云的速度推进基础架构和数据平台的稳定性和工具化：Clourdea和Hortonworks提供的工具让Hadoop的安装变得一键傻瓜式；Spark以飞快的速度变成稳定，可以部署在上千台机器在P级别的内存里计算；YARN集群的管理和维护可以通过图形界面方便地操作；Hbase发布了1.0版本，可以搞定T到P级别的数据存储访问；越来越丰富的内存数据库和列存储数据库可供选择。</p>

<p>上层的策略和算法也越来越成熟，特别是有丰富的lib来使用，大部分公司使用工业界经典的算法和经验，加上尝试学术界新的研究成果就可以解决大部分问题了（比如spark的mllib，在最新的1.3版本里实现了大部分经典的机器学习，推荐系统和数据挖掘算法）。我相信几年之内开源社区就会提供好用（相比weka）的工具让你在图形界面里通过鼠标拖拽和简单输入解决大部分ML和DM问题。对于很多优化算法，也有现成的实现，不需要自己去推导实现。</p>

<p>最终大数据这块在未来有挑战性的是业务逻辑，每个公司都有自己相对独特的业务，理清业务，分清主次，平衡商业和技术，利用大数据技术给公司创造最大价值是个人价值最大化的方式。这背后需要的是对大数据领域全面的了解，架构能力，商业思维和团队管理。这也是我目前的职业发展目标。</p>

<h4>3. 个人技术发展 vs. 带团队</h4>

<p>我身边有不少技术流同事（大多工作2-3年左右）比较排斥带团队，想要100%的精力放在技术钻研上，我非常理解，有一段时间我也这么想。现在我开始思考一个更好的平衡，身边也有同事作出了很好的榜样。</p>

<p>带团队对个人成长的益处是明显的：让自己有更高的视野，培养商业思维，锻炼leadership，更大地发挥自己影响力和价值的机会，在承担更多责任的同时也会获得更多的回报。</p>

<p>带团队一定会占用一定的精力：为团队制订目标，项目规划，团队建设，与团队成员定期沟通，为team负责，做一些没人愿意干的活。解决的方法有2个，第一是delegate工作，比如设立一个PM的角色负责项目规划和对外沟通，将TB的安排分配给某个细心热心的同事；第二个是更努力勤奋，在承担更多的责任带领团队奔向目标的同时还要提高技术的深度和广度，只能更加努力，这是职业生涯必须要经历的阶段。</p>

<h4>4. 做一个积极的学习者</h4>

<p>视野局限在手头的工作是不够的，跟住技术圈和行业的发展很有必要。下面的一些点有些是我在关注的，有些是需要加强的：</p>

<ul>
<li>和同事，特别是别的组的同事多多交流，了解公司各个部门和team在做什么，他们关注什么，有什么值得学习和合作的；</li>
<li>积极参加公司内部的技术分享，特别是别的组的，用1个小时了解别人几个月做的事实在是很划算；</lib></li>
<li>订阅阅读，我在用feedly，比较好用，如果你关注大数据，可以订阅“Hadoop Weekly”, &ldquo;Databricks&#8221;以及一些技术公司的技术博客;</li>
<li>关注top conferences(ICML, KDD, AAAI, WSDM…), 90%的文章只需要看下标题，剩下的读读摘要和实验，需要精读或者实现的很少；</li>
<li>关注github trend;</li>
<li>微信的部分公众帐号</li>
<li>重视动手实践，动手去试过，我才会认为自己真的了解；</li>
</ul>


<p>每天保持阅读，follow技术进展和业界变化目前我做得还不够好，其实做了会发现也就是每天花半个小时，做与不做长期下来差别应该会很大。</p>

<h4>5. 时间和效率管理</h4>

<p>在Hulu的几年，时间管理上有一些心得，有些点执行得不够好，下一份工作要做到。</p>

<ul>
<li>每天早上的第一件事情就是做计划（前一天晚上应该更好），精确到半小时。按照优先级排序，每完成一项就标注，比较有成就感。注意尽力让自己不要被打断；</li>
<li>给邮件分类，取消邮件提醒，避免被邮件打断，集中午饭后和晚饭后2个时间段阅读回复邮件；</li>
<li>早上的时间最高效，我很享受很早到办公司，一个人把重要的事情先处理完，这样晚上甚至下午的时间可以用来读文章或者尝试新的东西；</li>
</ul>


<h4>6. 高质量带来高效率</h4>

<p>质量体现在工作的每个细节中，在Hulu的几年深有体会，比如说发邮件，你的邮件有语法错误吗？你的邮件组织清晰吗？你的邮件里的每句话对方都关心吗（不关心的就要删除）？有把核心结论放在头部吗？你的观点有充分的数据支持吗？数据支持的图表美观易懂吗？我很感谢对我作出指点的前辈同事。质量还体现在你做的技术分享的质量，开会前的准备，代码的质量和效率，code review时的认真度等等。</p>

<p>高质量和高效率有一些不可调和的地方，这就需要依据事情的优先级来，比如code review需要的细致程度取决于代码的重要性，有没有别的高质量reviewers帮忙。但是很多时候高质量保证了长期的高效率，比如：</p>

<ul>
<li><p>如果代码比较烂或者跑得太慢，请务必集中时间立刻彻底改进它，否则这些代码以后会成为你的时间黑洞。</p>

<p>  <code>实例：我曾经有半年的陷入在开发一个项目的某个模块（一个逻辑略复杂的spark应用），3个月开发完之后开始在集群上测试，跑得很慢，内存消耗也很大，但是勉强还能接受。虽然负责集群管理的team有所抱怨，自己一次完整的测试也要花4个小时，但是我还是没有足够重视。后来代码需要引入新的逻辑，由于之前代码质量不高，新逻辑的引入很痛苦，调试的时间也比较长。由于在spark集群中跑得时间太长内存消耗太大，经常会突然挂掉。挣扎了一段时间的小修小补后，终于下定决心梳理逻辑，重构代码，彻底修改了spark程序的并行逻辑，执行时间下降到了半个小时，内存使用大大减少，代码逻辑也简单很多了，这个改变要是在早期就做，肯定能节省很多时间。</code></p></li>
<li><p>在动手进行正式编码开发前，确保对数据做细致的分析，否则可能浪费掉一周的编码时间（不要假设任何来源的数据是没有问题的）；</p></li>
<li><p>你可以先用某个新语言或者工具，但是有时间了请务必搞透它，否则以后会付出代价；</p>

<p>  <code>实例：一直有一个坏习惯：每次遇到问题去google，而不是把东西研究透。在1年多前开始接触scala，草草地看了一本书，也写了一些比较小的应用，一直没有细致研究它。后来趟了无数坑。</code></p></li>
<li><p>将能自动化的一切自动化（一个典型的例子是机器学习的实验，从数据准备到测试到发实验报告整个过程在自动化后可以节约大量时间，提高了后续实验的效率）</p></li>
</ul>


<h4>7. 做技术总结和分享</h4>

<p>技术总结和分享可以梳理加深自己对知识的理解，纪录自己的成长，同时还是很好的提升自己影响力的机会。如果是通过演讲的方式分享，由于自己理解了和让别人理解不是一个难度，可以进一步加深自己的理解。锻炼自己成为一个好的演讲者（这非常重要）。</p>

<p>技术分享不仅仅是给大家讲调研了什么新的技术，读了什么nb的papers，还包括推动新技术，算法，代码库，工具在team和公司的使用。</p>

<h4>8. 成为让别人和公司信赖的人</h4>

<p>2013年一帮老朋友离开Hulu，都是和我合作比较多，对我帮助比较大的，第一份工作中遇到这种情况对我的影响还是比较大的。公司做了组织结构的调整，有一些别的组的同事调整到广告组来，在这个特殊阶段，我还算不错地扮演了team核心的角色，帮助公司让这个team稳定并一步步壮大起来。</p>

<p>在努力成为让公司信赖让别人可依赖的人的过程中，我成长了。这边总结下自己做得不够好的地方：1). 从心态上更好地调整好leader的心态； 2). 做判断需要更果断； 3). 更积极地协调大家的工作，特别是实习生的工作，让大家的效率更高； 4). 更好地和PM协调好工作分配</p>

<h4>9. 扮演好自己的角色</h4>

<p>在工作中，你需要相处的角色有4类，第1类是自己的下属，第2类是组内的PM(programe manager以及product manager)，第3类是其他组需要合作的同事，第4类是自己的老板。过去4年有很多心得，也有不少教训。</p>

<ul>
<li>和自己的下属：需要明确自信地宣称你是老大，你为这个team以及大家的成长和发展负责，定期的沟通，及时指出问题，保证每个人有正确的方向，做的事情符合优先级顺序，有产出，帮忙解决block issue。当然为team制定中长期计划，争取资源和项目也是非常重要的；</li>
<li>和组内的PM：需要一开始就划清职责边界，什么事情由谁负责决定，避免以后工作中出现职责不清或非良性得竞争。要敢于将工作delegate出去，当然要做到放得出去收得回来；</li>
<li>和其他组合作的同事：平时要注意建设好关系，不能需要支援的时候才联系对方。合作的过程中要多从对方的角度思考，对方为什么要合我合作这件事？对方关注什么？对方能得到什么？不能suppose对方有义务积极配合自己；</li>
<li>和自己老大：多沟通，争取主动权和控制权，学会向上manage；</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Druid Cluster Setup]]></title>
    <link href="http://dongguo.me/blog/2015/03/02/druid-cluster-setup/"/>
    <updated>2015-03-02T14:53:25+08:00</updated>
    <id>http://dongguo.me/blog/2015/03/02/druid-cluster-setup</id>
    <content type="html"><![CDATA[<p>本文介绍如何搭建Druid cluster，Druid的介绍与应用见<a href="http://dongguo.me/blog/2014/05/05/druid-introduction-and-practise/">另一篇文章</a></p>

<p>Druid的官网也有详细的<a href="http://druid.io/docs/latest/">文档</a>，建议浏览一遍。本文对关键部分做一些梳理，总结一些比较坑的点。</p>

<h2>机器准备</h2>

<p>Druid包含若干个services和nodes，我的配置如下（如果没有多个机器，当然可以将所有模块都起在一台机器上）</p>

<ul>
<li>services/nodes on machine1: Mysql server, Zookepper server, coordinator node, overlord node (indexing service)</li>
<li>services/nodes on machine2: Historical node, Realtime node</li>
<li>services/nodes on machine3: Broker node</li>
</ul>


<p>3台机器都安装配置好java (<a href="https://www.digitalocean.com/community/tutorials/how-to-install-java-on-ubuntu-with-apt-get">how</a>)</p>

<h2>安装配置依赖</h2>

<h4>mysql配置</h4>

<p>按照Druid的文档安装mysql并创建一个新的用户druid/diurd。理论上Druid在后续步骤会在database druid中创建3张表druid_config, druid_rules和druid_segments。如果最终你发现没有这3张表，可以手动创建。</p>

<h4>安装Zookeeper</h4>

<p>安装启动，无坑</p>

<h4>Deep storage</h4>

<p>如果是local模式（全部都在一台机器上），使用本地磁盘作为deep storage是最简单的，对于cluster，较简单的方式是大家（indexing services, historical node, realtime node）挂载一块公共的磁盘(比如nfs方式)，这样historical node就可以同步deep storage上的segments，realtime node也可以将segments同步到deep storage上来。</p>

<p>在实际应用中数据量通常比较大，常常会使用hdfs作为deep storage，为了能够将segments写入到hdfs中，</p>

<h3>配置启动Druid各个nodes</h3>

<p>对于如下每个node/service，Druid都有一个配置文件runtime.properties（较新的版本将一些公共的配置提取了出来），每个node/service都配置下druid.zk.service.host为zookeeper的地址。</p>

<ul>
<li>coordinator node: 无坑，在machine1上启动</li>
<li><p>historical node: Druid默认Deep storage数据路径为/tmp/druid/localStorage, 可通过配置druid.storage.storageDirectory=XXX来覆盖。</p>

<p>  <code>
druid.storage.type=local
druid.storage.storageDirectory=/mnt/data/druid/localStorage
druid.segmentCache.locations=[{"path": "/mnt/data/druid/indexCache", "maxSize"\: 10000000000}]
 </code>
  如果deep storage是hdfs，则修改druid.storage.type=hdfs，druid.storage.storageDirectory为hdfs上的路径</p></li>
<li><p>broker node: 无坑，在machine3上启动；</p></li>
<li><p>indexing service:</p>

<p>  <code>
druid.indexer.task.hadoopWorkingPath=hdfs://elsaudnn001.prod.hulu.com/user/guodong/druid
druid.storage.type=hdfs
druid.storage.storageDirectory=hdfs://elsaudnn001.prod.hulu.com/user/guodong/druid
 </code>
  对应deep storage是hdfs</p></li>
<li>realtime node: 需要使用kafka，参考官网文档即可；</li>
</ul>


<h3>数据导入</h3>

<p>使用indexing services是Druid推荐的数据导入方式，数据的input和output都可以是本地/挂载磁盘或者hdfs。
如果要读写hdfs，需要保证druid引用的hadoop版本和你使用的版本一致。</p>

<p>另外Druid引用了2.5.0版本的protobuf，而2.1.0之前版本的hadoop使用的是更老的protobuf版本（如2.4.0a），如果你遇到protobuf版本冲突的问题，需要修改druid的pom.xml<a href="http://druid.io/docs/latest/Build-from-source.html">重新打包</a></p>

<h2>参考</h2>

<ol>
<li><a href="http://druid.io/docs/latest/">官方文档</a></li>
<li><a href="https://groups.google.com/forum/#!forum/druid-development">google groups讨论区</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在线广告中的cookie Matching]]></title>
    <link href="http://dongguo.me/blog/2015/02/12/cookies-matching-introduction/"/>
    <updated>2015-02-12T13:45:00+08:00</updated>
    <id>http://dongguo.me/blog/2015/02/12/cookies-matching-introduction</id>
    <content type="html"><![CDATA[<p>用户定向是在线广告的核心优势之一，数据是用户定向的基础，而cookie matching技术可以将用户在各个站点上的数据关联在一起，使得re-targeting成为可能。</p>

<p>cookie matching有很多的应用场景，典型的有2种，一种是在DMP(Data Management Platform)生态中，另一种是在RTB(Real-time bidding)中。下面介绍下在这2种场景中cookie matching是如何实现的。</p>

<p><img src="http://dongguo.me/images/personal/ads/cookie_matching_DMP.png" alt="" /></p>

<ol>
<li>用户U访问jd.com, jd从用户browser中获取jd_cookie_id(jd.com的cookies id);</li>
<li>jd的页面中预先嵌入了BlueKai的js脚本，会有一个302重定向请求转发给BlueKai, 用户的browser中会生成BlueKai的cookies,同时用户的jd_cookie_id会被发送给BlueKai;</li>
<li>BlueKai在其后端service中纪录下BlueKai_cookie_id和jd_cookie_id的映射关系</li>
<li>用户U某一次去了yahoo.com浏览新闻，假设事先yahoo和jd签了一笔重定向的广告订单</li>
<li>yahoo的ad server在给用户U挑选广告前，访问BlueKai server，BlueKai会在其数据库中检索Bluekai_cookie_id对应了哪些站点的cookie_id</li>
<li>BlueKai给yahoo ad server返回用户U的tags（包含了哪些站点的cookie_id），如果其中包含了jd_cookie_id，则jd的广告可能会播放给该用户看</li>
</ol>


<p><img src="http://dongguo.me/images/personal/ads/cookie_matching_RTB.png" alt="" /></p>

<ol>
<li>用户U访问jd.com, jd用从户browser中获取jd_cookie_id(jd.com的cookies id);</li>
<li>jd的页面预先嵌入了PinYou的脚本，同样的会为BlueKai生成cookie，同时请求Pinyou分配cookie mapping任务;</li>
<li>Pinyou给jd返回一个beacon，其中包含ad exchange地址，和用户U的Pinyou_cookie_id;</li>
<li>jd会通过该beacon向DoubleClick发送cookie matching请求，包含了pinyou_cookie_id;</li>
<li>doubleclick通过302重定向向Pinyou发送doubleclick_cookie_id;</li>
<li>Pinyou在其数据库中存储doubleclick_cookie_id和pinyou_cookie_id的映射关系；</li>
<li>用户U某一次去yahoo.com浏览新闻，yahoo事先接入了double click广告平台售卖广告；</li>
<li>yahoo的ad server会向double click发送广告请求，double click会将用户U的doubleclick_cookie_id发送给Pinyou等DSP, Pinyou通过cookie matching数据库找到pinyou_cookie_id, 再检查其对应了哪些站点的cookie_id，如果包含了jd_cookie_id，Pinyou就可能会为jd的广告竞争该广告位</li>
<li>double click返回挑中的广告让yahoo播放</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark使用经验分享]]></title>
    <link href="http://dongguo.me/blog/2014/12/30/Spark-Usage-Share/"/>
    <updated>2014-12-30T23:01:39+08:00</updated>
    <id>http://dongguo.me/blog/2014/12/30/Spark-Usage-Share</id>
    <content type="html"><![CDATA[<p><a href="https://spark.apache.org/">Spark</a>是一个基于内存的分布式计算engine，最近1-2年在开源社区(<a href="https://github.com/apache/spark">github</a>)和工业界非常火，国内的一些公司也搭建自己的spark集群。典型的应用场景是大数据上的机器学习模型的训练以及各种数据分析。下面是我理解的spark的优势:</p>

<ol>
<li><p>Spark使得分布式编程更简单</p>

<p> Spark将实际分布在众多Nodes上的数据抽象成RDD(resilient distributed dataset)，使得我们可以像本地数据一样进行处理。同时，Spark提供了相比MapReduce更丰富的<a href="http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations">API</a>，相比MapReduce编程更加简单。</p></li>
<li><p>Spark通过充分利用内存提高计算效率</p>

<p> 随着数据量越来越大，内存越来越便宜，使用较多的内存让（某些类型的）计算效率提升10至100倍，对很多公司来说是比较划算的。Spark和Facebook的Presto都基于这样的思想。在Spark中，你可以指定将那些在后续需要被多次使用的RDD缓存在内存中，减少了IO的开销，可以显著提高如机器学习模型训练这种需要迭代计算的应用的效率。</p></li>
<li><p>Spark提供了一整套的数据分析和计算解决方案，降低了学习和维护成本
 <img src="http://dongguo.me/images/personal/engineering/spark/spark-components.png" alt="" /></p>

<ul>
<li>Spark本身支持做batch的计算，比如每天机器学习模型的训练，各种数据的处；</li>
<li>Spark Streaming可以用来做realtime计算和数据处理，Spark Streaming的<a href="https://spark.apache.org/docs/1.1.1/streaming-programming-guide.html">API</a>和Spark的比较类似，其实背后的实现也是把一段段的realtime数据用batch的方式去处理；</li>
<li>MLlib实现了常用的机器学习和推荐算法，可以直接用或者作为baseline；</li>
<li>Spark SQL使得可以通过SQL来对Hive表，Json文件等数据源进行查询，查询会被转变为一个Spark job；</li>
<li>还有GraphX, 我没有用过，其用于一些图相关的计算；<br></br></li>
</ul>
</li>
<li><p>Spark可以和MapReduce通过YARN共享机器资源
 <img src="http://dongguo.me/images/personal/engineering/spark/spark-mr-yarn.png" alt="" /></p>

<p> 所有的存储(HDFS)，计算，内存资源都可以共享</p></li>
</ol>


<h2>个人使用Spark的一些经验总结</h2>

<ol>
<li><p>理解spark application的运行原理， 可以避免犯很多错误
 <img src="http://dongguo.me/images/personal/engineering/spark/driver-executors.png" alt="" />
 Driver中涉及到RDD操作的代码（比如RDD.map{}中的代码）需要Serialize后由Driver所在的Node传输给Executors所在的Nodes，并做Deserialize后在executors上执行，RDD操作中涉及到的数据结构，比如map中用到了一个user_id &ndash;> user_profile的hashtable，也需要由Driver所在的Node传输给Executors所在的Nodes。理解了这点就可以更好理解下面2点分享</p></li>
<li><p>保证Rdd操作中的代码都是可序列化的，否则会有NonSerializableException</p>

<p> 一种常见的错误是，在rdd1.map{objectOfClassA.fun}中，对象objectOfClassA所属的类ClassA需要是可序列化的，这也以为ClassA中用到的所有成员属性都是可序列化的。如果classA使用的某个成员属性无法序列化（或者标识为Serializable），scala中可以通过@transient关键字标明序列化ClassA时不序列化该成员变量。推荐stakoverflow的2个讨论：<a href="http://stackoverflow.com/questions/24224392/why-does-spark-throw-notserializableexception-org-apache-hadoop-io-nullwritable">link1</a> <a href="http://stackoverflow.com/questions/22592811/task-not-serializable-java-io-notserializableexception-when-calling-function-ou/22594142#22594142">link2</a></p></li>
<li><p>正确地使用广播变量(broadcast variables)</p>

<p> 如果我们有一份const数据，需要在executors上用到，一个典型的例子是Driver从数据库中load了一份数据dbData，在很多RDD操作中都引用了dbData，这样的话，每次RDD操作，driver node都需要将dbData分发到各个executors node一遍（分享1中已经介绍了背景），这非常的低效，特别是dbData比较大且RDD操作次数较多时。Spark的广播变量使得Driver可以提前只给各个executors node传一遍（spark内部具体的实现可能是driver传给某几个executors，这几个executors再传给其余executors）。使用广播变量有一个我犯过的错误如下：
 <pre><code> val brDbData = sparkContext.broadcast(dbData) //broadcast dbDataA, and name it as brDbData
 val dbDataB = brDbData.value //no longer broadcast variable
 oneRDD.map(x=>{dbDataB.getOrElse(key, -1); …})</code></pre>
 第一行将dbData已经广播出去且命名为brDbData，一定要在RDD操作中直接使用该广播变量，如果提前提取出值，第三行的RDD操作还需要将dbData传送一遍。正确的代码如下
 <pre><code> val brDbData = sparkContext.broadcast(dbData) //broadcast dbDataA, and name it as brDbData
 oneRDD.map(x=>{brDbData.value.getOrElse(key, -1); …})</code></pre></p></li>
<li><p>使用yarn-client或者yarn-cluster模式运行spark应用之前，在IDE中配置spark local模式调试以及测试好代码</p>

<p> spark的yanr-client或者yarn-cluster模式做一次测试比较耗时，因为涉及到代码打包以及上传。在IDE（推荐IntelliJ）中配置local模型用于debug和测试，将显著提升开发和测试效率；</p>

<p> 在VM option中配置：&#8221;-Dspark.master=local -Dspark.app.name=Test -Xmx2G&#8221; (also increase maximal memory for Heap)
 <img src="http://dongguo.me/images/personal/engineering/spark/spark-mr-yarn.png" alt="" /></p></li>
<li><p>充分利用spark的并行性</p>

<p> 理想的情况是整个代码的逻辑是对一个或几个RDD做处理，这时候spark的并行性往往是充分利用的。有时候代码逻辑会更复杂，比如你需要统计一年中每一天的一些数值，由于代码逻辑比较复杂，一种简单的“偷懒”方式是用一个for循环，在for循环内部做RDD的操作，这种情况是要努力避免的，务必思考将不同date的统计并行化。我写过的两个应用中都遇到了这种情况：优化之后速度提升非常明显。</p></li>
<li><p>使用cache()操作</p>

<p> cache RDD需要考虑自己有多少内存，对于后续不需要多次使用的RDD不要cache，如果内存有限却又指定要cache，大量的时间将被花在memory和disk的in-out上</p></li>
<li><p>为spark-submit选择合适的参数</p>

<p> <a href="http://spark.apache.org/docs/latest/submitting-applications.html">spark-submit</a>用于提交spark job，其可配置为job申请多少资源，包括Driver的内存和cpu，executor的个数，每个executor的内存，cpu和线程数。如果使用yarn做资源管理，只有内存是硬性占有的，一个job过多地申请内存，将会有资源浪费，可能会使别的job因为申请不到足够的内存无法跑。可以用JMX(Java Management Extension)来监控你的spark job到底消耗多少内存，可以指导你申请合适的内存大小。</p></li>
<li><p>Spark可以访问众多的数据源：比如HDFS, HBase, Cassandra或者Hive表（Hive on Spark)， 直接得到一个RDD用作后续处理</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Slides of Some Machine Learning Talk I Shared in Hulu]]></title>
    <link href="http://dongguo.me/blog/2014/12/16/Machine-Learning-talks-from-me/"/>
    <updated>2014-12-16T00:00:00+08:00</updated>
    <id>http://dongguo.me/blog/2014/12/16/Machine-Learning-talks-from-me</id>
    <content type="html"><![CDATA[<p>Hulu has good traditional of engineering and research sharing, both internal and external.</p>

<p>Below are slides of 5 machine learning talks from me.</p>

<p><a href="http://www.slideshare.net/guo_dong/expectation-propagation-researchworkshop">Expectation propagation</a> (one popular bayesian inference technique proposed by Thomas Minka)</p>

<p><a href="http://www.slideshare.net/guo_dong/machine-learning-introduction">Machine Learning Introduction</a></p>

<p><a href="http://www.slideshare.net/guo_dong/feature-selection">Feature selection</a></p>

<p><a href="http://www.slideshare.net/guo_dong/logistic-regressionpptx">Logistic regression</a></p>

<p><a href="http://www.slideshare.net/guo_dong/additive-model-and-boosting-tree">Additive Model and boosting tree</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Programmatic Digital Advertising]]></title>
    <link href="http://dongguo.me/blog/2014/11/28/programmatic-digital-advertising/"/>
    <updated>2014-11-28T23:51:24+08:00</updated>
    <id>http://dongguo.me/blog/2014/11/28/programmatic-digital-advertising</id>
    <content type="html"><![CDATA[<p>从2010年开始开始工作，一直在做搜索广告，联盟上下文广告以及视频广告。这几年RTB，或者更广义的广告的程序化交易非常火。在这边总结一下我的理解。</p>

<p>“程序化交易“即通过程序自动化地完成商品的买和卖，这在很多领域都有应用，最经典的就是金融市场中的股票，债券，货币，期货等的交易。其至少有2个好处，第一：将人从交易的各个环节中解放出来，让一切变得自动化，有效率；第二：这种程序带来的自动化使得更大范围(甚至全球)资源的优化配置变得有可能。</p>

<p>广告也不例外。相比于传统线下媒体（比如电视）广告，互联网广告（这里我们默认是显示广告，不包括由几家巨头独营的搜索广告市场）有很多优势，最显著的也是2点，第一：用户在互联网的数据可以被用来做广告的精准投放，比如你在浏览很多网站的时候都有可能看到京东的广告，而广告的内容是你之前在京东浏览过的商品；第二：也是由于数据的获取更方便，互联网广告的质和量能更容易被度量，比如广告主可以仅为点击而不是展示付费，且点击次数很容易track。</p>

<p>当然这还不够完美，对于一个广告主，其终极目标是把自己的广告投放到全球最相关的用户上，可能出现在上万个不同的站点上，而自己只需要定义每次展示，点击，或者转化的付费（当然也可以为不同的站点指定不同的单价），广告主或者其代理不需要和各个内容提供商或内容提供商的代理分别扯皮。联盟广告（如百度联盟，阿里妈妈）实现了广告交易的程序化，但仅是其中特殊的一种。</p>

<h3>在线广告程序化交易</h3>

<p>在线广告程序化交易有如下一些stakeholders：
<img src="http://dongguo.me/images/personal/ads/programmatic_stakeholders.png">
DSP(Demand side platform)可以认为其是一个有技术背景的代理商，广告主可以选择为展示，点击或者转化进行付费，DSP则和其他众多DSP通过竞价竞争广告位。DSP的数据和技术积累直接关系到其是否NB.
SSP(Supply side platform)则将publishers进行整合。Ad Network在这个生态里扮演一个中枢的角色。</p>

<p>注意为了实现广告的程序化交易，除了advertisers和publishers, 其他角色都不是必须的，因为广告主和内容提供商之间完全可以直接交易。对于百度联盟，可以认为其同时扮演了Ad Network和DSP的角色，如果你既有内容资源又有广告主资源，你当然不希望和别人分享收益。</p>

<p>可以按照2个纬度（广告投放量是否被保证，以及是固定单价还是需要竞价）将在线广告的程序化交易分为4个类别：
<img src="http://dongguo.me/images/personal/ads/programmatic_types.png"/>
<a href="http://www.iab.net/media/file/IAB_Digital_Simplified_Programmatic_Sept_2013.pdf">reference</a></p>

<p>Inventory即广告流量，广告主往往比较关心广告投放量是否能够放完，特别是对于大的品牌广告主。保证广告投放量的deal就是传统的Guaranteed deal. 对于广告商来说，其为广告的付费一直是fixed，其可以选择是为每次展示付1毛钱还是为每次点击付10块钱。这个表格中提到的Pricing指的是publisher或者SSP端看到的报价，而这个价格通常指的都是展示的单价(CPM)，如果广告主选择以CPM付费（给DSP或者SSP或者直接给publisher）,publisher端看到的该由该advertiser声称的报价通常是稳定的，但是如果广告主选择以点击甚至转化付费，DSP对不同的广告位的出价的差别就很可能由很大的差别。</p>

<p>Automated Guaranteed相比传统的广告售卖方式差别不大，主要是让流程变得自动化。注意premium内容的售卖通常是这种方式（比如Hulu以及yahoo首页），这就意味着程序化交易的scope超脱了狭义的RTB, 也适用并有利于premium内容的售卖;</p>

<p>Unreserved Fixed Rate由比较大的实际意义，对于premium的内容，其大部分的Inventory还是会通过传统的方式一笔一笔和大广告主谈（大广告主的deal细节比较复杂），剩余有多少蛋糕可以卖给中小广告主？很难保证，所以通过不保量的方式程序化售卖出去是一个很理想的选择;</p>

<p>Invitation-Only Auction和Open Auction差别不大，只是前者限制只接入部分DSP或者advertisers，2者都是我们常说的RTB。</p>

<h3>实时竞价(Real-Time-Bidding)</h3>

<p>这边不展开介绍，有2个资源对RTB有很清晰的介绍</p>

<p><a href="https://www.youtube.com/watch?v=-Glgi9RRuJs&amp;index=2&amp;list=PL6aT9elthI51NOdkxxV3m7O3vIA_A9C5u">Youtube: how an Ad is Served with Real Time Bidding</a></p>

<p><a href="http://www.math.pku.edu.cn/teachers/yaoy/Spring2013/RTB101_iPinYou_XuehuaShen_English.pdf">iPinyou 沈学华的一篇科普</a></p>

<p>RTB这块对数据的要求还是比较高的。涉及到全互联网的数据共享，用户隐私又是一个棘手的问题。想想央视某年的315报道。</p>

<h3>新变化和问题</h3>

<p>相比RTB一直给人在垃圾流量做买卖的印象，越来越多高质量的publisher愿意接入到Ad Network中，小广告主也有机会了，程序化交易越来越普及；</p>

<p>质量的控制，包括广告的质量以及内容的质量；标准的统一，比如广告位的尺寸，视频广告的清晰度和风格等; 数据的获取以及隐私；</p>

<h3>一些推荐的资源</h3>

<p><a href="http://www.iab.net/">Interactive Advertising Bureau</a>: 一家致力于建立标准，推动在线广告行业发展的公司
<a href="http://www.iab.net/programmatic">IAB programmatic</a></p>

<p><a href="http://www.iab.net/iablog/2014/11/top-10-things-you-need-to-know-about-programmatic.html">TOP 10 thinks you need to know about programmatic</a></p>

<p><a href="https://www.youtube.com/watch?v=-Glgi9RRuJs&amp;index=2&amp;list=PL6aT9elthI51NOdkxxV3m7O3vIA_A9C5u">Youtube: how an Ad is Served with Real Time Bidding</a></p>

<p><a href="http://www.math.pku.edu.cn/teachers/yaoy/Spring2013/RTB101_iPinYou_XuehuaShen_English.pdf">iPinyou 沈学华的一篇科普</a></p>

<p><a href="http://www.tubemogul.com/">TubeMogul, 一家典型的DSP公司</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Challenges for a Word-class Ad Inventory Forecasting System]]></title>
    <link href="http://dongguo.me/blog/2014/09/20/ad-inventory-forecasting/"/>
    <updated>2014-09-20T22:01:24+08:00</updated>
    <id>http://dongguo.me/blog/2014/09/20/ad-inventory-forecasting</id>
    <content type="html"><![CDATA[<p>Key words: Ad Inventory Forecasting, Ad serving, Online advertising.</p>

<p>广告流量预估是各家采取保量模式售卖广告位的公司都必须要做的，无论是传统的电视媒体还是各家互联网公司。
一句话介绍就是给定未来任意一段时间区间（通过在一年内），在任意给定定向条件（比如demographic限定，geographic限定，上下文内容限定，平台限定，时间段限定等）下，预估对于各种形态的广告（比如视频，图片，文本广告）分别有多少可以卖。</p>

<h4>实现一个优秀的广告流量预估系统的挑战在什么地方呢？至少包括如下几点</h4>

<ol>
<li><p>在大数据量下保证快速的查询响应时间</p>

<ul>
<li>大数据体现在2点，首先是广告数据条目多，另外是定向条件多。当有100类定向条件，每类可以有2种取值时，不同定向条件的组合数目虽然不会到2<sup>100</sup>级别，但到billion级别还是可能的。如何做到近于实时的查询？<br></br></li>
</ul>
</li>
<li><p>复杂多样的干扰因素对预估准确性的影响</p>

<ul>
<li>业务本身的波动性对广告流量的影响</li>
<li>业务变动对广告流量的影响</li>
<li>突发时间对广告流量的影响<br></br></li>
</ul>
</li>
<li><p>具体业务逻辑的复杂性增加了系统逻辑的复杂性</p>

<ul>
<li>典型的业务流程是来了一个广告订单，在系统种查询是否有足够的流量可以售卖，但是查询得到的流量是满足定向条件的总流量，而单个订单的在投放过程种会有各种约束，比如不能给单个用户在一天中重复播放同一个广告商的广告。所以实际能够售卖给该订单的广告量一定少于查询到的总流量。这就需要在预估中考虑广告播放的频率限制；<br></br></li>
</ul>
</li>
<li><p>和Ad server(广告投放服务器)逻辑的协调</p>

<ul>
<li>通常同一个广告位会有多个广告qualify，Ad server决定了具体放哪个广告。在ad server逻辑不发生变化的情况下，可以利用历史数据（广告总量在各个定向条件上的分布）进行预估，但是一旦ad server逻辑发生变动，广告流量预告系统最好能实时作出调整，而不是收集了一个月数据之后才发应过来。<br></br></li>
</ul>
</li>
<li><p>流量预估只是第一步，流量的管理或者说全局的统筹优化是最大化收益的必要。</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Druid介绍与实践]]></title>
    <link href="http://dongguo.me/blog/2014/05/05/druid-introduction-and-practise/"/>
    <updated>2014-05-05T22:25:34+08:00</updated>
    <id>http://dongguo.me/blog/2014/05/05/druid-introduction-and-practise</id>
    <content type="html"><![CDATA[<h3>关键词</h3>

<p>Druid, column-stores, distributed system, bitmaps indexing</p>

<h3>应用场景</h3>

<p>最近在设计一个系统来预估未来一年的广告流量，不是总流量，是任意时间段任何定向(Targeting)条件约束情况下的流量。定向条件有近百种（内容类别，设备平台，用户地域，用户人口属性等），整个时间区间不同组合数（也就是数据行数）是亿级别。目标是秒级的查询响应时间。一个简单的数据例子如下：
<img src="http://dongguo.me/images/personal/engineering/druid/druid_data_example.png" width=800 align=bottom /></p>

<h3>存储系统选择</h3>

<h4>Mysql不是适合的选择</h4>

<p>最容易想到的是用Mysql作为数据存放和查询引擎，由于数据行数太多，Mysql必须通过创建索引或者组合索引来加速查询。典型的查询包含若干个定向类别，这些定向条件的组合是非常多的（top 80%的查询也会包含几十种组合），故需要创建非常多的组合索引，代价很高。另外，对于那些没有创建组合索引的查询，查询时间完全不能接受。实际测试结果是加了组合索引后整体查询速度提升有限。</p>

<h4>为什么没有用Hbase或者Hive</h4>

<p>Hbase本身是一个经典的基于hdfs的分布式存储系统，通常来说其是行存储的，当创建column families之后，每个column family是列存储的（代价就是当通过key查询某行的时候，需要从多个不连续的存储空间读数据，具体可<a href="http://stackoverflow.com/questions/11816609/column-based-or-row-based-for-hbase">参考</a>)。在这个应用中，可以为每个定向类别（包括日期）创建一个单独的column family，但是据我所知Hbase本身没有为column family创建bitmap indexing（<a href="https://issues.apache.org/jira/browse/HBASE-6014">参考</a>），查询速度应该会受到影响。另外不用Hbase的一个原因是我希望存储系统尽量轻量级，最好不要安装hadoop。</p>

<p>Hive将查询转化为M/R任务，没法保证查询的快速响应（比如M/R cluster资源竞争很激烈时），而且使用Hive需要以来hadoop cluster，对这个应用来说也略微重量级。</p>

<h4>我们需要一个高可用的分布式的列存储系统</h4>

<p>我们的核心需求包含2点，一是查询速度快，二是系统的拓展性好，最好是分布式的。</p>

<p>第一点要求意味着最好用column-store而不是row-store，在这个应用中，虽然定向类别有近百种，但是单次查询通常只会涉及几个。对于修改操作较少且查询往往只涉及少数几列的场景使用column-store可以获得快一个量级的查询速度。而且column-store可以通过bitmap indexing，encoding，以及compression来优化查询速度和存储开销。<a href="http://www.infoq.com/cn/articles/bigdata-store-choose">还存储还是列存储</a></p>

<p>第二点要求一方面是由于我们的数据量较大，并行存储和查询可以减少时间开销，另一方面是数据量每年还在快速上涨，以后可以简单地通过加机器来应对。</p>

<p>对系统的其他要求比较普遍：系统可用性要高，稳定，轻量级，易于上手。</p>

<h4>为什么Druid是适合的选择</h4>

<p>Druid满足我们上面2点要求，其是一个开源的、分布式的、列存储系统，特别适用于大数据上的（准）实时分析统计。且具有较好的稳定性（Highly Available）。
其相对比较轻量级，文档非常完善，也比较容易上手。</p>

<h3>Druid介绍</h3>

<p><strong>如何搭建一个Druid cluster请参考我<a href="http://dongguo.me/blog/2015/03/02/druid-cluster-setup/">另一篇文章</a></strong></p>

<h4>概念</h4>

<p><strong>Segment</strong>: Druid中有个重要的数据单位叫segment，其是Druid通过bitmap indexing从raw data生成的（batch or realtime）。segment保证了查询的速度。可以自己设置每个segment对应的数据粒度，这个应用中广告流量查询的最小粒度是天，所以每天的数据会被创建成一个segment。注意segment是不可修改的，如果需要修改，只能够修改raw data，重新创建segment了。</p>

<h4>架构</h4>

<p><img src="http://dongguo.me/images/personal/engineering/druid/druid_system.png" width=800 align=bottom /></p>

<p><strong>Druid本身包含5个组成部分</strong>：Broker nodes, Historical nodes, Realtime nodes, Coordinator Nodes和indexing services. 分别的作用如下：</p>

<ul>
<li>Broker nodes: 负责响应外部的查询请求，通过查询Zookeeper将请求划分成segments分别转发给Historical和Real-time nodes，最终合并并返回查询结果给外部；</li>
<li>Historial nodes: 负责&#8217;Historical&#8217; segments的存储和查询。其会从deep storage中load segments，并响应Broder nodes的请求。Historical nodes通常会在本机同步deep storage上的部分segments，所以即使deep storage不可访问了，Historical nodes还是能serve其同步的segments的查询；</li>
<li>Real-time nodes: 用于存储和查询热数据，会定期地将数据build成segments移到Historical nodes。一般会使用外部依赖kafka来提高realtime data ingestion的可用性。如果不需要实时ingest数据到cluter中，可以舍弃Real-time nodes，只定时地batch ingestion数据到deep storage；</li>
<li>Coordinator nodes: 可以认为是Druid中的master，其通过Zookeeper管理Historical和Real-time nodes，且通过Mysql中的metadata管理Segments</li>
<li>Druid中通常还会起一些indexing services用于数据导入，batch data和streaming data都可以通过给indexing services发请求来导入数据。</li>
</ul>


<p><strong>Druid还包含3个外部依赖</strong></p>

<ul>
<li>Mysql：存储Druid中的各种metadata（里面的数据都是Druid自身创建和插入的），包含3张表：&#8221;druid_config&#8221;（通常是空的）, &ldquo;druid_rules&#8221;（coordinator nodes使用的一些规则信息，比如哪个segment从哪个node去load）和“druid_segments”（存储每个segment的metadata信息）；</li>
<li>Deep storage: 存储segments，Druid目前已经支持本地磁盘，NFS挂载磁盘，HDFS，S3等。Deep Storage的数据有2个来源，一个是<a href="http://druid.io/docs/0.6.104/Batch-ingestion.html">batch Ingestion</a>, 另一个是real-time nodes；</li>
<li>ZooKeeper: 被Druid用于管理当前cluster的状态，比如记录哪些segments从Real-time nodes移到了Historical nodes；</li>
</ul>


<h4>查询</h4>

<p>Druid的查询是通过给Broker Nodes发送HTTP POST请求（也可以直接给Historical or Realtime Node），具体可见Druid<a href="http://druid.io/docs/latest/Tutorial:-All-About-Queries.html">官方文档</a>。查询条件的描述是json文件，查询的response也是json格式。Druid的查询包含如下4种：</p>

<ul>
<li><a href="http://druid.io/docs/latest/TimeBoundaryQuery.html">Time Boundary Queries</a>: 用于查询全部数据的时间跨度</li>
<li><a href="http://druid.io/docs/latest/GroupByQuery.html">groupBy Queries</a>: 是Druid的最典型查询方式，非常类似于Mysql的groupBy查询。query body中几个元素可以这么理解：

<ul>
<li>&ldquo;aggregation&rdquo;: 对应mysql&#8221;select XX from&#8221;部分，即你想查哪些列的聚合结果;</li>
<li>&ldquo;dimensions&rdquo;: 对应mysql&#8221;group by XX&#8221;，即你想基于哪些列做聚合;</li>
<li>&ldquo;filter&rdquo;: 对应mysql&#8221;where XX&#8221;条件，即过滤条件；</li>
<li>&ldquo;granularity&rdquo;: 数据聚合的粒度;</li>
</ul>
</li>
<li><a href="http://druid.io/docs/latest/TimeseriesQuery.html">Timeseries queries</a>: 其统计满足filter条件的&#8221;rows&#8221;上某几列的聚合结果，相比&#8221;groupBy Queries&#8221;不指定基于哪几列进行聚合，效率更高;</li>
<li><a href="http://druid.io/docs/latest/TopNQuery.html">TopN queries</a>: 用于查询某一列上按照某种metric排序的最常见的N个values;</li>
</ul>


<h3>本文小结</h3>

<ol>
<li>Druid是一个开源的，分布式的，列存储的，适用于实时数据分析的系统，文档详细，易于上手；

<ul>
<li>Druid在设计时充分考虑到了Highly Available，各种nodes挂掉都不会使得druid停止工作（但是状态会无法更新）；</li>
<li>Druid中的各个components之间耦合性低，如果不需要streaming data ingestion完全可以忽略realtime node；</li>
<li>Druid的数据单位Segment是不可修改的，我们的做法是生成新的segments替换现有的；</li>
<li>Druid使用Bitmap indexing加速column-store的查询速度，使用了一个叫做<a href="http://ricerca.mat.uniroma3.it/users/colanton/docs/concise.pdf">CONCISE</a>的算法来对bitmap indexing进行压缩，使得生成的segments比原始文本文件小很多；</li>
</ul>
</li>
<li>在我们的应用场景下（一共10几台机器，数据大概100列，行数是亿级别），平均查询时间&lt;2秒，是同样机器数目的Mysql cluter的1/100 ~ 1/10；</li>
<li>Druid的一些“局限”：

<ul>
<li>Segment的不可修改性简化了Druid的实现，但是如果你有修改数据的需求，必须重新创建segment，而bitmap indexing的过程是比较耗时的；</li>
<li>Druid能接受的数据的格式相对简单，比如不能处理嵌套结构的数据</li>
</ul>
</li>
</ol>


<h3>参考资料&amp;推荐阅读</h3>

<ol>
<li><a href="http://druid.io/docs/latest/">官方文档</a></li>
<li><a href="https://groups.google.com/forum/#!forum/druid-development">google groups讨论区</a></li>
<li><a href="http://static.druid.io/docs/druid.pdf">Druid: A Real-time Analytical Data Store</a></li>
<li><a href="http://en.wikipedia.org/wiki/Bitmap_index">Bitmap indexing wikepedia</a></li>
<li><a href="http://ricerca.mat.uniroma3.it/users/colanton/docs/concise.pdf">Bitmap indexing compression algorithm used by Druid</a></li>
<li><a href="http://www.infoq.com/cn/articles/bigdata-store-choose">行存储or列存储？</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Expectation Propagation: Theory and Application]]></title>
    <link href="http://dongguo.me/blog/2014/01/01/expectation-propagation/"/>
    <updated>2014-01-01T22:04:00+08:00</updated>
    <id>http://dongguo.me/blog/2014/01/01/expectation-propagation</id>
    <content type="html"><![CDATA[<h2>简介</h2>

<p>第一次接触EP是10年在百度实习时，当时组里面正有计划把线上的CTR预估模型改成支持增量更新的版本，读到了微软一篇基于baysian的CTR预估模型的文章（见推荐阅读5），文章中没有给出推导的细节，自己也没有继续研究。今年在PRML中读Approximal inference这章对EP有了一些了解，同时参考了其它相关的一些资料，在这里和大家探讨。</p>

<h4>什么是期望传播</h4>

<p>期望传播(Expectation Propagation): 基于<strong>bayesian</strong>的一种<strong>近似</strong>推断方法，常用于图模型中计算单个节点的边缘分布或者后验分布，属于message passing这一类推断方法。</p>

<h4>牛人</h4>

<p>首先当然是Thomas Minka, 其在MIT读博期间提出了EP，并将EP作为博士论文课题在2001年发表。Minka毕业之后去了CMU教书，现在和Bishop一起在剑桥微软研究院。</p>

<p>其次是Kevin p. Murphy, 他是我做EP相关文献调研时发现的paper比较多的，我读到的一篇全文基本都是在推导Minka博士论文中一些公式的细节。btw Murphy 2013年出版了一本书，见推荐阅读2。</p>

<h4>中英文对照</h4>

<p>下面是一些关键词的中英文对应 （由于相关的书籍文献基本都是英文的，有些词没有想到比较好的中文翻译，故保留英文）</p>

<p>截断高斯: Truncated Gaussian</p>

<p>置信传播: Belief Propagation （后面会简称BP）</p>

<p>期望传播: Expectation Propagation (后面会简称为EP)</p>

<p>消息传递: Message passing</p>

<h2>背景</h2>

<p>EP本身的思想和方法都还是比较简单的，不过会涉及到一些背景知识，这边一并介绍。</p>

<h3>高斯、截断高斯</h3>

<p>EP的核心思想之一是用指数族分布近似复杂分布，实际应用中通常选择高斯分布，所以多个高斯分布的乘积，相除，积分在EP应用过程中不可避免。</p>

<p>截断高斯是高斯分布在指定区间归一化后的结果，（所以其并不是一个高斯分布），EP本身并不和截断高斯直接相关，但是如果在分类问题中应用EP，对观察样本（0-1）建模方法通常是y=sign(f(x)>t), 和另一个高斯分布相乘之后即为截断高斯分布。（然后就需要计算其的均值方差，原因后面会提到）</p>

<p>我在另一篇文章<a href="http://dongguo.me/blog/2013/12/02/gaussian-and-truncated-gaussian/">Gaussian and Truncated Gaussian</a>中介绍了比较多的细节，可以参考。</p>

<h3>指数族分布</h3>

<p>指数族分布（exponential family distribution）有着非常好的特性，比如其有<strong>充分统计量</strong>，多个指数族分布的乘积依然是指数族分布，具体的介绍可以参见wikipedia, 介绍的非常全面，也可以参考PRML第2章。</p>

<p>由于指数族的良好特性，其常被拿去近似复杂的概率分布（EP和variance baysian都是）。由于EP中常常选择高斯分布，我们这边强调一下，高斯分布的充分统计量为: (x, x<sup>2</sup>), 其中x为高斯分布的自变量。</p>

<h3>图模型</h3>

<p>EP是贝叶斯流派的计算变量后验分布（或者说是边缘分布）的近似推断方法，通常都可以通过一个概率图模型来描述问题的生成过程（generation process），所以可以说图模型是EP的典型应用场景。</p>

<p>图模型在很多地方都有介绍，比如PRML第8章，在这里就不重复了。有1点提一下，一个图模型的联合分布（不管是有向图还是无向图）可以写成若干个因子的乘积，对于有向图每个因子是每个节点的条件分布（条件于其的所有直接相连的父节点），对于无限图每个因子是energy function。
这个特性在后面的置信传播算法会用到。</p>

<h3>factor graph</h3>

<p>图模型中节点之间的关系通过边来表达，factor graph将这种节点之间的关系通过显式的节点（factor node）来表达，比如对于有向图，每个factor node就代表一个条件概率分布，图中的所有的信息都存在于节点上（variable nodes和factor nodes）。</p>

<p>后面的BP和EP都基于factor graph，可以认为factor graph使得图上的inference方法变得比较直观，另一个好处是factor graph屏蔽了有向图和无向图的差异。（有向图无向图都可以转变为factor graph）</p>

<p>更多了解可以看PRML第8章。</p>

<h3>置信传播</h3>

<p>Belief Propagation (BP)又叫&#8217;sum-product&#8217;，是一种计算图模型上节点边缘分布的推断方法，属于消息传递方法的一种，非近似方法（基于其延伸的Loopy Belief propagation为近似推断方法）。
BP的核心为如下3点：</p>

<ul>
<li><strong>单个variable node边缘分布的计算</strong></li>
</ul>


<p><img src="http://dongguo.me/images/personal/research/ep-intro/marginal_dis_variable_node.png" width=400 align=top /></p>

<p>(注：上图来之PRML)</p>

<p>前面提到过图模型的联合分布可以分解为若干因子的乘积，每个因子对应一个factor node：</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/posterior_dis_variable_node_f1.png" width=500 align=top /></p>

<p>每个variable node的边缘分布为与其直接相连的factor nodes传递过来的message的乘积：</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/posterior_dis_variable_node_f2.png" width=700 align=top /></p>

<ul>
<li><strong>从factor node到variable node的消息传递</strong></li>
</ul>


<p><img src="http://dongguo.me/images/personal/research/ep-intro/message_factor_to_variable.png" width=400 align=bottom /></p>

<p>(注：上图来之PRML)</p>

<p>从factor node f传递到variable node x的message为：与f直接相连（除了x）的variable nodes传递到f的messages与f本身的乘积的积分（积分变量为与f直接相连的除x之外的所有variable nodes）：</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/message_factor_to_variable_f1.png" width=600 align=top /></p>

<ul>
<li><strong>从variable node到factor node的消息传递</strong></li>
</ul>


<p><img src="http://dongguo.me/images/personal/research/ep-intro/message_variable_to_factor.png" width=400 align=bottom /></p>

<p>(注：上图来之PRML)</p>

<p>从variable node x到factor node f的message为：与x直接相连的factor nodes（除f以外）传递到x的messages的乘积：</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/message_variable_to_factor_f1.png" width=400 align=top /></p>

<p>更多细节请参考PRML</p>

<h3>Moment matching</h3>

<p>在实际的问题中，要么后验分布本身比较复杂（推荐阅读3中的Clutter example），要么最大化后验的计算比较复杂，要么破坏了具体算法的假设（比如EP要求图中的所有message都是指数族），所以常常会用（有良好性质的）指数族分布近似实际的概率分布。</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/moment_matching_1.png" width=600 align=top />
<img src="http://dongguo.me/images/personal/research/ep-intro/moment_matching_2.png" width=300 align=top /></p>

<p>用一个分布去近似另一个分布的常见方法是最小化KL散度:</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/moment_matching_3.png" width=600 align=top />
<img src="http://dongguo.me/images/personal/research/ep-intro/moment_matching_4.png" width=600 align=top /></p>

<p>我们发现通过最小化KL散度得到的‘最接近’p(x)的q(x)可以简单地通过匹配充分统计量的期望得到。</p>

<p>当q(x)为高斯分布的时候，我们知道其充分统计量u(x)=(x, x<sup>2</sup>)，这时通过KL散度最小化近似分布近似的方法称为moment matching(匹配矩)</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/moment_matching_5.png" width=600 align=top /></p>

<p>为什么称为匹配矩呢，看看矩的定义就知道了：</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/moment_matching_6.png" width=350 align=top /></p>

<h2>期望传播方法-理论</h2>

<p>EP的思想：在图模型中，用高斯分布近似每一个factors，然后&#8217;approximate each factor in turn in the context of all remaining facotrs&#8217;.</p>

<p>下面为具体的算法：
<img src="http://dongguo.me/images/personal/research/ep-intro/ep_def.png" width=800 align=top />
(注：本算法参考了PRML)</p>

<p>下面通过Minka博士论文中的例子‘clutter problem’来解释：每个观察样本以(1-w)的概率由高斯分布N(x|sita, I)生成，以w的概率由noise生成（同样也是高斯分布N(x|0, aI)），于是：
<img src="http://dongguo.me/images/personal/research/ep-intro/clutter_problem_1.png" width=400 align=top />
<img src="http://dongguo.me/images/personal/research/ep-intro/clutter_problem_2.png" width=200 align=top /></p>

<p>按照EP的思想，我们用一个单高斯q(sita)去近似混合高斯p(x|sita)
<img src="http://dongguo.me/images/personal/research/ep-intro/clutter_problem_3.png" width=400 align=top /></p>

<p>单高斯去近似混合高斯听起来效果一定不好，但实际上，由于EP在近似的时候乘了其他所有factors的高斯近似之后的上下文，考虑到很多个高斯分布相乘之后的方差一般都很小，所有实际上单高斯只需要在很小的区间近似好混合高斯即可。如下图：</p>

<p><img src="http://dongguo.me/images/personal/research/ep-intro/clutter_problem_4.png" width=350 align=top />
<img src="http://dongguo.me/images/personal/research/ep-intro/clutter_problem_5.png" width=350 align=top /></p>

<p>(注：上面2张图来之PRML)</p>

<p>其中蓝色曲线为混合高斯（没有画完整），红色曲线为近似的单高斯，绿色曲线为‘其它所有factor的乘积’。</p>

<h3>EP怎么应用在message passing中：</h3>

<p>在图模型中，所谓的&#8217;context of all remaining factors&#8217;就是当前节点之外所有节点和messages，所以EP在图模型中的使用方式为：和BP一样的方法计算message和marginal distribution，当某个factor或者marginal distribution不是高斯分布时，用高斯分布近似它。所以Minka认为EP也就是BP+moment matching。</p>

<p>由于每个factor以及variable node的边缘分布都是高斯分布（或被近似为高斯分布），所以EP的计算过程一般并不复杂。</p>

<h2>期望传播方法-应用</h2>

<p>EP被广泛地应用在图模型的inference上，这边提一下微软的2个应用：Bing的CTR预估，XBOX游戏中player skill的评估。</p>

<h3>Bing的CTR预估</h3>

<p>详细的推导及实验请参考：<a href="http://dongguo.me/blog/2013/12/01/bayesian-ctr-prediction-for-bing/">Bayesian CTR prediction for Bing</a>
paper中称这个model为ad predictor，其在我的数据集上预估效果很不错，训练预测速度快，天然支持增量更新，主要的缺点就是模型不是稀疏的。如果你知道怎么自然地达到稀疏效果，请指教。</p>

<p>和其它算法的比较请参考：<a href="http://dongguo.me/blog/2013/12/15/classification-models/">Classification Models</a></p>

<h3>XBOX中player skill的评估</h3>

<p>图模型和上一篇略有差异，推导过程差不多，paper中没有给出详细的推导过程，不过Murphy的新书中给出了，请参考推荐阅读2。</p>

<h2>一些小结</h2>

<ol>
<li>EP的通用性比较好，对于实际的问题，画出graph model和factor graph，就可以尝试用EP来进行inference；</li>
<li>虽然应用EP时的推导过程略长（计算很多个message和marginal distribution），但是最终的整体的更新公式一般都非常简单，所以模型训练时间开销往往较小；</li>
<li>为了使用EP，只能用高斯分布来建模，比如Bing的CTR预估那篇对每个feature的weight建模，只能假设服从高斯分布，相当于是2范数的正则化，不能达到稀疏模型的效果；</li>
<li>在我的实验中，通过EP进行inference得到的模型预估效果不错，值得一试；</li>
</ol>


<h2>推荐阅读</h2>

<ol>
<li><p>机器学习保留书籍:<a href="http://research.microsoft.com/en-us/um/people/cmbishop/prml/">Pattern recognition and machine learning</a> 第2,8,10章 (第2章看看高斯四则运算，指数族分布特性；第8章了解图模型基础，期望传播算法；第10章了解期望传播算法)</p></li>
<li><p>Murphy新书: <a href="http://www.cs.ubc.ca/~murphyk/MLbook/">Machine Learning: A Probabilistic Perspective</a> 第22章 (本书相比PRML更加具体，第22章干脆包含了TrueSkill的详细推导步骤)</p></li>
<li><p>Minka的博士论文：<a href="http://qh.eng.ua.edu/e_paper/e_thesis/EPThesis.pdf">A family of algorithms for approximate Bayesian inference</a> (想了解基本思想和理论看完前3节即可)</p></li>
<li><p>EP的应用之一：<a href="http://research.microsoft.com/pubs/74419/tr-2006-80.pdf">TrueSkill: A Bayesian Skill Rating System</a> (文中并没有给出EP每一步的细节)</p></li>
<li><p>EP的应用之二：<a href="http://research.microsoft.com/pubs/122779/adpredictor%20icml%202010%20-%20final.pdf">Web-Scale Bayesian Click-Through Rate Prediction for Sponsored Search Advertising in Microsoft’s Bing Search Engine</a> (CTR预估的应用比较吸引人，文章写得很棒，算法的效果也很好，只是干脆忽略的inference过程，有兴趣的同学可以参看我另一个文章，里面有一步一步推导的过程)</p></li>
<li><p>Minka整理的EP学习资料：<a href="http://research.microsoft.com/en-us/um/people/minka/papers/ep/roadmap.html">link</a> (其中的包含了一个videolecture上他做的variance inference的talk值得一看)</p></li>
<li><p>本文的PPT： <a href="http://www.slideshare.net/guo_dong/expectation-propagation-researchworkshop">墙外</a>, <a href="http://pan.baidu.com/s/1kT3DtvL">墙内</a></p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Classification Models]]></title>
    <link href="http://dongguo.me/blog/2013/12/15/classification-models/"/>
    <updated>2013-12-15T00:35:00+08:00</updated>
    <id>http://dongguo.me/blog/2013/12/15/classification-models</id>
    <content type="html"><![CDATA[<p>During my past 3 years in career, following classifiers are often used for classification tasks.</p>

<h2>Typcial classifiers comparision</h2>

<p><img class="left" src="http://dongguo.me/images/personal/research/classifiers/classifiers_compare.png" width="800"></p>

<h2>Decision Tree</h2>

<p>Decision Tree is not a start-of-art model for classification or regression, and when there are huge features(say millions) it will take a long time for training.
But it may perform very well when the number of distinct features are limited, and the classification/regression task is obviously non-linear.</p>

<p>A typical scenario is multi-model fusion: you have trained multiple models for single task, and you want to generate the final prediction result using all these models.
Based on my past experiments, Decision Tree can out perform linear model(linear regression, logistic regression and so on) on many datasets.</p>

<h2>RDT, random forest, boosting tree</h2>

<p>All of these 3 models are ensemble learning method for classification/regression that operate by constructing multiple Decision Tree at training time.
For RDT(random decision tree), only part of total samples are used to training each tree. And all features are considered for splitting.</p>

<p>Similar with RDT, random forest also use part of total sampels to construct each tree, but it also only use subset of features/dimisions for splitting.
So random forest introduces more &lsquo;random&rsquo; factors for training, and it may perform better when there are more noises in training set.</p>

<p>boosting tree is actually forward stagwise additive modeling with decision tree as base learner. And if you choose exponential loss function, then boosting tree becauses Adaboost with decision tree as base learner.
Here is one <a href="http://www.slideshare.net/guo_dong/additive-model-and-boosting-tree">slide</a> about additive model and boosting tree.</p>

<h2>Generalized linear model</h2>

<p>One of the most popular generalized linear model is logistic regression, which is generalized linear model with inversed sigmoid function as the link function.
There are multiple different implementation for logistic regression, and here are some often used by me.</p>

<h4>Logistic regression optimized with SGD.</h4>

<p>It&rsquo;s very basic, so I ignore the details here</p>

<h4>OWLQN</h4>

<p>It was proposed by Microsoft in paper <a href="http://research.microsoft.com/en-us/downloads/b1eb1016-1738-4bd5-83a9-370c9d498a03/">Orthant-Wise Limited-memory Quasi-Newton Optimizer for L1-regularized Objectives</a> of ICML 2007. You can also find the source code and executable runner via this link.</p>

<p>This model is optimized by a method which is similar with L-BFGS, but can achieve sparse model with L1 regularizer. I recommend you try this model and compare with other models you are using in your dataset.
Here are four reasons:</p>

<ol type="a">
<li>It&rsquo;s fast, especially when the dataset is huge;</li>
<li>It can generate start-of-art prediction results on most dataset;</li>
<li>It&rsquo;s stable and there are few parameters need to be tried. Actaully, I find only regularization parameters can impact the performance obviously;</li>
<li>It&rsquo;s sparse, which is very important for big dataset and real product. (Of course, sparse is due to L1 regularizer, instead of the specific optimization method)</li>
</ol>


<p>One problem is it&rsquo;s more challenge to implement it by yourself, so you need spend some time to make it support incremental update or online learning.</p>

<h4>FTRL</h4>

<p>It was proposed by Google via paper <a href="http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/41159.pdf">
Ad Click Prediction: a View from the Trenches</a> in 2013. I tried on my dataset, and this implementation can generate similar prediction performance with OWLQN.
It&rsquo;s quicker than OWLQN for training, and it&rsquo;s also sparse. One advantage is it&rsquo;s very easy to implement, and it support increamental update naturally.
One pain point for me is this model has 3-4 parameters need to be chosen, and most of them impact the prediction performance obviously.</p>

<h4>Ad predictor</h4>

<p>This <a href="http://research.microsoft.com/pubs/122779/adpredictor%20icml%202010%20-%20final.pdf">paper</a> was also proposed by Microsoft in ICML 2009.</p>

<p>One biggest different with upper 3 implementation is it&rsquo;s based on bayesian, so it&rsquo;s generative model. Ad predictor is used to predict CTR of sponsor search ads of Bing, and on my dataset, it could also achieve comparable prediction performance with OWQLN and FTRL.
Ad predictor model the weight of each feature with a gaussian distribution, so it natually supports online learning. And the prediction result for each sample is also a gaussian distribution, and it could be used to handle the exploration and exploitation problem.
See more details of this model in another <a href="http://guod08.github.io/me/blog/2013/12/01/bayesian-ctr-prediction-for-bing/">post</a>.</p>

<h2>Neural Network</h2>

<p>ANN is so slow for training, so it&rsquo;s tried only when the dataset is small of medium. Another disadvantage of ANN is it&rsquo;s totally blackbox.</p>

<h2>SVM</h2>

<p>SVM with kernel is also slow for training. You can try it with <a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">libsvm</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gaussian and Truncated Gaussian]]></title>
    <link href="http://dongguo.me/blog/2013/12/02/gaussian-and-truncated-gaussian/"/>
    <updated>2013-12-02T18:30:00+08:00</updated>
    <id>http://dongguo.me/blog/2013/12/02/gaussian-and-truncated-gaussian</id>
    <content type="html"><![CDATA[<p>Everybody knows about Gaussian distribution, and Gaussian is very popular in Bayesian world and even in our life. This article summaries typical operation of Gaussian, and something about Truncated Guassian distribution.</p>

<h2>Gaussian</h2>

<h3>pdf and cdf</h3>

<p><img class="left" src="http://dongguo.me/images/personal/research/gaussian/gaussian_pdf.png" width="350" title="'Gaussian pdf'" >
<img class="right" src="http://dongguo.me/images/personal/research/gaussian/gaussian_cdf.png" width="350" title="'Gaussian cdf'" >
<img src="http://dongguo.me/images/personal/research/gaussian/gaussian_1.png" width="1200"></p>

<h3>Sum/substraction of two independent Gaussian random variables</h3>

<p><img src="http://dongguo.me/images/personal/research/gaussian/gaussian_plus2.png" width="1200">
Please take care upper formula only works when x1 and x2 are independent. And it&rsquo;s easy to get the distribution for variable x=x1-x2
See <a href="http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter7.pdf">here</a> for the detils of inference</p>

<h3>Product of two Gaussian pdf</h3>

<p><img src="http://dongguo.me/images/personal/research/gaussian/gaussian_multiple2.png" width="1200">
Please take care x is no longer a gaussian distribution. And you can find it&rsquo;s very elegant to use &lsquo;precision&rsquo; and &lsquo;precision adjusted mean&rsquo; for Gaussian operation like multiply and division.
See <a href="http://www.tina-vision.net/docs/memos/2003-003.pdf">here</a> for the detils of inference</p>

<h3>Division of two Gaussian pdf</h3>

<p><img src="http://dongguo.me/images/personal/research/gaussian/gaussian_divide2.png" width="1200"></p>

<h3>Intergral of the product of two gaussian distribution</h3>

<p><img src="http://dongguo.me/images/personal/research/gaussian/gaussian_integral.png" width="1200"></p>

<h2>Truncated Gaussian</h2>

<p><img class="left" src="http://dongguo.me/images/personal/research/gaussian/tg_pdf.png" width="350" title="'Gaussian pdf'" >
<img class="right" src="http://dongguo.me/images/personal/research/gaussian/tg_cdf.png" width="350" title="'Gaussian cdf'" ></p>

<p>Truncated Gaussian distribution is very simple: it&rsquo;s just one conditional (Gaussian) distribution.
Suppose variable x belongs to Gaussian distribution, then x conditional on x belongs to (a, b) has a truncated Gaussian distribution.
<img src="http://dongguo.me/images/personal/research/gaussian/tg_def.png" width="1200"></p>

<h3>Calculate expectation of Truncated Gaussian</h3>

<p><img src="http://dongguo.me/images/personal/research/gaussian/tg_e1.png" width="1200">
<img src="http://dongguo.me/images/personal/research/gaussian/tg_e2.png" width="1200"></p>

<h3>Calculate variance of Truncated Gaussian</h3>

<p><img src="http://dongguo.me/images/personal/research/gaussian/tg_v1.png" width="1200">
<img src="http://dongguo.me/images/personal/research/gaussian/tg_v2.png" width="1200">
<img src="http://dongguo.me/images/personal/research/gaussian/tg_v3.png" width="1200"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bayesian CTR Prediction of Bing]]></title>
    <link href="http://dongguo.me/blog/2013/12/01/bayesian-ctr-prediction-for-bing/"/>
    <updated>2013-12-01T22:07:00+08:00</updated>
    <id>http://dongguo.me/blog/2013/12/01/bayesian-ctr-prediction-for-bing</id>
    <content type="html"><![CDATA[<p>Microsoft published a paper in ICML 2009 named &lsquo;Web-Scale Bayesian Click-Through Rate Prediction for Sponsored Search Advertising in Microsoft&rsquo;s Bing Search Engine&rsquo;,
which is claimed won the competition of most accurate and scalable CTR predictor across MS.
This article shows how to inference this model(let&rsquo;s call it Ad predictor) step-by-step.</p>

<h2>Pros. and Cons.</h2>

<p>I like it because it&rsquo;s totally based on Bayesian, and Bayesian is beautiful. Online learning is naturally supported, and the precition accuracy is comparable with FTRL and OWLQN. And both training and prediction is light-weight and fast.
Btw: one shortage of this model is it&rsquo;s not sparse, which may be a big issue when applied on big dataset with huge amount of features.</p>

<h2>Inference using Expectation Propagation step by step</h2>

<p>Firstly, following is the factor graph of ad predictor.
<img class="left" src="http://dongguo.me/images/personal/research/ep/adPredictor.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_factor_definition.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step1.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step2.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step3.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step4.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step5.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step6.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step7_1.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step7_2.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step7_3.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step7_4.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step8.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step9.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step10.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step11.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step12.png" width="1200"></p>

<p><img class="left" src="http://dongguo.me/images/personal/research/ep/ep_step13.png" width="1200"></p>

<p>For each sample, we can use the formula of step 13 to update the posterior parameter of W, which is very easy to be implemented.</p>

<h2>Prediction</h2>

<p>After training, we can predict with following formula:
<img class="left" src="http://dongguo.me/images/personal/research/ep/ep_predict.png" width="1200"></p>

<h2>Prediction Accuracy</h2>

<p>I compared it with FTRL and OWLQN on one dataset for age&amp;gender prediction. AUC of this model is comparable with OWLQN and FTRL, so I recommend you have a try in your case.</p>

<h2>Insights</h2>

<ol>
<li><p>You can find variance of each feature increases after every exposure, which makes sense.</p></li>
<li><p>This model shows samples with more features will have bigger variance, which does not make sense very much. I think the reason is we assume all the features are independent. Any insights from you?</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Notes for Distributed System Theory]]></title>
    <link href="http://dongguo.me/blog/2013/11/12/distributed-system-theory/"/>
    <updated>2013-11-12T23:23:27+08:00</updated>
    <id>http://dongguo.me/blog/2013/11/12/distributed-system-theory</id>
    <content type="html"><![CDATA[<p>过去三年参与的广告相关的项目都基于各种各样的分布式存储和计算系统，比如hdfs, hbase, cassandra cluster, memcached cluster, Druid, hadoop和spark。最近在研究各个系统的原理，周末浏览了一本电子书<a href="http://www.valleytalk.org/wp-content/uploads/2012/07/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D.pdf">《分布式系统原理介绍》</a>，介绍了很多重要的基础知识，推荐浏览。</p>

<h3>Key words:</h3>

<p>数据存储方式，consistent hashing，数据副本，副本控制协议，Lease机制，Quorum机制，日志技术，Paxos协议，CAP理论</p>

<h3>consistent hashing: 分布式数据存取的经典方案</h3>

<ol>
<li>背景：数据的分布式存储的一种简单方式为hash, 这种方法简单，无需纪录数据存放在哪台node上。但是当集群需要拓展（或者减少）机器时，由于hash结果一般和机器数目有关，数据需要重新迁移；</li>
<li>Consistent hashing将key组织成一个环，每个node负责一段连续的子环，当增加一个node时，只需要将临近的一个node上的部分数据copy到新node，不停机的情况下，对hit rate的影响明显减小；</li>
<li>需要额外存储的元数据只有node在环上的顺序，数据量小；</li>
<li>有一个缺点是：每次加入一个node，只能减轻现有的一个node的压力。且如果是随即分配node在环上的顺序，将很难保证在每个node的&#8217;负载均衡&#8217;；</li>
<li>一个较好的解决方案是引入&#8217;virtual nodes&#8217;： 首先假设有比真实nodes个数明显多的virtual nodes。这个个数是固定的，所以可以预先将其均匀地分布到环上。通过元数据将每个real node关联上多个virtual nodes，注意不是连续的，一般选在环上分隔较远的virtual nodes。这样的话，每加入一个real node，将会将属于其他real nodes的几个virtual nodes分配给新加入的real node，分担了多个real nodes的压力。反之，当一个real node失败，可以有多个real nodes来分担压力。</li>
</ol>


<h3>数据副本: 分布式系统提供高容错高用可行的重要手段</h3>

<ol>
<li>有2种最常见的数据副本存储方案，一种是以机器为粒度，一种是以数据块为粒度。</li>
<li>以机器为粒度的缺点：

<ul>
<li>一旦某台机器数据丢失，数据恢复的效率不高，因为一般需要从非常有限台机器copy数据。而且会比较消耗copy from机器的资源，往往需要让一台机器下线，或者限制copy的速度；</li>
<li>一旦某台机器宕机，压力被有限的几台副本机器分担（若3台机器互为副本，则剩余机器的数据访问压力提高50%）</li>
<li>增加一台机器无法扩容，必须一下增加若干台机器（互为副本）</li>
</ul>
</li>
<li>以数据块为粒度的好处：(相对应)

<ul>
<li>一旦某台机器数据丢失，可以从剩余的所有机器上copy数据，数据恢复的效率高</li>
<li>一台机器宕机，不会给任何单台机器增加明显压力；</li>
<li>扩容容易</li>
</ul>
</li>
</ol>


<h3>副本控制协议: 控制各副本数据读写行为，使得副本满足一定可用性和一致性</h3>

<ol>
<li>中心化副本控制协议：中心结点负责数据的更新，并发控制，协调副本一致性；单点故障

<ul>
<li>primary node在将更新同步到各个secondary nodes时，限于primary node的压力，往往只同步给有限几个secondary nodes，后续采用接力的方式</li>
<li>同步过程的中间状态，包括同步失败的处理，以及access状态的返回，决定了系统的数据一致性</li>
<li>primary node宕机由于需要时间来发现（比如10s），在这段时间内无法更新数据</li>
</ul>
</li>
<li>去中心化副本控制协议</li>
<li>实例 （大部分分布式数据存储系统都使用primary－secondary副本控制协议）

<ul>
<li>GFS: primary-secondary</li>
<li>PUNTS(yahoo!的分布式数据存储平台): 使用primary－secondary协议</li>
<li>Dynamo/Cassandra: 使用去中心化副本控制协议</li>
<li>Zookeeper: 使用去中心化协议选出primary node，之后就转变为中心化的副本控制协议</li>
</ul>
</li>
</ol>


<h3>Lease机制：保证secondary nodes和primary node的一致性</h3>

<ol>
<li>primary node在向cache nodes同步数据时，还会附带一个时间戳表达这份数据的有效期。在有效期内primary node保证不修改数据，cache nodes可以放心使用数据。</li>
<li>带来的cost是：若某个cache node提高修改元数据请求，primary node需要阻塞所有cache nodes对该份数据的读写请求，并等待到该份数据的lease超时才修改元数据。</li>
<li>所以lease的时长比较关键：太长会导致availability下降，太短会导致cache nodes频繁同步primary node；常使用10s</li>
<li>lease机制用于primary node的选择：primary node的更改主要由于结点宕机，而传统的Heartbeat的方法不能有效监控结点状态（存在网络失败，监控机器本身性能问题导致的延时等），故每当nodes给监控机器发heartbeat时，返回一个lease，若primary node心跳失败，则等待lease过期后，监控结点更换primary node</li>
<li>lease机制应用的实例

<ul>
<li>GFS中用于master挑选primary node</li>
<li>Chubby(google的分布式文件系统) 有2处使用了lease机制 a). secondary nodes承诺在一段时间内不重新选举primary node; b). primary node用于监控secondary nodes的状态</li>
<li>Zookeeper: primary node向client颁发lease</li>
</ul>
</li>
</ol>


<h3>Quorum机制: 可用性和一致性的权衡</h3>

<ol>
<li>在存在N个副本的情况下，对于更新操作，只要在W在副本上更新成功，则算该更新成功（“成功提交的更新操作”）。当读取R个副本时（限制R+W>N），就可以保证可以读到更新之后的数据。</li>
<li>注意：仅依赖quorum机制无法知道最新成功提交的版本号，故无法保证强一致性（系统应该始终返回最新的成功提交的数据），需要通过其他方式获取系统最新成功提交的数据；</li>
<li>Quorum机制体现了CAP理论中的availability（update时只需要更新了W个副本，read时只需要读取R个副本）和consistent（由于update或者read只需要在部分副本上成功即可，导致了仅follow Quorum机制不能保证强一致性）的权衡：</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[更高效地工作学习]]></title>
    <link href="http://dongguo.me/blog/2013/10/20/shi-jian-guan-li/"/>
    <updated>2013-10-20T20:53:00+08:00</updated>
    <id>http://dongguo.me/blog/2013/10/20/shi-jian-guan-li</id>
    <content type="html"><![CDATA[<p>周末浏览了一本书《小强升职记》，介绍了工作中事情管理的很多经验，个人觉得帮助挺大，在这边分享一下。</p>

<ol>
<li><p>将事情按照重要性、紧急性2个维度分成4个象限。</p>

<ol type="a">
<li>第一象限（重要且紧急）：立马去做；思考“这些事情真的都是重要且紧急的吗？”，“为什么这些事情会进入这个象限？”；</li>
<li>第二象限（重要但不紧急）：尽量开始去做，没时间的话第一时间进行任务分解，制定时间表；</li>
<li>第三象限（不重要但紧急）：注意紧急和重要一点关系没有；思考“如何尽力减少这类事情？”</li>
<li>第四象限（不重要且不紧急）：尽量别做</li>
</ol>
</li>
<li><p>走出第三象限（不重要但紧急）：Monkey theory
 甩掉自己身上的猴子，将猴子放回到主人身上 （书中这段举的例子很有意思）
 比如：“朋友问：这周六咱们去游泳吧；你答：好啊，到时候你提前给我打电话，有时间的话，我一定去”。
 比如“新来的同事问：你好，能不能给我讲讲pre-demo这个项目；你答：好啊，能不能你先看一下咱们wiki上的文档，你总结问题之后咱们一起讨论？”
 另外，第三象限中的事情可以想办法delegate给别人去做</p></li>
<li><p>第二象限是精力分配的重点
 有2个原因：这些事是重要的；这些事安排处理好了，进入第一象限的事情也会明显变少；
 目标描述和任务分解：让自己清晰地自己有哪些细分的是要做，每个时段的任务是什么，明确地知道该任务是否拖延；有利于减轻自己的压力；</p></li>
<li><p>时段工作法：将待做的事情分配到各个小时，每个小时或者任务完成后勾掉任务，给自己增加压力，督促自己提高效率；
 这种方法还可以让自己了解自己的高效、低效时段在哪</p></li>
<li><p>每周（天）开始前将要做的事情分到4个象限; 优先做（或者在自己效率最高的时段）做第一第二象限的事情；同时按照时段工作法进行</p></li>
<li><p>一些tips
 尽量午休
 做一件事情的时候尽量不让自己给打断（如果同事来讨论问题，可以说一会去找他，同时记录下这件事情），专注心如止水地做事
 关掉outlook的邮件提醒，绝大部分邮件都不需要立即响应，每半天主动检查一次邮件即可；
 安排计划前提前考虑已经被预约掉的时间；
 保持办公环境，特别是办公桌的整洁有序；
 刚到公司或者吃完饭回到公司，先给水杯打满水再工作；</p></li>
</ol>

]]></content>
  </entry>
  
</feed>
